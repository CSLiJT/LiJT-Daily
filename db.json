{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1},{"_id":"source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":0},{"_id":"source/images/2021112601.png","path":"images/2021112601.png","modified":0,"renderable":0},{"_id":"source/images/2021112602.png","path":"images/2021112602.png","modified":0,"renderable":0},{"_id":"source/images/2021112604.png","path":"images/2021112604.png","modified":0,"renderable":0},{"_id":"source/images/2021112603.png","path":"images/2021112603.png","modified":0,"renderable":0},{"_id":"source/images/2021121301.png","path":"images/2021121301.png","modified":0,"renderable":0},{"_id":"source/images/IMG_20210321_171950.jpg","path":"images/IMG_20210321_171950.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210323_120734.jpg","path":"images/IMG_20210323_120734.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210325_104740.jpg","path":"images/IMG_20210325_104740.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210405_134224.jpg","path":"images/IMG_20210405_134224.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210405_134319.jpg","path":"images/IMG_20210405_134319.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210809_091606_edit_932701128736847.jpg","path":"images/IMG_20210809_091606_edit_932701128736847.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210925_120441.jpg","path":"images/IMG_20210925_120441.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210925_120635_edit_759134094171144.jpg","path":"images/IMG_20210925_120635_edit_759134094171144.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210925_210835.jpg","path":"images/IMG_20210925_210835.jpg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210925_210855.jpg","path":"images/IMG_20210925_210855.jpg","modified":0,"renderable":0},{"_id":"source/images/Linkedin.svg","path":"images/Linkedin.svg","modified":0,"renderable":0},{"_id":"source/images/background.jpg","path":"images/background.jpg","modified":0,"renderable":0},{"_id":"source/images/c995d143ad4bd113d3b5cb035eafa40f4bfb0582.jpg","path":"images/c995d143ad4bd113d3b5cb035eafa40f4bfb0582.jpg","modified":0,"renderable":0},{"_id":"source/images/email.svg","path":"images/email.svg","modified":0,"renderable":0},{"_id":"source/images/github.svg","path":"images/github.svg","modified":0,"renderable":0},{"_id":"source/images/pytorch.png","path":"images/pytorch.png","modified":0,"renderable":0},{"_id":"source/images/qrcode_cslijt.github.io.png","path":"images/qrcode_cslijt.github.io.png","modified":0,"renderable":0},{"_id":"source/images/屏幕截图_2022-03-26_175317.jpg","path":"images/屏幕截图_2022-03-26_175317.jpg","modified":0,"renderable":0},{"_id":"source/images/屏幕截图_2022-03-26_175646.jpg","path":"images/屏幕截图_2022-03-26_175646.jpg","modified":0,"renderable":0},{"_id":"source/images/微信图片_20211001161414.jpg","path":"images/微信图片_20211001161414.jpg","modified":0,"renderable":0},{"_id":"source/images/微信图片_20211001171428.jpg","path":"images/微信图片_20211001171428.jpg","modified":0,"renderable":0},{"_id":"source/images/知乎.svg","path":"images/知乎.svg","modified":0,"renderable":0},{"_id":"source/images/IMG_20210925_203119.jpg","path":"images/IMG_20210925_203119.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"f212d288b5790d4b0c65c6c0efb845933d71bdca","modified":1649236296665},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1627608806000},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1627608806000},{"_id":"themes/next/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1627608806000},{"_id":"themes/next/.gitignore","hash":"56f3470755c20311ddd30d421b377697a6e5e68b","modified":1627608806000},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1627608806000},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1627608806000},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1627608806000},{"_id":"themes/next/README.md","hash":"9b4b7d66aca47f9c65d6321b14eef48d95c4dff1","modified":1627608806000},{"_id":"themes/next/_config.yml","hash":"ea8b79fef05571ab8e17b983aa48520fc37172c0","modified":1649237541404},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"e554931b98f251fd49ff1d2443006d9ea2c20461","modified":1627608806000},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1627608806000},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"aa4cb7aff595ca628cb58160ee1eee117989ec4e","modified":1627608806000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1a435c20ae8fa183d49bbf96ac956f7c6c25c8af","modified":1627608806000},{"_id":"themes/next/gulpfile.js","hash":"1b4fc262b89948937b9e3794de812a7c1f2f3592","modified":1627608806000},{"_id":"themes/next/.github/config.yml","hash":"1d3f4e8794986817c0fead095c74f756d45f91ed","modified":1627608806000},{"_id":"themes/next/package.json","hash":"62fad6de02adbbba9fb096cbe2dcc15fe25f2435","modified":1627608806000},{"_id":"themes/next/.github/issue-close-app.yml","hash":"7cba457eec47dbfcfd4086acd1c69eaafca2f0cd","modified":1627608806000},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1627608806000},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"c7a994b9542040317d8f99affa1405c143a94a38","modified":1627608806000},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"fca600ddef6f80c5e61aeed21722d191e5606e5b","modified":1627608806000},{"_id":"themes/next/.github/lock.yml","hash":"61173b9522ebac13db2c544e138808295624f7fd","modified":1627608806000},{"_id":"themes/next/.github/mergeable.yml","hash":"0ee56e23bbc71e1e76427d2bd255a9879bd36e22","modified":1627608806000},{"_id":"themes/next/.github/release-drafter.yml","hash":"3cc10ce75ecc03a5ce86b00363e2a17eb65d15ea","modified":1627608806000},{"_id":"themes/next/docs/DATA-FILES.md","hash":"cddbdc91ee9e65c37a50bec12194f93d36161616","modified":1627608806000},{"_id":"themes/next/.github/support.yml","hash":"d75db6ffa7b4ca3b865a925f9de9aef3fc51925c","modified":1627608806000},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1627608806000},{"_id":"themes/next/.github/stale.yml","hash":"fdf82de9284f8bc8e0b0712b4cc1cb081a94de59","modified":1627608806000},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"94dc3404ccb0e5f663af2aa883c1af1d6eae553d","modified":1627608806000},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1627608806000},{"_id":"themes/next/docs/MATH.md","hash":"d645b025ec7fb9fbf799b9bb76af33b9f5b9ed93","modified":1627608806000},{"_id":"themes/next/languages/de.yml","hash":"74c59f2744217003b717b59d96e275b54635abf5","modified":1627608806000},{"_id":"themes/next/languages/ar.yml","hash":"9815e84e53d750c8bcbd9193c2d44d8d910e3444","modified":1627608806000},{"_id":"themes/next/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1627608806000},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1627608806000},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"8b6e4b2c9cfcb969833092bdeaed78534082e3e6","modified":1627608806000},{"_id":"themes/next/languages/en.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1627608806000},{"_id":"themes/next/languages/fa.yml","hash":"3676b32fda37e122f3c1a655085a1868fb6ad66b","modified":1627608806000},{"_id":"themes/next/languages/es.yml","hash":"c64cf05f356096f1464b4b1439da3c6c9b941062","modified":1627608806000},{"_id":"themes/next/languages/hu.yml","hash":"b1ebb77a5fd101195b79f94de293bcf9001d996f","modified":1627608806000},{"_id":"themes/next/languages/id.yml","hash":"572ed855d47aafe26f58c73b1394530754881ec2","modified":1627608806000},{"_id":"themes/next/languages/fr.yml","hash":"752bf309f46a2cd43890b82300b342d7218d625f","modified":1627608806000},{"_id":"themes/next/languages/it.yml","hash":"44759f779ce9c260b895532de1d209ad4bd144bf","modified":1627608806000},{"_id":"themes/next/languages/ja.yml","hash":"0cf0baa663d530f22ff380a051881216d6adcdd8","modified":1627608806000},{"_id":"themes/next/languages/ko.yml","hash":"0feea9e43cd399f3610b94d755a39fff1d371e97","modified":1627608806000},{"_id":"themes/next/languages/nl.yml","hash":"5af3473d9f22897204afabc08bb984b247493330","modified":1627608806000},{"_id":"themes/next/languages/pt.yml","hash":"718d131f42f214842337776e1eaddd1e9a584054","modified":1627608806000},{"_id":"themes/next/languages/pt-BR.yml","hash":"67555b1ba31a0242b12fc6ce3add28531160e35b","modified":1627608806000},{"_id":"themes/next/languages/uk.yml","hash":"3a6d635b1035423b22fc86d9455dba9003724de9","modified":1627608806000},{"_id":"themes/next/languages/ru.yml","hash":"e993d5ca072f7f6887e30fc0c19b4da791ca7a88","modified":1627608806000},{"_id":"themes/next/languages/tr.yml","hash":"2b041eeb8bd096f549464f191cfc1ea0181daca4","modified":1627608806000},{"_id":"themes/next/layout/_layout.swig","hash":"cf68af4a334c866fad464c76c575cb53e38bb3fe","modified":1649235560334},{"_id":"themes/next/languages/vi.yml","hash":"93393b01df148dcbf0863f6eee8e404e2d94ef9e","modified":1627608806000},{"_id":"themes/next/languages/zh-TW.yml","hash":"8c09da7c4ec3fca2c6ee897b2eea260596a2baa1","modified":1627608806000},{"_id":"themes/next/languages/zh-CN.yml","hash":"a1f15571ee7e1e84e3cc0985c3ec4ba1a113f6f8","modified":1627608806000},{"_id":"themes/next/layout/category.swig","hash":"1bde61cf4d2d171647311a0ac2c5c7933f6a53b0","modified":1627608806000},{"_id":"themes/next/languages/zh-HK.yml","hash":"3789f94010f948e9f23e21235ef422a191753c65","modified":1627608806000},{"_id":"themes/next/layout/archive.swig","hash":"e4e31317a8df68f23156cfc49e9b1aa9a12ad2ed","modified":1627608806000},{"_id":"themes/next/layout/index.swig","hash":"7f403a18a68e6d662ae3e154b2c1d3bbe0801a23","modified":1627608806000},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1627608806000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d3efc0df0275c98440e69476f733097916a2d579","modified":1627608806000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"c3e6b8196c983c40fd140bdeca012d03e6e86967","modified":1627608806000},{"_id":"themes/next/layout/page.swig","hash":"db581bdeac5c75fabb0f17d7c5e746e47f2a9168","modified":1627608806000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"12d99fb8b62bd9e34d9672f306c9ae4ace7e053e","modified":1627608806000},{"_id":"themes/next/layout/tag.swig","hash":"0dfb653bd5de980426d55a0606d1ab122bd8c017","modified":1627608806000},{"_id":"themes/next/layout/post.swig","hash":"2f6d992ced7e067521fdce05ffe4fd75481f41c5","modified":1627608806000},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"0bd2d696f62a997a11a7d84fec0130122234174e","modified":1627608806000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"53df7d537e26aaf062d70d86835c5fd8f81412f3","modified":1627608806000},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"34b88784ec120dfdc20fa82aadeb5f64ef614d14","modified":1627608806000},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"5237a368ab99123749d724b6c379415f2c142a96","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"fb23b85db6f7d8279d73ae1f41631f92f64fc864","modified":1627608806000},{"_id":"themes/next/docs/ru/README.md","hash":"85dd68ed1250897a8e4a444a53a68c1d49eb7e11","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"d3f03be036b75dc71cf3c366cd75aee7c127c874","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"ca1030efdfca5e20f9db2e7a428998e66a24c0d0","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"8b18f84503a361fc712b0fe4d4568e2f086ca97d","modified":1627608806000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"9c8dc0b8170679cdc1ee9ee8dbcbaebf3f42897b","modified":1627608806000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"71655ca21907e9061b6e8ac52d0d8fbf54d0062b","modified":1627608806000},{"_id":"themes/next/layout/_macro/post.swig","hash":"090b5a9b6fca8e968178004cbd6cff205b7eba57","modified":1627608806000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"db6ab5421b5f4b7cb32ac73ad0e053fdf065f83e","modified":1627608806000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"ba5a0341a495e66af8ec9aea0989906461ba6619","modified":1649235778324},{"_id":"themes/next/layout/_partials/languages.swig","hash":"ba9e272f1065b8f0e8848648caa7dea3f02c6be1","modified":1627608806000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1627608806000},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/README.md","hash":"c038629ff8f3f24e8593c4c8ecf0bef3a35c750d","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b92585d251f1f9ebe401abb5d932cb920f9b8b10","modified":1627608806000},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1627608806000},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"d9ce7331c1236bbe0a551d56cef2405e47e65325","modified":1627608806000},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1627608806000},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"b782eb2e34c0c15440837040b5d65b093ab6ec04","modified":1627608806000},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1627608806000},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"311e5eceec9e949f1ea8d623b083cec0b8700ff2","modified":1627608806000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"2731e262a6b88eaee2a3ca61e6a3583a7f594702","modified":1627608806000},{"_id":"themes/next/scripts/events/index.js","hash":"5743cde07f3d2aa11532a168a652e52ec28514fd","modified":1627608806000},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1627608806000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1627608806000},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1627608806000},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"4d2c93c66e069852bb0e3ea2e268d213d07bfa3f","modified":1627608806000},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"703bdd142a671b4b67d3d9dfb4a19d1dd7e7e8f7","modified":1627608806000},{"_id":"themes/next/scripts/filters/locals.js","hash":"b193a936ee63451f09f8886343dcfdca577c0141","modified":1627608806000},{"_id":"themes/next/scripts/filters/post.js","hash":"44ba9b1c0bdda57590b53141306bb90adf0678db","modified":1627608806000},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1627608806000},{"_id":"themes/next/scripts/helpers/font.js","hash":"40cf00e9f2b7aa6e5f33d412e03ed10304b15fd7","modified":1627608806000},{"_id":"themes/next/source/css/_colors.styl","hash":"a8442520f719d3d7a19811cb3b85bcfd4a596e1f","modified":1627608806000},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"958e86b2bd24e4fdfcbf9ce73e998efe3491a71f","modified":1627608806000},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"5e11f30ddb5093a88a687446617a46b048fa02e5","modified":1627608806000},{"_id":"themes/next/source/css/_mixins.styl","hash":"e31a557f8879c2f4d8d5567ee1800b3e03f91f6e","modified":1627608806000},{"_id":"themes/next/scripts/helpers/engine.js","hash":"bdb424c3cc0d145bd0c6015bb1d2443c8a9c6cda","modified":1627608806000},{"_id":"themes/next/source/css/main.styl","hash":"a3a3bbb5a973052f0186b3523911cb2539ff7b88","modified":1627608806000},{"_id":"themes/next/scripts/tags/button.js","hash":"8c6b45f36e324820c919a822674703769e6da32c","modified":1627608806000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f1826ade2d135e2f60e2d95cb035383685b3370c","modified":1627608806000},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"94e0bbc7999b359baa42fa3731bdcf89c79ae2b3","modified":1627608806000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"d902fd313e8d35c3cc36f237607c2a0536c9edf1","modified":1627608806000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1627608806000},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1627608806000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1627608806000},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1627608806000},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1627608806000},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1627608806000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1627608806000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1627608806000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1627608806000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1627608806000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1627608806000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1627608806000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1627608806000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1627608806000},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1627608806000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1627608806000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1627608806000},{"_id":"themes/next/source/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1627608806000},{"_id":"themes/next/source/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1627608806000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"93d8a734a3035c1d3f04933167b500517557ba3e","modified":1627608806000},{"_id":"themes/next/source/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1627608806000},{"_id":"themes/next/scripts/tags/pdf.js","hash":"8c613b39e7bff735473e35244b5629d02ee20618","modified":1627608806000},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1627608806000},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"c70f8e71e026e878a4e9d5ab3bbbf9b0b23c240c","modified":1627608806000},{"_id":"themes/next/source/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1627608806000},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"7dbe93b8297b746afb89700b4d29289556e85267","modified":1627608806000},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"d31f896680a6c2f2c3f5128b4d4dd46c87ce2130","modified":1627608806000},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"9440d8a3a181698b80e1fa47f5104f4565d8cdf3","modified":1627608806000},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"ae2261bea836581918a1c2b0d1028a78718434e0","modified":1627608806000},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"000bad572d76ee95d9c0a78f9ccdc8d97cc7d4b4","modified":1627608806000},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"954ad71536b6eb08bd1f30ac6e2f5493b69d1c04","modified":1627608806000},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"810d544019e4a8651b756dd23e5592ee851eda71","modified":1627608806000},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"ceba16b9bd3a0c5c8811af7e7e49d0f9dcb2f41e","modified":1627608806000},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1627608806000},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1627608806000},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"2b1a73556595c37951e39574df5a3f20b2edeaef","modified":1627608806000},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1627608806000},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"c46849e0af8f8fb78baccd40d2af14df04a074af","modified":1627608806000},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"077b5d66f6309f2e7dcf08645058ff2e03143e6c","modified":1627608806000},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"48430bd03b8f19c9b8cdb2642005ed67d56c6e0b","modified":1627608806000},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"9b7a66791d7822c52117fe167612265356512477","modified":1627608806000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"f48a6a8eba04eb962470ce76dd731e13074d4c45","modified":1627608806000},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"2be50f9bfb1c56b85b3b6910a7df27f51143632c","modified":1627608806000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1627608806000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"2fa2b51d56bfac6a1ea76d651c93b9c20b01c09b","modified":1627608806000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1627608806000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1627608806000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1627608806000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"f39a5bf3ce9ee9adad282501235e0c588e4356ec","modified":1627608806000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b14908644225d78c864cd0a9b60c52407de56183","modified":1627608806000},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1627608806000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1627608806000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1627608806000},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"d6ceb70648555338a80ae5724b778c8c58d7060d","modified":1627608806000},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"f910618292c63871ca2e6c6e66c491f344fa7b1f","modified":1627608806000},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"82f5b6822aa5ec958aa987b101ef860494c6cf1f","modified":1627608806000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"f7a9eca599a682479e8ca863db59be7c9c7508c8","modified":1627608806000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"be0a8eccf1f6dc21154af297fc79555343031277","modified":1627608806000},{"_id":"themes/next/source/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1627608806000},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1627608806000},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1627608806000},{"_id":"themes/next/source/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1627608806000},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"d35a999d67f4c302f76fdf13744ceef3c6506481","modified":1627608806000},{"_id":"themes/next/scripts/events/lib/config.js","hash":"d34c6040b13649714939f59be5175e137de65ede","modified":1627608806000},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1627608806000},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"ecf751321e799f0fb3bf94d049e535130e2547aa","modified":1627608806000},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"a54708fd9309b4357c423a3730eb67f395344a5e","modified":1627608806000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"2486f3e0150c753e5f3af1a3665d074704b8ee2c","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"4c0c99c7e0f00849003dfce02a131104fb671137","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"7f8b92913d21070b489457fa5ed996d2a55f2c32","modified":1627608806000},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"4b1986e43d6abce13450d2b41a736dd6a5620a10","modified":1627608806000},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"b26ac2bfbe91dd88267f8b96aee6bb222b265b7a","modified":1627608806000},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1627608806000},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"5f6a966c509680dbfa70433f9d658cee59c304d7","modified":1627608806000},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"f233d8d0103ae7f9b861344aa65c1a3c1de8a845","modified":1627608806000},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1627608806000},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"d56d5af427cdfecc33a0f62ee62c056b4e33d095","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"6cbd85f9433c06bae22225ccf75ac55e04f2d106","modified":1627608806000},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"f3c43664a071ff3c0b28bd7e59b5523446829576","modified":1627608806000},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"d30b0e255a8092043bac46441243f943ed6fb09b","modified":1627608806000},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"d5fefc31fba4ab0188305b1af1feb61da49fdeb0","modified":1627608806000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"f70be8e229da7e1715c11dd0e975a2e71e453ac8","modified":1627608806000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"f4e694e5db81e57442c7e34505a416d818b3044a","modified":1627608806000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1627608806000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"62df49459d552bbf73841753da8011a1f5e875c8","modified":1627608806000},{"_id":"themes/next/source/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1627608806000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1627608806000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"612ec843372dae709acb17112c1145a53450cc59","modified":1627608806000},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1627608806000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"818508748b7a62e02035e87fe58e75b603ed56dc","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"7785bd756e0c4acede3a47fec1ed7b55988385a5","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"f0131db6275ceaecae7e1a6a3798b8f89f6c850d","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"f6516d0f7d89dc7b6c6e143a5af54b926f585d82","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"bb7ace23345364eb14983e860a7172e1683a4c94","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"7104b9cef90ca3b140d7a7afcf15540a250218fc","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"6136da4bbb7e70cec99f5c7ae8c7e74f5e7c261a","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"93db5dafe9294542a6b5f647643cb9deaced8e06","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"e282df938bd029f391c466168d0e68389978f120","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"70a4324b70501132855b5e59029acfc5d3da1ebd","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"85da2f3006f4bef9a2199416ecfab4d288f848c4","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"44f47c88c06d89d06f220f102649057118715828","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"e740deadcfc4f29c5cb01e40f9df6277262ba4e3","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"ca5e70662dcfb261c25191cc5db5084dcf661c76","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"2b2e7b5cea7783c9c8bb92655e26a67c266886f0","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"a47725574e1bee3bc3b63b0ff2039cc982b17eff","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"0b2c4b78eead410020d7c4ded59c75592a648df8","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1627608806000},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"8e7b57a72e757cf95278239641726bb2d5b869d1","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"2e3bf7baf383c9073ec5e67f157d3cb3823c0957","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"a2e9e00962e43e98ec2614d6d248ef1773bb9b78","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"18ce72d90459c9aa66910ac64eae115f2dde3767","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1627608806000},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"681d33e3bc85bdca407d93b134c089264837378c","modified":1627608806000},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"a1690e035b505d28bdef2b4424c13fc6312ab049","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"b1f0fab7344a20ed6748b04065b141ad423cf4d9","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"d21d4ac1982c13d02f125a67c065412085a92ff2","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"e771dcb0b4673e063c0f3e2d73e7336ac05bcd57","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"e75693f33dbc92afc55489438267869ae2f3db54","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f49ca072b5a800f735e8f01fc3518f885951dd8e","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"902569a9dea90548bec21a823dd3efd94ff7c133","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"f71a3e86c05ea668b008cf05a81f67d92b6d65e4","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ded41fd9d20a5e8db66aaff7cc50f105f5ef2952","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"1e4190c10c9e0c9ce92653b0dbcec21754b0b69d","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"65cb6edb69e94e70e3291e9132408361148d41d5","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"72d495a88f7d6515af425c12cbc67308a57d88ea","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"6a97bcfa635d637dc59005be3b931109e0d1ead5","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"d114b2a531129e739a27ba6271cfe6857aa9a865","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"a760ee83ba6216871a9f14c5e56dc9bd0d9e2103","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"b49e9fbd3c182b8fc066b8c2caf248e3eb748619","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"1d2778ca5aeeeafaa690dc2766b01b352ab76a02","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"709d10f763e357e1472d6471f8be384ec9e2d983","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9a878d0119785a2316f42aebcceaa05a120b9a7a","modified":1627608806000},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"9f0b93d109c9aec79450c8a0cf4a4eab717d674d","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"d7fce4b51b5f4b7c31d93a9edb6c6ce740aa0d6b","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"e4d9a77ffe98e851c1202676940097ba28253313","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"454a4aebfabb4469b92a8cbb49f46c49ac9bf165","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e2d606f1ac343e9be4f15dbbaf3464bc4df8bf81","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b49c64f8e9a6ca1c45c0ba98febf1974fdd03616","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"e7a9fdb6478b8674b1cdf94de4f8052843fb71d9","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"a793cfff86ad4af818faef04c18013077873f8f0","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"f23670f1d8e749f3e83766d446790d8fd9620278","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1627608806000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"35c871a809afa8306c8cde13651010e282548bc6","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"fa0222197b5eee47e18ac864cdc6eac75678b8fe","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"44487d9ab290dc97871fa8dd4487016deb56e123","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"5f432a6ed9ca80a413c68b00e93d4a411abf280a","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"45a239edca44acecf971d99b04f30a1aafbf6906","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"1f0e7fbe80956f47087c2458ea880acf7a83078b","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b2fc519828fe89a1f8f03ff7b809ad68cd46f3d7","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"a960a2dd587b15d3b3fe1b59525d6fa971c6a6ec","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"a05a4031e799bc864a4536f9ef61fe643cd421af","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"2a47f8a6bb589c2fb635e6c1e4a2563c7f63c407","modified":1627608806000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"a9cd93c36bae5af9223e7804963096274e8a4f03","modified":1627608806000},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1627608806000},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1627608806000},{"_id":"themes/next/images/avatar.jpg","hash":"15683b2f7f56946cc4639cbd21441ec3e87add35","modified":1632917523974},{"_id":"source/images/avatar.jpg","hash":"15683b2f7f56946cc4639cbd21441ec3e87add35","modified":1632917523974},{"_id":"source/_posts/2022-04-01-plan.md","hash":"2638df47097e8a3bbdb03721c1611efaf5b7bb46","modified":1649238678870},{"_id":"source/_posts/2022-03-26-remind.md","hash":"2382fd397fd35d1a1a576ea783ee216f2a72a7f6","modified":1649238669106},{"_id":"source/_posts/2022-02-22-paper.md","hash":"2299162d82f3b3cfa386122b689d5ee8345ccb92","modified":1649238658025},{"_id":"source/_posts/2021-09-27-pytorch.md","hash":"270b6a4fa11b01f25d52fb275c2c81643c36409e","modified":1649238091960},{"_id":"source/_posts/2021-09-29-food.md","hash":"a0f3cbafb199bbd0de41494d3865314d29ac660f","modified":1649238222817},{"_id":"source/_posts/2021-10-01-stewlamb.md","hash":"ecfd7f193fc1d45df0a06dcecaf050cd396b0ccb","modified":1649238231884},{"_id":"source/_posts/2021-10-07-pytorch.md","hash":"59c582c80b3e13c38f5c25d68ef62efa674b2899","modified":1649238255444},{"_id":"source/_posts/2021-10-01-whale01.md","hash":"b3b2927c08635fa913e20d05b228bb1ef0d7c1f8","modified":1649238241519},{"_id":"source/_posts/2021-10-18-ablation.md","hash":"82f08e5684920f4264964013850b6672f1a2eeb3","modified":1649238280657},{"_id":"source/_posts/2021-10-25-python.md","hash":"cd02e9078971f5d570881ebd7622af2e199abde2","modified":1649238366378},{"_id":"source/_posts/2021-10-26-regex.md","hash":"3fc820311de2c1a710e16aa75a698be921262ea5","modified":1649238401582},{"_id":"source/_posts/2021-11-26-vscode.md","hash":"b9d8bd10ae2d04c46455ee4eead83fbd59af8a0b","modified":1649238470569},{"_id":"source/_posts/2021-11-23-delicacy.md","hash":"cb3d103adf224fed9a1cf22e5964c7fcd164e18a","modified":1649238431857},{"_id":"source/about/index.md","hash":"b3e73bc1ecb8eff94e56a1e2f0f7f8b1a8408933","modified":1649236803024},{"_id":"source/categories/index.md","hash":"d7dc11c389a65875212803ffde140e4539fabd97","modified":1649236799583},{"_id":"source/_posts/2021-12-13-hadoop.md","hash":"71e85a28008a919b64641334db3f28075b25ef80","modified":1649238591656},{"_id":"source/tags/index.md","hash":"0022d708d44ce8886e15253bb5feba61f9c452fb","modified":1649236795845},{"_id":"source/_posts/2021-12-13-java.md","hash":"2688a43c1ce7ef411c2d4902262515c83191cc8d","modified":1649238632027},{"_id":"source/_posts/2021-12-29-fuzzy.md","hash":"7a8202a9efe7b2528363abd3cb4a7273c2ec4cb8","modified":1649238645714},{"_id":"source/images/2021112604.png","hash":"86b40fadbfd75b7afae3266f54e772a67ec6c6a2","modified":1637912471329},{"_id":"source/images/Linkedin.svg","hash":"c9fef67479d6a9e36dcd93e7bcf396b8dd41be7c","modified":1636976186012},{"_id":"source/images/email.svg","hash":"d347f708ecac0aad59241631a8e20999a098cf1b","modified":1636976210834},{"_id":"source/images/github.svg","hash":"328b059eb62ccdbf789100eb7fa93e0ad88baacd","modified":1636975753931},{"_id":"source/images/pytorch.png","hash":"c2e801b87de4351c4e0ee23aca1f1768b61e2ba4","modified":1633580527891},{"_id":"source/images/qrcode_cslijt.github.io.png","hash":"7242fae717ed02bd23fffcb6044c8a9dbb43aa1c","modified":1637029191368},{"_id":"source/images/屏幕截图_2022-03-26_175646.jpg","hash":"26e1a1351e575419cd154e827f9cf99569e2ff29","modified":1648288609876},{"_id":"source/images/知乎.svg","hash":"13af7dd0fecfa2111e1ad926934e3effdc8b693d","modified":1636976252400},{"_id":"source/images/2021112601.png","hash":"e097693047fe4101014ae79b1ae1efc76062b16d","modified":1637901977945},{"_id":"source/images/2021112603.png","hash":"c1052463cdc4375b1472169b592bd64f698152d9","modified":1637911359123},{"_id":"source/images/c995d143ad4bd113d3b5cb035eafa40f4bfb0582.jpg","hash":"cb074d590659e292ce0d605882a3b4b3a1f04dcd","modified":1633080352111},{"_id":"source/images/屏幕截图_2022-03-26_175317.jpg","hash":"c4a37962b06c44cf51afe57bc581c74496d5ba33","modified":1648288451693},{"_id":"source/images/2021112602.png","hash":"638027646cd217ce436c31957c7158b7ea914638","modified":1637902079233},{"_id":"source/images/2021121301.png","hash":"15d5d40d42c834bebeacc41495cd204ba3f3234f","modified":1639378671587},{"_id":"source/images/微信图片_20211001171428.jpg","hash":"45a8630d8a32f35c386de921d084d4cc5bf7774b","modified":1633079681820},{"_id":"source/images/IMG_20210925_203119.jpg","hash":"2e9abe7309e6e97c2123978bfab497e46e858902","modified":1632917523931},{"_id":"source/images/IMG_20210925_120635_edit_759134094171144.jpg","hash":"7224ffbd056b66d4a804fcacd514b850b314efa0","modified":1632917523920},{"_id":"source/images/IMG_20210925_210855.jpg","hash":"fa759ff825b95129080a0c904880240177afb55f","modified":1632917523957},{"_id":"source/images/IMG_20210809_091606_edit_932701128736847.jpg","hash":"598dbcf1c15c494679c130432aa0f814c9d5e7b7","modified":1632917523895},{"_id":"source/images/IMG_20210925_210835.jpg","hash":"b31a89e566d3addbb9d74dac9893894984c9fa17","modified":1632917523942},{"_id":"source/images/IMG_20210925_120441.jpg","hash":"a267aeacf92ab8d504ad7b3b315c380e8056456d","modified":1632917523912},{"_id":"source/images/微信图片_20211001161414.jpg","hash":"1878e9bac84ead0d7444adeb7b4c3f36b63e4c1a","modified":1633076080727},{"_id":"source/images/IMG_20210323_120734.jpg","hash":"ba5f11fde2b69fa608712e6b9939df96174cecc1","modified":1632917523649},{"_id":"source/images/IMG_20210321_171950.jpg","hash":"af85f769e58663ec27832b75c01724c16a963172","modified":1632917523629},{"_id":"source/images/IMG_20210405_134224.jpg","hash":"3eeaa0239bfff2a50721fa503ac1c607bf0a4471","modified":1632917523732},{"_id":"source/images/IMG_20210325_104740.jpg","hash":"55ab15bbe191dce47fa98b7064740b4d86aa8d7a","modified":1632917523699},{"_id":"source/images/background.jpg","hash":"9b3c658843fa18464120a82be9431e0c881b8e06","modified":1632917523877},{"_id":"source/images/IMG_20210405_134319.jpg","hash":"9b3c658843fa18464120a82be9431e0c881b8e06","modified":1632917523877},{"_id":"public/categories/index.html","hash":"aa0b29f1cf836f59cd1ed564fcf343cad235f96e","modified":1649243617791},{"_id":"public/about/index.html","hash":"f5f86aa408eab674908bea5a38a6f66155b613d0","modified":1649243617791},{"_id":"public/tags/index.html","hash":"1bbd7b11b77d5c44ccd3569eb54c66376cd00999","modified":1649243617791},{"_id":"public/2022/04/03/hello-world/index.html","hash":"d61d46131665d71e4dbbd0588e8baa923ee5b518","modified":1649243617791},{"_id":"public/2022/04/01/2022-04-01-plan/index.html","hash":"0bd7c51f6e0c96ee42501cf7a467e4210626f4a1","modified":1649243617791},{"_id":"public/2022/03/26/2022-03-26-remind/index.html","hash":"13037db84311795dd9054418e4f780a7b2cbc36f","modified":1649243617791},{"_id":"public/2022/02/22/2022-02-22-paper/index.html","hash":"25f98c8491e7ba029049b2ed8d143d4e5f25fbe7","modified":1649243617791},{"_id":"public/2021/12/29/2021-12-29-fuzzy/index.html","hash":"b5aaf4f929998ad5ea727b4bd682f6bdcdc7879b","modified":1649243617791},{"_id":"public/2021/12/13/2021-12-13-hadoop/index.html","hash":"5a19d028ae86448ac2eb9a604ec6dff8eb0a8790","modified":1649243617791},{"_id":"public/2021/11/23/2021-11-23-delicacy/index.html","hash":"c0c10a30da76fe634d086c6f89ffacdaba252244","modified":1649243617791},{"_id":"public/2021/10/18/2021-10-18-ablation/index.html","hash":"7753e4549fc1e6850c097d1b009959ef541f8fc6","modified":1649243617791},{"_id":"public/2021/10/01/2021-10-01-stewlamb/index.html","hash":"225d7764b92c8719a97a77c3338cb4b452df641c","modified":1649243617791},{"_id":"public/2021/10/01/2021-10-01-whale01/index.html","hash":"c3f026043cc2a4984ae6a57ff87d3837146a7841","modified":1649243617791},{"_id":"public/2021/09/29/2021-09-29-food/index.html","hash":"92fd005ce536ac944852c8b06095c39136b6544d","modified":1649243617791},{"_id":"public/archives/index.html","hash":"32267fc2d8f8f68f360e558197cf2b9f84701a03","modified":1649243617791},{"_id":"public/archives/page/2/index.html","hash":"d2b2eef9f6b44e09e6bbec4d88a2d12f4edc05d5","modified":1649243617791},{"_id":"public/archives/2021/index.html","hash":"f7c5e42fe473274887e5cb9b4c89c0dc9b5e7995","modified":1649243617791},{"_id":"public/archives/2021/page/2/index.html","hash":"b5db0c9350737406d57208adb4530834d2172f44","modified":1649243617791},{"_id":"public/archives/2021/09/index.html","hash":"811ee572b940bca1762ab821c8b6b5d82491ec5a","modified":1649243617791},{"_id":"public/archives/2021/10/index.html","hash":"218c02e11db7849a3d3c69be482702e3a2513a78","modified":1649243617791},{"_id":"public/archives/2021/11/index.html","hash":"eae6bf948d2b823c5072602722a8a6a6539d0882","modified":1649243617791},{"_id":"public/archives/2021/12/index.html","hash":"48993b5871a74dd7d7df8764bc597fa1aa842bd6","modified":1649243617791},{"_id":"public/archives/2022/index.html","hash":"57f89404feb6a0cd9433228dbba86b1042020285","modified":1649243617791},{"_id":"public/archives/2022/02/index.html","hash":"b63776c9be334227f6e4884b73d59c065a8cbd37","modified":1649243617791},{"_id":"public/archives/2022/03/index.html","hash":"fa01b7110901764438623b7b588ed906d72e5b22","modified":1649243617791},{"_id":"public/archives/2022/04/index.html","hash":"67590bc61fe01cd660ce7b0d6a3322348f4c571e","modified":1649243617791},{"_id":"public/tags/科研/index.html","hash":"83caba211654829f73592bfe2eb8a96976234119","modified":1649243617791},{"_id":"public/tags/pytorch/index.html","hash":"b4a213e70821e607548943c5bb0a0fff96d366c0","modified":1649243617791},{"_id":"public/tags/深度学习/index.html","hash":"77ad12da3bfb2d35957fc64c562fb7ef58893196","modified":1649243617791},{"_id":"public/tags/coding/index.html","hash":"3610687ca23cca1fb9f94925357dc64a0a48b8d3","modified":1649243617791},{"_id":"public/tags/持续更新/index.html","hash":"55b09b31096e3d621e876ae5027613957403b24b","modified":1649243617791},{"_id":"public/tags/美食/index.html","hash":"032d42be31239344260be078b9ac19d7192c8446","modified":1649243617791},{"_id":"public/tags/小说/index.html","hash":"493dd438d5f4bfaf6a11db69055fc665366dc43f","modified":1649243617791},{"_id":"public/tags/实验/index.html","hash":"5f2fa31c22cf0e4fd886e9f0d8c52de8aced9a35","modified":1649243617791},{"_id":"public/tags/Python/index.html","hash":"3b0e540956e764315011a0bc97eeefe8b4e6eafa","modified":1649243617791},{"_id":"public/tags/杂谈/index.html","hash":"98492f32e7b558818bd93a8f335592dc4f662442","modified":1649243617791},{"_id":"public/tags/vscode/index.html","hash":"6791bb3bc979007e09bb178a9e8d79eea74a66f9","modified":1649243617791},{"_id":"public/tags/ssh/index.html","hash":"7e983159c95216ed33ea247e6e7d28faa49546b3","modified":1649243617791},{"_id":"public/tags/大数据/index.html","hash":"d640aad3c7abfb2f8b3b5a4cb70685414ccf92fb","modified":1649243617791},{"_id":"public/tags/Java/index.html","hash":"511a519f90df57b373bcc9591f2a9414a7950ecf","modified":1649243617791},{"_id":"public/tags/Hadoop/index.html","hash":"f70876780f6f84ca432e0dad5d2e7ed682d0860a","modified":1649243617791},{"_id":"public/tags/Mapreduce/index.html","hash":"4602bcd92d4162ba04f0c1fbd912cde649c735f8","modified":1649243617791},{"_id":"public/tags/大数据-Java-Hadoop/index.html","hash":"5e5a1d7ee866825fec88c62aa7482311c0acf2b6","modified":1649243617791},{"_id":"public/tags/数学/index.html","hash":"99b6743e23dbac1de04daf2adfab18552bd96052","modified":1649243617791},{"_id":"public/tags/学习/index.html","hash":"5db5097e4fdcfa0d9781b734b6ef5629063a839b","modified":1649243617791},{"_id":"public/2021/12/13/2021-12-13-java/index.html","hash":"67a7ad968a9037793a0f7b857587ed5ea08dc059","modified":1649243617791},{"_id":"public/2021/11/26/2021-11-26-vscode/index.html","hash":"4bd345381936cabffa4a07f50a7ce3efdd9bf314","modified":1649243617791},{"_id":"public/2021/10/26/2021-10-26-regex/index.html","hash":"b090118b82a48c63c8d91b948e020c4b1b6e1dbe","modified":1649243617791},{"_id":"public/2021/10/25/2021-10-25-python/index.html","hash":"fd18f151a2ba1b4ca606a628542cfffb6f9fa731","modified":1649243617791},{"_id":"public/2021/10/07/2021-10-07-pytorch/index.html","hash":"fd4b4cc3156efeb5bc7c9c2c5c06fedf810b6430","modified":1649243617791},{"_id":"public/2021/09/27/2021-09-27-pytorch/index.html","hash":"c292d0fd3dbff77c99865adfba08e092e44ab4fd","modified":1649243617791},{"_id":"public/index.html","hash":"b75350d94c071a037bbc049a79a8cf6648f6b59c","modified":1649243617791},{"_id":"public/page/2/index.html","hash":"ed236f4166a1717d97e537780b130ccdde3244c0","modified":1649243617791},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1649243106893},{"_id":"public/images/2021112604.png","hash":"86b40fadbfd75b7afae3266f54e772a67ec6c6a2","modified":1649243106893},{"_id":"public/images/Linkedin.svg","hash":"c9fef67479d6a9e36dcd93e7bcf396b8dd41be7c","modified":1649243106893},{"_id":"public/images/email.svg","hash":"d347f708ecac0aad59241631a8e20999a098cf1b","modified":1649243106893},{"_id":"public/images/github.svg","hash":"328b059eb62ccdbf789100eb7fa93e0ad88baacd","modified":1649243106893},{"_id":"public/images/pytorch.png","hash":"c2e801b87de4351c4e0ee23aca1f1768b61e2ba4","modified":1649243106893},{"_id":"public/images/qrcode_cslijt.github.io.png","hash":"7242fae717ed02bd23fffcb6044c8a9dbb43aa1c","modified":1649243106893},{"_id":"public/images/屏幕截图_2022-03-26_175646.jpg","hash":"26e1a1351e575419cd154e827f9cf99569e2ff29","modified":1649243106893},{"_id":"public/images/知乎.svg","hash":"13af7dd0fecfa2111e1ad926934e3effdc8b693d","modified":1649243106893},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1649243106893},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1649243106893},{"_id":"public/images/2021112601.png","hash":"e097693047fe4101014ae79b1ae1efc76062b16d","modified":1649243106893},{"_id":"public/images/2021112603.png","hash":"c1052463cdc4375b1472169b592bd64f698152d9","modified":1649243106893},{"_id":"public/images/c995d143ad4bd113d3b5cb035eafa40f4bfb0582.jpg","hash":"cb074d590659e292ce0d605882a3b4b3a1f04dcd","modified":1649243106893},{"_id":"public/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1649243106893},{"_id":"public/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1649243106893},{"_id":"public/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1649243106893},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1649243106893},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1649243106893},{"_id":"public/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1649243106893},{"_id":"public/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1649243106893},{"_id":"public/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1649243106893},{"_id":"public/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1649243106893},{"_id":"public/css/main.css","hash":"4bad146e8788fdc29b97b68b28d0debe66889cf8","modified":1649243106893},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1649243106893},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1649243106893},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1649243106893},{"_id":"public/images/屏幕截图_2022-03-26_175317.jpg","hash":"c4a37962b06c44cf51afe57bc581c74496d5ba33","modified":1649243106893},{"_id":"public/images/2021112602.png","hash":"638027646cd217ce436c31957c7158b7ea914638","modified":1649243106893},{"_id":"public/images/2021121301.png","hash":"15d5d40d42c834bebeacc41495cd204ba3f3234f","modified":1649243106893},{"_id":"public/images/微信图片_20211001171428.jpg","hash":"45a8630d8a32f35c386de921d084d4cc5bf7774b","modified":1649243106893},{"_id":"public/images/avatar.jpg","hash":"15683b2f7f56946cc4639cbd21441ec3e87add35","modified":1649243106893},{"_id":"public/images/IMG_20210925_203119.jpg","hash":"2e9abe7309e6e97c2123978bfab497e46e858902","modified":1649243106893},{"_id":"public/images/IMG_20210925_120635_edit_759134094171144.jpg","hash":"7224ffbd056b66d4a804fcacd514b850b314efa0","modified":1649243106893},{"_id":"public/images/IMG_20210925_210855.jpg","hash":"fa759ff825b95129080a0c904880240177afb55f","modified":1649243106893},{"_id":"public/images/IMG_20210809_091606_edit_932701128736847.jpg","hash":"598dbcf1c15c494679c130432aa0f814c9d5e7b7","modified":1649243106893},{"_id":"public/images/IMG_20210925_210835.jpg","hash":"b31a89e566d3addbb9d74dac9893894984c9fa17","modified":1649243106893},{"_id":"public/images/IMG_20210925_120441.jpg","hash":"a267aeacf92ab8d504ad7b3b315c380e8056456d","modified":1649243106893},{"_id":"public/images/IMG_20210323_120734.jpg","hash":"ba5f11fde2b69fa608712e6b9939df96174cecc1","modified":1649243106893},{"_id":"public/images/微信图片_20211001161414.jpg","hash":"1878e9bac84ead0d7444adeb7b4c3f36b63e4c1a","modified":1649243106893},{"_id":"public/images/IMG_20210321_171950.jpg","hash":"af85f769e58663ec27832b75c01724c16a963172","modified":1649243106893},{"_id":"public/images/IMG_20210405_134224.jpg","hash":"3eeaa0239bfff2a50721fa503ac1c607bf0a4471","modified":1649243106893},{"_id":"public/images/IMG_20210325_104740.jpg","hash":"55ab15bbe191dce47fa98b7064740b4d86aa8d7a","modified":1649243106893},{"_id":"public/images/IMG_20210405_134319.jpg","hash":"9b3c658843fa18464120a82be9431e0c881b8e06","modified":1649243106893},{"_id":"public/images/background.jpg","hash":"9b3c658843fa18464120a82be9431e0c881b8e06","modified":1649243106893}],"Category":[],"Data":[],"Page":[{"title":"categories","date":"2022-04-06T09:15:20.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2022-04-06 17:15:20\ntype: \"categories\"\n---\n","updated":"2022-04-06T09:19:59.583Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cl1ngri8a0000hsv95tvyhcnp","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","date":"2022-04-06T09:14:43.000Z","type":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2022-04-06 17:14:43\ntype: \"about\"\n---\n","updated":"2022-04-06T09:20:03.024Z","path":"about/index.html","comments":1,"layout":"page","_id":"cl1ngri8e0002hsv93vow3rxo","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2022-04-06T09:15:01.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2022-04-06 17:15:01\ntype: \"tags\"\n---\n","updated":"2022-04-06T09:19:55.845Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cl1ngri8i0005hsv90wglh78p","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!--more-->\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!--more-->\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2022-04-03T09:03:57.332Z","updated":"2022-04-06T09:11:36.665Z","_id":"cl1j28gkf0000kgv942pd74w8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<span id=\"more\"></span>\n\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>","more":"<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>"},{"title":"读Paper的一些感想记录","date":"2022-02-21T16:00:00.000Z","key":"paper20220222","_content":"\n最近一直在读paper。结合之前与老师、前辈、朋友讨论的经历，在此总结读paper的一些感想记录。这既是我自己的反思与总结，也可以为大家提供一些经验参考。\n\n<!--more-->\n## 读写paper\n在开始一个研究项目前，往往需要阅读大量领域内的paper。这一方面是为了快速了解最新研究进展，寻找idea并且避免工作重复；另一方面是为了学习优秀paper的写作风格。毕竟，读者在读你的Intro之前，并不知道你的工作内容是什么。因此在优秀的paper中，作者会让读者在进入正文之前快速了解：1. 本文研究的是什么问题；2. 该问题有什么研究挑战； 3. 我们怎样一一解决这些挑战。一言以蔽之，让读者快速了解研究工作的价值。然而，虽然优秀的paper篇篇相似，不行的paper各有各的缺点，但即便是优秀的paper也浩如烟海。因此，高效地阅读paper是一个重要的能力。为此，我主要总结了以下几点：\n1. 外语水平：基本语言素养\n2. 注意力分配：各个章节注意力占比\n3. 带着问题去读\n\n### 外语水平\n就个人经验而言，在cs领域，绝大部分paper用英文写成。因此高效阅读paper的基本素养便是足够过关的英文水平。\n\n首先，专业paper需要大量的词汇积累，既包括日常常见词汇，也包括领域内的专业词汇。积累词汇能极大减少查词典的时间，因此无疑能提升阅读paper效率。其次，要锻炼阅读长难句、复杂句式的能力（虽然写论文严重不建议用长难句）。如果paper作者来自于英语国家，或者研究领域在教育学、心理学等不那么理工科的专业，那么对应的英文paper常常会出现三四行一句的长难句。遇到这种情况时，我一般会手动将长难句化解为几个简单的短句，然后结合上下文分别阅读。虽然cs领域的论文鲜有长难句，但目前机器学习和其他领域的交叉十分普遍，因此免不了阅读其他领域的论文，故而必须适应阅读这类复杂句式的能力。\n\n整体而言，个人认为六级550+或托福100+是量化的必要水平（废话，国外研究生申请很多是这个bar）。在此之上，还需要大量阅读本领域的文章，从而内化paper的写作风格、积累专业表达。这样在阅读新Paper时便能快速上手。\n\n### 注意力分配\n初读paper时，我往往恨不得一字一句地都读下去，从abstract到intro到model到experiment，每一个部分都打破沙锅问到底。**然而**，这是一个十分低效的阅读策略。就个人经验和老师前辈们的指导而言，注意力应该多放在intro上——这一章节具体介绍了paper主要的研究方向、研究问题和解决方法。如果阅读过程中能够快速理解问题的价值和研究贡献，那么就考虑读model和experiment部分。能发出来的paper，模型结构基本七七八八，实验效果都不会差。因此没有必要花太多时间在研究模型和实验细节部分。对于个人而言，这两部分的阅读主要起到启发灵感的作用——比如模型的设计有无借鉴；实验的组织安排、性能评测指标能否参考使用等。如某友所言，写paper不是写技术文档，更不是写实验报告。创新永远是第一位的，而这一点一定会在intro中展示。\n\n总结而言，读paper的注意力分配策略实质上是一个自顶向下的层次化(hierarchical)方法。第一层，快速阅读abstract和intro，了解研究问题和创新点。第二层，根据第一层的阅读结果动态选择继续细读或快速浏览或放弃。这一自顶向下、自粗向细的方法能极大提升阅读效率，并将注意力放在与自己研究内容相关的paper上。\n\n### 带着问题去读\n需要明白的是，任何一项研究工作，都需要一个动机(motivation)——每一篇paper都为解决某些专业问题而写成。而paper的创新点，则构成了解决问题的方法。不仅写paper是问题导向的，读paper也是问题导向的。如果不带着问题去读，往往会有头无尾，晕头转向——为什么这里要用LSTM而不是FC？为什么要使用强理论假设？相反，带着问题去读，逻辑便能和作者的思维贯通，也有助于读者达成自己的阅读目的（如研究paper是怎么解决问题的，从而启发灵感）。\n\n在读写论文的问题上，我曾和一位在国际学校学习过的好友聊过——他的课程中包含大量科技写作的训练。友人建议用\"5W\"法阅读和写作。这里进一步参考[百度百科](https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597)，总结5W2H法的问题提出方法：\n\n#### 5W2H\n- WHAT——是什么？目的是什么？做什么工作？\n- WHY——为什么要做？可不可以不做？有没有替代方案？\n- WHO——谁？由谁来做？\n- WHEN——何时？什么时间做？什么时机最适宜？\n- WHERE——何处？在哪里做？\n- HOW ——怎么做？如何提高效率？如何实施？方法是什么？\n- HOW MUCH——多少？做到什么程度？数量如何？质量水平如何？费用产出如何？\n\n在阅读论文中，可以灵活地使用5W2H法提出和跟踪问题。带着问题去读，能帮助理清paper的逻辑和创新点，达到事半功倍的阅读效果。\n\n最后，这里推荐一篇范文——[《一种加辣椒的番茄炒蛋》](https://zhuanlan.zhihu.com/p/433237905)，可以从作者的角度了解一篇paper的逻辑是如何组织的。\n\n## 参考文献\n1. [一种加辣椒的番茄炒蛋.Jingwei Huang.CVPR 9999 Best Paper](https://zhuanlan.zhihu.com/p/433237905)\n2. [技术之外(一).Yuandong Tian](https://zhuanlan.zhihu.com/p/469717875)\n3. [5W2H分析法.百度百科](https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597)","source":"_posts/2022-02-22-paper.md","raw":"---\ntitle: 读Paper的一些感想记录\ndate: 2022-02-22\ntags: 科研\nkey: paper20220222\n---\n\n最近一直在读paper。结合之前与老师、前辈、朋友讨论的经历，在此总结读paper的一些感想记录。这既是我自己的反思与总结，也可以为大家提供一些经验参考。\n\n<!--more-->\n## 读写paper\n在开始一个研究项目前，往往需要阅读大量领域内的paper。这一方面是为了快速了解最新研究进展，寻找idea并且避免工作重复；另一方面是为了学习优秀paper的写作风格。毕竟，读者在读你的Intro之前，并不知道你的工作内容是什么。因此在优秀的paper中，作者会让读者在进入正文之前快速了解：1. 本文研究的是什么问题；2. 该问题有什么研究挑战； 3. 我们怎样一一解决这些挑战。一言以蔽之，让读者快速了解研究工作的价值。然而，虽然优秀的paper篇篇相似，不行的paper各有各的缺点，但即便是优秀的paper也浩如烟海。因此，高效地阅读paper是一个重要的能力。为此，我主要总结了以下几点：\n1. 外语水平：基本语言素养\n2. 注意力分配：各个章节注意力占比\n3. 带着问题去读\n\n### 外语水平\n就个人经验而言，在cs领域，绝大部分paper用英文写成。因此高效阅读paper的基本素养便是足够过关的英文水平。\n\n首先，专业paper需要大量的词汇积累，既包括日常常见词汇，也包括领域内的专业词汇。积累词汇能极大减少查词典的时间，因此无疑能提升阅读paper效率。其次，要锻炼阅读长难句、复杂句式的能力（虽然写论文严重不建议用长难句）。如果paper作者来自于英语国家，或者研究领域在教育学、心理学等不那么理工科的专业，那么对应的英文paper常常会出现三四行一句的长难句。遇到这种情况时，我一般会手动将长难句化解为几个简单的短句，然后结合上下文分别阅读。虽然cs领域的论文鲜有长难句，但目前机器学习和其他领域的交叉十分普遍，因此免不了阅读其他领域的论文，故而必须适应阅读这类复杂句式的能力。\n\n整体而言，个人认为六级550+或托福100+是量化的必要水平（废话，国外研究生申请很多是这个bar）。在此之上，还需要大量阅读本领域的文章，从而内化paper的写作风格、积累专业表达。这样在阅读新Paper时便能快速上手。\n\n### 注意力分配\n初读paper时，我往往恨不得一字一句地都读下去，从abstract到intro到model到experiment，每一个部分都打破沙锅问到底。**然而**，这是一个十分低效的阅读策略。就个人经验和老师前辈们的指导而言，注意力应该多放在intro上——这一章节具体介绍了paper主要的研究方向、研究问题和解决方法。如果阅读过程中能够快速理解问题的价值和研究贡献，那么就考虑读model和experiment部分。能发出来的paper，模型结构基本七七八八，实验效果都不会差。因此没有必要花太多时间在研究模型和实验细节部分。对于个人而言，这两部分的阅读主要起到启发灵感的作用——比如模型的设计有无借鉴；实验的组织安排、性能评测指标能否参考使用等。如某友所言，写paper不是写技术文档，更不是写实验报告。创新永远是第一位的，而这一点一定会在intro中展示。\n\n总结而言，读paper的注意力分配策略实质上是一个自顶向下的层次化(hierarchical)方法。第一层，快速阅读abstract和intro，了解研究问题和创新点。第二层，根据第一层的阅读结果动态选择继续细读或快速浏览或放弃。这一自顶向下、自粗向细的方法能极大提升阅读效率，并将注意力放在与自己研究内容相关的paper上。\n\n### 带着问题去读\n需要明白的是，任何一项研究工作，都需要一个动机(motivation)——每一篇paper都为解决某些专业问题而写成。而paper的创新点，则构成了解决问题的方法。不仅写paper是问题导向的，读paper也是问题导向的。如果不带着问题去读，往往会有头无尾，晕头转向——为什么这里要用LSTM而不是FC？为什么要使用强理论假设？相反，带着问题去读，逻辑便能和作者的思维贯通，也有助于读者达成自己的阅读目的（如研究paper是怎么解决问题的，从而启发灵感）。\n\n在读写论文的问题上，我曾和一位在国际学校学习过的好友聊过——他的课程中包含大量科技写作的训练。友人建议用\"5W\"法阅读和写作。这里进一步参考[百度百科](https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597)，总结5W2H法的问题提出方法：\n\n#### 5W2H\n- WHAT——是什么？目的是什么？做什么工作？\n- WHY——为什么要做？可不可以不做？有没有替代方案？\n- WHO——谁？由谁来做？\n- WHEN——何时？什么时间做？什么时机最适宜？\n- WHERE——何处？在哪里做？\n- HOW ——怎么做？如何提高效率？如何实施？方法是什么？\n- HOW MUCH——多少？做到什么程度？数量如何？质量水平如何？费用产出如何？\n\n在阅读论文中，可以灵活地使用5W2H法提出和跟踪问题。带着问题去读，能帮助理清paper的逻辑和创新点，达到事半功倍的阅读效果。\n\n最后，这里推荐一篇范文——[《一种加辣椒的番茄炒蛋》](https://zhuanlan.zhihu.com/p/433237905)，可以从作者的角度了解一篇paper的逻辑是如何组织的。\n\n## 参考文献\n1. [一种加辣椒的番茄炒蛋.Jingwei Huang.CVPR 9999 Best Paper](https://zhuanlan.zhihu.com/p/433237905)\n2. [技术之外(一).Yuandong Tian](https://zhuanlan.zhihu.com/p/469717875)\n3. [5W2H分析法.百度百科](https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597)","slug":"2022-02-22-paper","published":1,"updated":"2022-04-06T09:50:58.025Z","_id":"cl1nc5d0d0000fwv95tabbjmx","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近一直在读paper。结合之前与老师、前辈、朋友讨论的经历，在此总结读paper的一些感想记录。这既是我自己的反思与总结，也可以为大家提供一些经验参考。</p>\n<span id=\"more\"></span>\n<h2 id=\"读写paper\"><a href=\"#读写paper\" class=\"headerlink\" title=\"读写paper\"></a>读写paper</h2><p>在开始一个研究项目前，往往需要阅读大量领域内的paper。这一方面是为了快速了解最新研究进展，寻找idea并且避免工作重复；另一方面是为了学习优秀paper的写作风格。毕竟，读者在读你的Intro之前，并不知道你的工作内容是什么。因此在优秀的paper中，作者会让读者在进入正文之前快速了解：1. 本文研究的是什么问题；2. 该问题有什么研究挑战； 3. 我们怎样一一解决这些挑战。一言以蔽之，让读者快速了解研究工作的价值。然而，虽然优秀的paper篇篇相似，不行的paper各有各的缺点，但即便是优秀的paper也浩如烟海。因此，高效地阅读paper是一个重要的能力。为此，我主要总结了以下几点：</p>\n<ol>\n<li>外语水平：基本语言素养</li>\n<li>注意力分配：各个章节注意力占比</li>\n<li>带着问题去读</li>\n</ol>\n<h3 id=\"外语水平\"><a href=\"#外语水平\" class=\"headerlink\" title=\"外语水平\"></a>外语水平</h3><p>就个人经验而言，在cs领域，绝大部分paper用英文写成。因此高效阅读paper的基本素养便是足够过关的英文水平。</p>\n<p>首先，专业paper需要大量的词汇积累，既包括日常常见词汇，也包括领域内的专业词汇。积累词汇能极大减少查词典的时间，因此无疑能提升阅读paper效率。其次，要锻炼阅读长难句、复杂句式的能力（虽然写论文严重不建议用长难句）。如果paper作者来自于英语国家，或者研究领域在教育学、心理学等不那么理工科的专业，那么对应的英文paper常常会出现三四行一句的长难句。遇到这种情况时，我一般会手动将长难句化解为几个简单的短句，然后结合上下文分别阅读。虽然cs领域的论文鲜有长难句，但目前机器学习和其他领域的交叉十分普遍，因此免不了阅读其他领域的论文，故而必须适应阅读这类复杂句式的能力。</p>\n<p>整体而言，个人认为六级550+或托福100+是量化的必要水平（废话，国外研究生申请很多是这个bar）。在此之上，还需要大量阅读本领域的文章，从而内化paper的写作风格、积累专业表达。这样在阅读新Paper时便能快速上手。</p>\n<h3 id=\"注意力分配\"><a href=\"#注意力分配\" class=\"headerlink\" title=\"注意力分配\"></a>注意力分配</h3><p>初读paper时，我往往恨不得一字一句地都读下去，从abstract到intro到model到experiment，每一个部分都打破沙锅问到底。<strong>然而</strong>，这是一个十分低效的阅读策略。就个人经验和老师前辈们的指导而言，注意力应该多放在intro上——这一章节具体介绍了paper主要的研究方向、研究问题和解决方法。如果阅读过程中能够快速理解问题的价值和研究贡献，那么就考虑读model和experiment部分。能发出来的paper，模型结构基本七七八八，实验效果都不会差。因此没有必要花太多时间在研究模型和实验细节部分。对于个人而言，这两部分的阅读主要起到启发灵感的作用——比如模型的设计有无借鉴；实验的组织安排、性能评测指标能否参考使用等。如某友所言，写paper不是写技术文档，更不是写实验报告。创新永远是第一位的，而这一点一定会在intro中展示。</p>\n<p>总结而言，读paper的注意力分配策略实质上是一个自顶向下的层次化(hierarchical)方法。第一层，快速阅读abstract和intro，了解研究问题和创新点。第二层，根据第一层的阅读结果动态选择继续细读或快速浏览或放弃。这一自顶向下、自粗向细的方法能极大提升阅读效率，并将注意力放在与自己研究内容相关的paper上。</p>\n<h3 id=\"带着问题去读\"><a href=\"#带着问题去读\" class=\"headerlink\" title=\"带着问题去读\"></a>带着问题去读</h3><p>需要明白的是，任何一项研究工作，都需要一个动机(motivation)——每一篇paper都为解决某些专业问题而写成。而paper的创新点，则构成了解决问题的方法。不仅写paper是问题导向的，读paper也是问题导向的。如果不带着问题去读，往往会有头无尾，晕头转向——为什么这里要用LSTM而不是FC？为什么要使用强理论假设？相反，带着问题去读，逻辑便能和作者的思维贯通，也有助于读者达成自己的阅读目的（如研究paper是怎么解决问题的，从而启发灵感）。</p>\n<p>在读写论文的问题上，我曾和一位在国际学校学习过的好友聊过——他的课程中包含大量科技写作的训练。友人建议用”5W”法阅读和写作。这里进一步参考<a href=\"https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597\">百度百科</a>，总结5W2H法的问题提出方法：</p>\n<h4 id=\"5W2H\"><a href=\"#5W2H\" class=\"headerlink\" title=\"5W2H\"></a>5W2H</h4><ul>\n<li>WHAT——是什么？目的是什么？做什么工作？</li>\n<li>WHY——为什么要做？可不可以不做？有没有替代方案？</li>\n<li>WHO——谁？由谁来做？</li>\n<li>WHEN——何时？什么时间做？什么时机最适宜？</li>\n<li>WHERE——何处？在哪里做？</li>\n<li>HOW ——怎么做？如何提高效率？如何实施？方法是什么？</li>\n<li>HOW MUCH——多少？做到什么程度？数量如何？质量水平如何？费用产出如何？</li>\n</ul>\n<p>在阅读论文中，可以灵活地使用5W2H法提出和跟踪问题。带着问题去读，能帮助理清paper的逻辑和创新点，达到事半功倍的阅读效果。</p>\n<p>最后，这里推荐一篇范文——<a href=\"https://zhuanlan.zhihu.com/p/433237905\">《一种加辣椒的番茄炒蛋》</a>，可以从作者的角度了解一篇paper的逻辑是如何组织的。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li><a href=\"https://zhuanlan.zhihu.com/p/433237905\">一种加辣椒的番茄炒蛋.Jingwei Huang.CVPR 9999 Best Paper</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/469717875\">技术之外(一).Yuandong Tian</a></li>\n<li><a href=\"https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597\">5W2H分析法.百度百科</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>最近一直在读paper。结合之前与老师、前辈、朋友讨论的经历，在此总结读paper的一些感想记录。这既是我自己的反思与总结，也可以为大家提供一些经验参考。</p>","more":"<h2 id=\"读写paper\"><a href=\"#读写paper\" class=\"headerlink\" title=\"读写paper\"></a>读写paper</h2><p>在开始一个研究项目前，往往需要阅读大量领域内的paper。这一方面是为了快速了解最新研究进展，寻找idea并且避免工作重复；另一方面是为了学习优秀paper的写作风格。毕竟，读者在读你的Intro之前，并不知道你的工作内容是什么。因此在优秀的paper中，作者会让读者在进入正文之前快速了解：1. 本文研究的是什么问题；2. 该问题有什么研究挑战； 3. 我们怎样一一解决这些挑战。一言以蔽之，让读者快速了解研究工作的价值。然而，虽然优秀的paper篇篇相似，不行的paper各有各的缺点，但即便是优秀的paper也浩如烟海。因此，高效地阅读paper是一个重要的能力。为此，我主要总结了以下几点：</p>\n<ol>\n<li>外语水平：基本语言素养</li>\n<li>注意力分配：各个章节注意力占比</li>\n<li>带着问题去读</li>\n</ol>\n<h3 id=\"外语水平\"><a href=\"#外语水平\" class=\"headerlink\" title=\"外语水平\"></a>外语水平</h3><p>就个人经验而言，在cs领域，绝大部分paper用英文写成。因此高效阅读paper的基本素养便是足够过关的英文水平。</p>\n<p>首先，专业paper需要大量的词汇积累，既包括日常常见词汇，也包括领域内的专业词汇。积累词汇能极大减少查词典的时间，因此无疑能提升阅读paper效率。其次，要锻炼阅读长难句、复杂句式的能力（虽然写论文严重不建议用长难句）。如果paper作者来自于英语国家，或者研究领域在教育学、心理学等不那么理工科的专业，那么对应的英文paper常常会出现三四行一句的长难句。遇到这种情况时，我一般会手动将长难句化解为几个简单的短句，然后结合上下文分别阅读。虽然cs领域的论文鲜有长难句，但目前机器学习和其他领域的交叉十分普遍，因此免不了阅读其他领域的论文，故而必须适应阅读这类复杂句式的能力。</p>\n<p>整体而言，个人认为六级550+或托福100+是量化的必要水平（废话，国外研究生申请很多是这个bar）。在此之上，还需要大量阅读本领域的文章，从而内化paper的写作风格、积累专业表达。这样在阅读新Paper时便能快速上手。</p>\n<h3 id=\"注意力分配\"><a href=\"#注意力分配\" class=\"headerlink\" title=\"注意力分配\"></a>注意力分配</h3><p>初读paper时，我往往恨不得一字一句地都读下去，从abstract到intro到model到experiment，每一个部分都打破沙锅问到底。<strong>然而</strong>，这是一个十分低效的阅读策略。就个人经验和老师前辈们的指导而言，注意力应该多放在intro上——这一章节具体介绍了paper主要的研究方向、研究问题和解决方法。如果阅读过程中能够快速理解问题的价值和研究贡献，那么就考虑读model和experiment部分。能发出来的paper，模型结构基本七七八八，实验效果都不会差。因此没有必要花太多时间在研究模型和实验细节部分。对于个人而言，这两部分的阅读主要起到启发灵感的作用——比如模型的设计有无借鉴；实验的组织安排、性能评测指标能否参考使用等。如某友所言，写paper不是写技术文档，更不是写实验报告。创新永远是第一位的，而这一点一定会在intro中展示。</p>\n<p>总结而言，读paper的注意力分配策略实质上是一个自顶向下的层次化(hierarchical)方法。第一层，快速阅读abstract和intro，了解研究问题和创新点。第二层，根据第一层的阅读结果动态选择继续细读或快速浏览或放弃。这一自顶向下、自粗向细的方法能极大提升阅读效率，并将注意力放在与自己研究内容相关的paper上。</p>\n<h3 id=\"带着问题去读\"><a href=\"#带着问题去读\" class=\"headerlink\" title=\"带着问题去读\"></a>带着问题去读</h3><p>需要明白的是，任何一项研究工作，都需要一个动机(motivation)——每一篇paper都为解决某些专业问题而写成。而paper的创新点，则构成了解决问题的方法。不仅写paper是问题导向的，读paper也是问题导向的。如果不带着问题去读，往往会有头无尾，晕头转向——为什么这里要用LSTM而不是FC？为什么要使用强理论假设？相反，带着问题去读，逻辑便能和作者的思维贯通，也有助于读者达成自己的阅读目的（如研究paper是怎么解决问题的，从而启发灵感）。</p>\n<p>在读写论文的问题上，我曾和一位在国际学校学习过的好友聊过——他的课程中包含大量科技写作的训练。友人建议用”5W”法阅读和写作。这里进一步参考<a href=\"https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597\">百度百科</a>，总结5W2H法的问题提出方法：</p>\n<h4 id=\"5W2H\"><a href=\"#5W2H\" class=\"headerlink\" title=\"5W2H\"></a>5W2H</h4><ul>\n<li>WHAT——是什么？目的是什么？做什么工作？</li>\n<li>WHY——为什么要做？可不可以不做？有没有替代方案？</li>\n<li>WHO——谁？由谁来做？</li>\n<li>WHEN——何时？什么时间做？什么时机最适宜？</li>\n<li>WHERE——何处？在哪里做？</li>\n<li>HOW ——怎么做？如何提高效率？如何实施？方法是什么？</li>\n<li>HOW MUCH——多少？做到什么程度？数量如何？质量水平如何？费用产出如何？</li>\n</ul>\n<p>在阅读论文中，可以灵活地使用5W2H法提出和跟踪问题。带着问题去读，能帮助理清paper的逻辑和创新点，达到事半功倍的阅读效果。</p>\n<p>最后，这里推荐一篇范文——<a href=\"https://zhuanlan.zhihu.com/p/433237905\">《一种加辣椒的番茄炒蛋》</a>，可以从作者的角度了解一篇paper的逻辑是如何组织的。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ol>\n<li><a href=\"https://zhuanlan.zhihu.com/p/433237905\">一种加辣椒的番茄炒蛋.Jingwei Huang.CVPR 9999 Best Paper</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/469717875\">技术之外(一).Yuandong Tian</a></li>\n<li><a href=\"https://baike.baidu.com/item/5W2H%E5%88%86%E6%9E%90%E6%B3%95/8111597\">5W2H分析法.百度百科</a></li>\n</ol>"},{"title":"一些杂谈.2","author":"LiJT","date":"2022-03-25T16:00:00.000Z","key":"remind2022032601","sharing":true,"_content":"\n本科期间上的统计类课程是多么美好的回忆。\n\n<!--more-->\n\n最近回炉统计学的一些分析与检验方法，翻到了ynyang老师的多元回归分析的讲义。\n\nynyang老师的课深入浅出，是给我印象最深，也是让我收获最大的统计类课程。从矩阵变换的技巧，到PCA，到SVD，甚至到谱聚类，PageRank算法的启蒙，都是在ynyang老师的课上完成的。尤其是SVD，当初花书和西瓜书翻了个遍也不知所云。但是ynyang老师的课却让我醍醐灌顶-SVD是对矩阵的最优低秩分解。\n\n![SVD1](https://cslijt.github.io/LiJT-Daily/images/屏幕截图_202022-03-26_175317.jpg)\n\n如今想来，本科四年在学习上的遗憾有二：\n1. 大三由于畏难，退了ynyang老师的回归分析的课。错过了一个亿的知识。\n2. 铁憨憨，没有和yang老师保持联系。\n\n\n\n\n","source":"_posts/2022-03-26-remind.md","raw":"---\ntitle: 一些杂谈.2\nauthor: LiJT\ndate: 2022-03-26\ntags: \n  - 数学 \n  - 杂谈\nkey: remind2022032601\nsharing: true\n---\n\n本科期间上的统计类课程是多么美好的回忆。\n\n<!--more-->\n\n最近回炉统计学的一些分析与检验方法，翻到了ynyang老师的多元回归分析的讲义。\n\nynyang老师的课深入浅出，是给我印象最深，也是让我收获最大的统计类课程。从矩阵变换的技巧，到PCA，到SVD，甚至到谱聚类，PageRank算法的启蒙，都是在ynyang老师的课上完成的。尤其是SVD，当初花书和西瓜书翻了个遍也不知所云。但是ynyang老师的课却让我醍醐灌顶-SVD是对矩阵的最优低秩分解。\n\n![SVD1](https://cslijt.github.io/LiJT-Daily/images/屏幕截图_202022-03-26_175317.jpg)\n\n如今想来，本科四年在学习上的遗憾有二：\n1. 大三由于畏难，退了ynyang老师的回归分析的课。错过了一个亿的知识。\n2. 铁憨憨，没有和yang老师保持联系。\n\n\n\n\n","slug":"2022-03-26-remind","published":1,"updated":"2022-04-06T09:51:09.106Z","_id":"cl1nc5d0l0003fwv9a7dvaox0","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本科期间上的统计类课程是多么美好的回忆。</p>\n<span id=\"more\"></span>\n\n<p>最近回炉统计学的一些分析与检验方法，翻到了ynyang老师的多元回归分析的讲义。</p>\n<p>ynyang老师的课深入浅出，是给我印象最深，也是让我收获最大的统计类课程。从矩阵变换的技巧，到PCA，到SVD，甚至到谱聚类，PageRank算法的启蒙，都是在ynyang老师的课上完成的。尤其是SVD，当初花书和西瓜书翻了个遍也不知所云。但是ynyang老师的课却让我醍醐灌顶-SVD是对矩阵的最优低秩分解。</p>\n<p><img src=\"https://cslijt.github.io/LiJT-Daily/images/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_202022-03-26_175317.jpg\" alt=\"SVD1\"></p>\n<p>如今想来，本科四年在学习上的遗憾有二：</p>\n<ol>\n<li>大三由于畏难，退了ynyang老师的回归分析的课。错过了一个亿的知识。</li>\n<li>铁憨憨，没有和yang老师保持联系。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>本科期间上的统计类课程是多么美好的回忆。</p>","more":"<p>最近回炉统计学的一些分析与检验方法，翻到了ynyang老师的多元回归分析的讲义。</p>\n<p>ynyang老师的课深入浅出，是给我印象最深，也是让我收获最大的统计类课程。从矩阵变换的技巧，到PCA，到SVD，甚至到谱聚类，PageRank算法的启蒙，都是在ynyang老师的课上完成的。尤其是SVD，当初花书和西瓜书翻了个遍也不知所云。但是ynyang老师的课却让我醍醐灌顶-SVD是对矩阵的最优低秩分解。</p>\n<p><img src=\"https://cslijt.github.io/LiJT-Daily/images/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_202022-03-26_175317.jpg\" alt=\"SVD1\"></p>\n<p>如今想来，本科四年在学习上的遗憾有二：</p>\n<ol>\n<li>大三由于畏难，退了ynyang老师的回归分析的课。错过了一个亿的知识。</li>\n<li>铁憨憨，没有和yang老师保持联系。</li>\n</ol>"},{"title":"最近的学习计划","author":"LiJT","date":"2022-03-31T16:00:00.000Z","show_author_profile":true,"key":"plan20220401","sharing":true,"_content":"\n记录一些出于兴趣或出于工程需要，最近计划系统学习的一些知识。\n\n相当于立一个flag.\n<!--more-->\n\n## CS\n- git\n  - 不要问一个学了四年CS(1年CS+3年DS)的人为什么要学git. 在此之前，git只是作为我管理代码的工具。仅仅到达“知其然”，而非知其“所以然”的程度。很多功能先搜先用、现学现卖，却不知其原理，不知其变化的用法。因此打算系统学习一下git，彻底（七七八八）掌握其各种功能的原理和用法。\n- 编译原理\n  - 3年DS跳过了编译原理这门课，实在是大不幸。考虑到最近code intelligence大火，以及自己可能整活的需要，计划学习编译原理。这一科目的学习以实践先行，理论后补的方法，免得满嘴跑火车却连语法树（听说的）都不会写。\n- GAN\n  - GAN就是干！\n\n## Stats\n- 各种参数优化方法\n  - 当初机器学习没学好，统计学里的参数优化方法不明所以。极大似然估计、贝叶斯推断、MCMC、MCMC里的Metropolis、Gibbs... 都需要补足\n  - 亲身体会：优化方法如果只看原理而没有具体案例，则原理很难理解透彻。需要结合具体的模型进行学习\n  - 最费解的还是EM算法....","source":"_posts/2022-04-01-plan.md","raw":"---\ntitle: 最近的学习计划\nauthor: LiJT\ndate: 2022-04-01\nshow_author_profile: true\ntags: \n  - 科研\n  - 学习\nkey: plan20220401\nsharing: true\n---\n\n记录一些出于兴趣或出于工程需要，最近计划系统学习的一些知识。\n\n相当于立一个flag.\n<!--more-->\n\n## CS\n- git\n  - 不要问一个学了四年CS(1年CS+3年DS)的人为什么要学git. 在此之前，git只是作为我管理代码的工具。仅仅到达“知其然”，而非知其“所以然”的程度。很多功能先搜先用、现学现卖，却不知其原理，不知其变化的用法。因此打算系统学习一下git，彻底（七七八八）掌握其各种功能的原理和用法。\n- 编译原理\n  - 3年DS跳过了编译原理这门课，实在是大不幸。考虑到最近code intelligence大火，以及自己可能整活的需要，计划学习编译原理。这一科目的学习以实践先行，理论后补的方法，免得满嘴跑火车却连语法树（听说的）都不会写。\n- GAN\n  - GAN就是干！\n\n## Stats\n- 各种参数优化方法\n  - 当初机器学习没学好，统计学里的参数优化方法不明所以。极大似然估计、贝叶斯推断、MCMC、MCMC里的Metropolis、Gibbs... 都需要补足\n  - 亲身体会：优化方法如果只看原理而没有具体案例，则原理很难理解透彻。需要结合具体的模型进行学习\n  - 最费解的还是EM算法....","slug":"2022-04-01-plan","published":1,"updated":"2022-04-06T09:51:18.870Z","_id":"cl1nc5d0p0006fwv95vgjdnt5","comments":1,"layout":"post","photos":[],"link":"","content":"<p>记录一些出于兴趣或出于工程需要，最近计划系统学习的一些知识。</p>\n<p>相当于立一个flag.</p>\n<span id=\"more\"></span>\n\n<h2 id=\"CS\"><a href=\"#CS\" class=\"headerlink\" title=\"CS\"></a>CS</h2><ul>\n<li>git<ul>\n<li>不要问一个学了四年CS(1年CS+3年DS)的人为什么要学git. 在此之前，git只是作为我管理代码的工具。仅仅到达“知其然”，而非知其“所以然”的程度。很多功能先搜先用、现学现卖，却不知其原理，不知其变化的用法。因此打算系统学习一下git，彻底（七七八八）掌握其各种功能的原理和用法。</li>\n</ul>\n</li>\n<li>编译原理<ul>\n<li>3年DS跳过了编译原理这门课，实在是大不幸。考虑到最近code intelligence大火，以及自己可能整活的需要，计划学习编译原理。这一科目的学习以实践先行，理论后补的方法，免得满嘴跑火车却连语法树（听说的）都不会写。</li>\n</ul>\n</li>\n<li>GAN<ul>\n<li>GAN就是干！</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Stats\"><a href=\"#Stats\" class=\"headerlink\" title=\"Stats\"></a>Stats</h2><ul>\n<li>各种参数优化方法<ul>\n<li>当初机器学习没学好，统计学里的参数优化方法不明所以。极大似然估计、贝叶斯推断、MCMC、MCMC里的Metropolis、Gibbs… 都需要补足</li>\n<li>亲身体会：优化方法如果只看原理而没有具体案例，则原理很难理解透彻。需要结合具体的模型进行学习</li>\n<li>最费解的还是EM算法….</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>记录一些出于兴趣或出于工程需要，最近计划系统学习的一些知识。</p>\n<p>相当于立一个flag.</p>","more":"<h2 id=\"CS\"><a href=\"#CS\" class=\"headerlink\" title=\"CS\"></a>CS</h2><ul>\n<li>git<ul>\n<li>不要问一个学了四年CS(1年CS+3年DS)的人为什么要学git. 在此之前，git只是作为我管理代码的工具。仅仅到达“知其然”，而非知其“所以然”的程度。很多功能先搜先用、现学现卖，却不知其原理，不知其变化的用法。因此打算系统学习一下git，彻底（七七八八）掌握其各种功能的原理和用法。</li>\n</ul>\n</li>\n<li>编译原理<ul>\n<li>3年DS跳过了编译原理这门课，实在是大不幸。考虑到最近code intelligence大火，以及自己可能整活的需要，计划学习编译原理。这一科目的学习以实践先行，理论后补的方法，免得满嘴跑火车却连语法树（听说的）都不会写。</li>\n</ul>\n</li>\n<li>GAN<ul>\n<li>GAN就是干！</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Stats\"><a href=\"#Stats\" class=\"headerlink\" title=\"Stats\"></a>Stats</h2><ul>\n<li>各种参数优化方法<ul>\n<li>当初机器学习没学好，统计学里的参数优化方法不明所以。极大似然估计、贝叶斯推断、MCMC、MCMC里的Metropolis、Gibbs… 都需要补足</li>\n<li>亲身体会：优化方法如果只看原理而没有具体案例，则原理很难理解透彻。需要结合具体的模型进行学习</li>\n<li>最费解的还是EM算法….</li>\n</ul>\n</li>\n</ul>"},{"title":"PyTorch踩坑记录（持续更新）","author":"LiJT","date":"2021-09-26T16:00:00.000Z","key":"pytorch20210927","_content":"\n本篇记录使用pytorch过程中踩到的各种坑！\n<!--more-->\n\n## 声明损失函数时忘记加括号\n```python\nloss_fn = nn.BCELoss # 应该是 nn.BCELoss()\n\n>> RuntimeError: bool value of Tensor with more than one value is ambiguous\n```\n\n## 通过索引赋值后，梯度还能正常反向传播吗？\n- 答案：__能__.\n\n### 验证代码\n\n```python\nimport torch \n\ndef main():\n    # x 是输入张量，可求梯度\n    x = torch.rand(4)\n    x.requires_grad_(True)\n    # cache 是中间张量，将x赋给cache\n    cache = torch.zeros(3,4)\n    optim = torch.optim.Adam([x],lr=1e-2)\n    for i in range(10):\n        # 按索引赋值\n        cache[1,:] = x \n        result = cache * 2\n        result = result.view(-1)\n        # 求损失函数\n        sum = torch.sum(result, dim = 0)\n        print(x.data)\n        optim.zero_grad()\n        sum.backward(retain_graph = True)\n        optim.step()\n    \n    return \n\nif __name__ == '__main__':\n    main()\n```\n\n### 验证输出\n```\ntensor([0.3073, 0.0680, 0.3627, 0.0659])\ntensor([0.2973, 0.0580, 0.3527, 0.0559])\ntensor([0.2873, 0.0480, 0.3427, 0.0459])\ntensor([0.2773, 0.0380, 0.3327, 0.0359])\ntensor([0.2673, 0.0280, 0.3227, 0.0259])\ntensor([0.2573, 0.0180, 0.3127, 0.0159])\ntensor([0.2473, 0.0080, 0.3027, 0.0059])\ntensor([ 0.2373, -0.0020,  0.2927, -0.0041])\ntensor([ 0.2273, -0.0120,  0.2827, -0.0141])\ntensor([ 0.2173, -0.0220,  0.2727, -0.0241])\n```\n经过 x -> cache -> sum 的计算并反向传播后，可见x的值如上所示有所变化，因此索引将前向传播中间结果赋给Tensor，再在Tensor上做后续运算，能够实现到达输入张量的反向传播！\n\n\n","source":"_posts/2021-09-27-pytorch.md","raw":"---\ntitle: PyTorch踩坑记录（持续更新）\nauthor: LiJT\ndate: 2021-09-27\ntags: \n  - pytorch \n  - 深度学习 \n  - coding \n  - 持续更新\nkey: pytorch20210927\n---\n\n本篇记录使用pytorch过程中踩到的各种坑！\n<!--more-->\n\n## 声明损失函数时忘记加括号\n```python\nloss_fn = nn.BCELoss # 应该是 nn.BCELoss()\n\n>> RuntimeError: bool value of Tensor with more than one value is ambiguous\n```\n\n## 通过索引赋值后，梯度还能正常反向传播吗？\n- 答案：__能__.\n\n### 验证代码\n\n```python\nimport torch \n\ndef main():\n    # x 是输入张量，可求梯度\n    x = torch.rand(4)\n    x.requires_grad_(True)\n    # cache 是中间张量，将x赋给cache\n    cache = torch.zeros(3,4)\n    optim = torch.optim.Adam([x],lr=1e-2)\n    for i in range(10):\n        # 按索引赋值\n        cache[1,:] = x \n        result = cache * 2\n        result = result.view(-1)\n        # 求损失函数\n        sum = torch.sum(result, dim = 0)\n        print(x.data)\n        optim.zero_grad()\n        sum.backward(retain_graph = True)\n        optim.step()\n    \n    return \n\nif __name__ == '__main__':\n    main()\n```\n\n### 验证输出\n```\ntensor([0.3073, 0.0680, 0.3627, 0.0659])\ntensor([0.2973, 0.0580, 0.3527, 0.0559])\ntensor([0.2873, 0.0480, 0.3427, 0.0459])\ntensor([0.2773, 0.0380, 0.3327, 0.0359])\ntensor([0.2673, 0.0280, 0.3227, 0.0259])\ntensor([0.2573, 0.0180, 0.3127, 0.0159])\ntensor([0.2473, 0.0080, 0.3027, 0.0059])\ntensor([ 0.2373, -0.0020,  0.2927, -0.0041])\ntensor([ 0.2273, -0.0120,  0.2827, -0.0141])\ntensor([ 0.2173, -0.0220,  0.2727, -0.0241])\n```\n经过 x -> cache -> sum 的计算并反向传播后，可见x的值如上所示有所变化，因此索引将前向传播中间结果赋给Tensor，再在Tensor上做后续运算，能够实现到达输入张量的反向传播！\n\n\n","slug":"2021-09-27-pytorch","published":1,"updated":"2022-04-06T09:41:31.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8c0001hsv99z4d9myf","content":"<p>本篇记录使用pytorch过程中踩到的各种坑！</p>\n<span id=\"more\"></span>\n\n<h2 id=\"声明损失函数时忘记加括号\"><a href=\"#声明损失函数时忘记加括号\" class=\"headerlink\" title=\"声明损失函数时忘记加括号\"></a>声明损失函数时忘记加括号</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_fn = nn.BCELoss <span class=\"comment\"># 应该是 nn.BCELoss()</span></span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt; RuntimeError: <span class=\"built_in\">bool</span> value of Tensor <span class=\"keyword\">with</span> more than one value <span class=\"keyword\">is</span> ambiguous</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"通过索引赋值后，梯度还能正常反向传播吗？\"><a href=\"#通过索引赋值后，梯度还能正常反向传播吗？\" class=\"headerlink\" title=\"通过索引赋值后，梯度还能正常反向传播吗？\"></a>通过索引赋值后，梯度还能正常反向传播吗？</h2><ul>\n<li>答案：<strong>能</strong>.</li>\n</ul>\n<h3 id=\"验证代码\"><a href=\"#验证代码\" class=\"headerlink\" title=\"验证代码\"></a>验证代码</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">main</span>():</span><br><span class=\"line\">    <span class=\"comment\"># x 是输入张量，可求梯度</span></span><br><span class=\"line\">    x = torch.rand(<span class=\"number\">4</span>)</span><br><span class=\"line\">    x.requires_grad_(<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"comment\"># cache 是中间张量，将x赋给cache</span></span><br><span class=\"line\">    cache = torch.zeros(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">    optim = torch.optim.Adam([x],lr=<span class=\"number\">1e-2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">10</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 按索引赋值</span></span><br><span class=\"line\">        cache[<span class=\"number\">1</span>,:] = x </span><br><span class=\"line\">        result = cache * <span class=\"number\">2</span></span><br><span class=\"line\">        result = result.view(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 求损失函数</span></span><br><span class=\"line\">        <span class=\"built_in\">sum</span> = torch.<span class=\"built_in\">sum</span>(result, dim = <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(x.data)</span><br><span class=\"line\">        optim.zero_grad()</span><br><span class=\"line\">        <span class=\"built_in\">sum</span>.backward(retain_graph = <span class=\"literal\">True</span>)</span><br><span class=\"line\">        optim.step()</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"验证输出\"><a href=\"#验证输出\" class=\"headerlink\" title=\"验证输出\"></a>验证输出</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([0.3073, 0.0680, 0.3627, 0.0659])</span><br><span class=\"line\">tensor([0.2973, 0.0580, 0.3527, 0.0559])</span><br><span class=\"line\">tensor([0.2873, 0.0480, 0.3427, 0.0459])</span><br><span class=\"line\">tensor([0.2773, 0.0380, 0.3327, 0.0359])</span><br><span class=\"line\">tensor([0.2673, 0.0280, 0.3227, 0.0259])</span><br><span class=\"line\">tensor([0.2573, 0.0180, 0.3127, 0.0159])</span><br><span class=\"line\">tensor([0.2473, 0.0080, 0.3027, 0.0059])</span><br><span class=\"line\">tensor([ 0.2373, -0.0020,  0.2927, -0.0041])</span><br><span class=\"line\">tensor([ 0.2273, -0.0120,  0.2827, -0.0141])</span><br><span class=\"line\">tensor([ 0.2173, -0.0220,  0.2727, -0.0241])</span><br></pre></td></tr></table></figure>\n<p>经过 x -&gt; cache -&gt; sum 的计算并反向传播后，可见x的值如上所示有所变化，因此索引将前向传播中间结果赋给Tensor，再在Tensor上做后续运算，能够实现到达输入张量的反向传播！</p>\n","site":{"data":{}},"excerpt":"<p>本篇记录使用pytorch过程中踩到的各种坑！</p>","more":"<h2 id=\"声明损失函数时忘记加括号\"><a href=\"#声明损失函数时忘记加括号\" class=\"headerlink\" title=\"声明损失函数时忘记加括号\"></a>声明损失函数时忘记加括号</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_fn = nn.BCELoss <span class=\"comment\"># 应该是 nn.BCELoss()</span></span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt; RuntimeError: <span class=\"built_in\">bool</span> value of Tensor <span class=\"keyword\">with</span> more than one value <span class=\"keyword\">is</span> ambiguous</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"通过索引赋值后，梯度还能正常反向传播吗？\"><a href=\"#通过索引赋值后，梯度还能正常反向传播吗？\" class=\"headerlink\" title=\"通过索引赋值后，梯度还能正常反向传播吗？\"></a>通过索引赋值后，梯度还能正常反向传播吗？</h2><ul>\n<li>答案：<strong>能</strong>.</li>\n</ul>\n<h3 id=\"验证代码\"><a href=\"#验证代码\" class=\"headerlink\" title=\"验证代码\"></a>验证代码</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">main</span>():</span><br><span class=\"line\">    <span class=\"comment\"># x 是输入张量，可求梯度</span></span><br><span class=\"line\">    x = torch.rand(<span class=\"number\">4</span>)</span><br><span class=\"line\">    x.requires_grad_(<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"comment\"># cache 是中间张量，将x赋给cache</span></span><br><span class=\"line\">    cache = torch.zeros(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">    optim = torch.optim.Adam([x],lr=<span class=\"number\">1e-2</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">10</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 按索引赋值</span></span><br><span class=\"line\">        cache[<span class=\"number\">1</span>,:] = x </span><br><span class=\"line\">        result = cache * <span class=\"number\">2</span></span><br><span class=\"line\">        result = result.view(-<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 求损失函数</span></span><br><span class=\"line\">        <span class=\"built_in\">sum</span> = torch.<span class=\"built_in\">sum</span>(result, dim = <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(x.data)</span><br><span class=\"line\">        optim.zero_grad()</span><br><span class=\"line\">        <span class=\"built_in\">sum</span>.backward(retain_graph = <span class=\"literal\">True</span>)</span><br><span class=\"line\">        optim.step()</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"验证输出\"><a href=\"#验证输出\" class=\"headerlink\" title=\"验证输出\"></a>验证输出</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([0.3073, 0.0680, 0.3627, 0.0659])</span><br><span class=\"line\">tensor([0.2973, 0.0580, 0.3527, 0.0559])</span><br><span class=\"line\">tensor([0.2873, 0.0480, 0.3427, 0.0459])</span><br><span class=\"line\">tensor([0.2773, 0.0380, 0.3327, 0.0359])</span><br><span class=\"line\">tensor([0.2673, 0.0280, 0.3227, 0.0259])</span><br><span class=\"line\">tensor([0.2573, 0.0180, 0.3127, 0.0159])</span><br><span class=\"line\">tensor([0.2473, 0.0080, 0.3027, 0.0059])</span><br><span class=\"line\">tensor([ 0.2373, -0.0020,  0.2927, -0.0041])</span><br><span class=\"line\">tensor([ 0.2273, -0.0120,  0.2827, -0.0141])</span><br><span class=\"line\">tensor([ 0.2173, -0.0220,  0.2727, -0.0241])</span><br></pre></td></tr></table></figure>\n<p>经过 x -&gt; cache -&gt; sum 的计算并反向传播后，可见x的值如上所示有所变化，因此索引将前向传播中间结果赋给Tensor，再在Tensor上做后续运算，能够实现到达输入张量的反向传播！</p>"},{"title":"美食的记录","author":"LiJT","date":"2021-09-28T16:00:00.000Z","key":"food20210929","_content":"\n## 煲王\n- 猪脚煲的味道很棒，想起了以前吃过的发财猪手。骨髓浓香四溢，但考虑到健康，未敢多吃。\n- 咖喱牛腩的味道很正，有澳门风味。猪肚鸡的汤底调味很好，可惜猪肚太少，仅三两片，怎能够吃？\n- 煲仔饭和卤水拼盘味道不错。卤水拼盘改良过，热吃，色浓，摆盘也更加粗犷。更喜欢吃潮汕的蘸白醋的卤水狮头鹅！\n- 茄子煲调味很好，但火候不够，茄子不入味。叉烧包实属鸡肋！过量的面和少量的肉馅... 但是可以把面撕下来，包猪手吃，极美。\n\n<!--more-->\n\n\n## 卜一帆\n- 京葱鸡肉串极鲜美。咸鲜、多汁、皮微焦的鸡肉，焦黄、冲香的葱，实在是相得益彰。\n- 烤五花味道浓香，脆骨爽口，但肉略微有些干，或许是没有刷油。\n- 青花鱼，熟悉的味道。不加任何调料烤制，挤上几滴柠檬汁，鲜美而浓郁。配上一碗米饭和沙拉就是完美的午餐。\n- 寿喜锅，久闻大名却第一次吃。日料虽然只有甜酱油、味增、味淋、昆布高汤等几种调味料，但甜酱油和高汤真的很适合火锅。牛肉多汁入味嫩而不烂，吸满汤汁的白菜、金针菇、魔芋丝和豆腐是米饭的绝配。看着咕嘟嘟的小锅和冒出的白雾，如果这是在冬天，想必一定是非常幸福的时刻吧。\n\n","source":"_posts/2021-09-29-food.md","raw":"---\ntitle: 美食的记录\nauthor: LiJT\ndate: 2021-09-29\ntags: 美食\nkey: food20210929 \n---\n\n## 煲王\n- 猪脚煲的味道很棒，想起了以前吃过的发财猪手。骨髓浓香四溢，但考虑到健康，未敢多吃。\n- 咖喱牛腩的味道很正，有澳门风味。猪肚鸡的汤底调味很好，可惜猪肚太少，仅三两片，怎能够吃？\n- 煲仔饭和卤水拼盘味道不错。卤水拼盘改良过，热吃，色浓，摆盘也更加粗犷。更喜欢吃潮汕的蘸白醋的卤水狮头鹅！\n- 茄子煲调味很好，但火候不够，茄子不入味。叉烧包实属鸡肋！过量的面和少量的肉馅... 但是可以把面撕下来，包猪手吃，极美。\n\n<!--more-->\n\n\n## 卜一帆\n- 京葱鸡肉串极鲜美。咸鲜、多汁、皮微焦的鸡肉，焦黄、冲香的葱，实在是相得益彰。\n- 烤五花味道浓香，脆骨爽口，但肉略微有些干，或许是没有刷油。\n- 青花鱼，熟悉的味道。不加任何调料烤制，挤上几滴柠檬汁，鲜美而浓郁。配上一碗米饭和沙拉就是完美的午餐。\n- 寿喜锅，久闻大名却第一次吃。日料虽然只有甜酱油、味增、味淋、昆布高汤等几种调味料，但甜酱油和高汤真的很适合火锅。牛肉多汁入味嫩而不烂，吸满汤汁的白菜、金针菇、魔芋丝和豆腐是米饭的绝配。看着咕嘟嘟的小锅和冒出的白雾，如果这是在冬天，想必一定是非常幸福的时刻吧。\n\n","slug":"2021-09-29-food","published":1,"updated":"2022-04-06T09:43:42.817Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8f0003hsv9hohn9i0d","content":"<h2 id=\"煲王\"><a href=\"#煲王\" class=\"headerlink\" title=\"煲王\"></a>煲王</h2><ul>\n<li>猪脚煲的味道很棒，想起了以前吃过的发财猪手。骨髓浓香四溢，但考虑到健康，未敢多吃。</li>\n<li>咖喱牛腩的味道很正，有澳门风味。猪肚鸡的汤底调味很好，可惜猪肚太少，仅三两片，怎能够吃？</li>\n<li>煲仔饭和卤水拼盘味道不错。卤水拼盘改良过，热吃，色浓，摆盘也更加粗犷。更喜欢吃潮汕的蘸白醋的卤水狮头鹅！</li>\n<li>茄子煲调味很好，但火候不够，茄子不入味。叉烧包实属鸡肋！过量的面和少量的肉馅… 但是可以把面撕下来，包猪手吃，极美。</li>\n</ul>\n<span id=\"more\"></span>\n\n\n<h2 id=\"卜一帆\"><a href=\"#卜一帆\" class=\"headerlink\" title=\"卜一帆\"></a>卜一帆</h2><ul>\n<li>京葱鸡肉串极鲜美。咸鲜、多汁、皮微焦的鸡肉，焦黄、冲香的葱，实在是相得益彰。</li>\n<li>烤五花味道浓香，脆骨爽口，但肉略微有些干，或许是没有刷油。</li>\n<li>青花鱼，熟悉的味道。不加任何调料烤制，挤上几滴柠檬汁，鲜美而浓郁。配上一碗米饭和沙拉就是完美的午餐。</li>\n<li>寿喜锅，久闻大名却第一次吃。日料虽然只有甜酱油、味增、味淋、昆布高汤等几种调味料，但甜酱油和高汤真的很适合火锅。牛肉多汁入味嫩而不烂，吸满汤汁的白菜、金针菇、魔芋丝和豆腐是米饭的绝配。看着咕嘟嘟的小锅和冒出的白雾，如果这是在冬天，想必一定是非常幸福的时刻吧。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"煲王\"><a href=\"#煲王\" class=\"headerlink\" title=\"煲王\"></a>煲王</h2><ul>\n<li>猪脚煲的味道很棒，想起了以前吃过的发财猪手。骨髓浓香四溢，但考虑到健康，未敢多吃。</li>\n<li>咖喱牛腩的味道很正，有澳门风味。猪肚鸡的汤底调味很好，可惜猪肚太少，仅三两片，怎能够吃？</li>\n<li>煲仔饭和卤水拼盘味道不错。卤水拼盘改良过，热吃，色浓，摆盘也更加粗犷。更喜欢吃潮汕的蘸白醋的卤水狮头鹅！</li>\n<li>茄子煲调味很好，但火候不够，茄子不入味。叉烧包实属鸡肋！过量的面和少量的肉馅… 但是可以把面撕下来，包猪手吃，极美。</li>\n</ul>","more":"<h2 id=\"卜一帆\"><a href=\"#卜一帆\" class=\"headerlink\" title=\"卜一帆\"></a>卜一帆</h2><ul>\n<li>京葱鸡肉串极鲜美。咸鲜、多汁、皮微焦的鸡肉，焦黄、冲香的葱，实在是相得益彰。</li>\n<li>烤五花味道浓香，脆骨爽口，但肉略微有些干，或许是没有刷油。</li>\n<li>青花鱼，熟悉的味道。不加任何调料烤制，挤上几滴柠檬汁，鲜美而浓郁。配上一碗米饭和沙拉就是完美的午餐。</li>\n<li>寿喜锅，久闻大名却第一次吃。日料虽然只有甜酱油、味增、味淋、昆布高汤等几种调味料，但甜酱油和高汤真的很适合火锅。牛肉多汁入味嫩而不烂，吸满汤汁的白菜、金针菇、魔芋丝和豆腐是米饭的绝配。看着咕嘟嘟的小锅和冒出的白雾，如果这是在冬天，想必一定是非常幸福的时刻吧。</li>\n</ul>"},{"title":"红烩羊肉","author":"LiJT","date":"2021-09-30T16:00:00.000Z","key":"stewlamb20211001","_content":"\n祝祖国母亲生日快乐！祝大家节日安康！\n\n今天在思考番茄酱和番茄沙司的用法，忽然灵光一闪——红烩羊肉，let's do this!\n<!--more-->\n\n## 原料\n- 羊肋排（手动去骨，切二指粗）一小盆\n- 番茄沙司\n- 番茄2枚\n- 红烧酱油/冰糖\n- 大葱、葱、姜、蒜、料酒\n- 盐、胡椒粉\n\n## 做法\n### 焯水\n- 羊肋排去骨切块洗净，冷水下锅，一并放入葱、姜、一勺料酒。大火煮开，转小火滚五分钟。期间打去血沫。捞起，温水洗净羊肉，去葱姜。\n\n### 煎制、熬酱\n- 番茄洗净切块备用，葱姜蒜洗净切片备用\n- 热锅凉油，下葱姜蒜小火慢炸直至蒜微黄，下羊排煎制，至表面金黄色，下番茄全部、番茄酱若干。继续小火翻炒，至番茄大量出水，加入开水，没过食材\n\n### 红烩\n- 加入少许红烧酱油调色，或炒糖色。转大火烧开五分钟给羊肉上色\n- 转小火慢炖10分钟\n- 调味，加入盐、胡椒粉。继续炖20分钟，让羊肉入味\n- 至临出锅前15分钟，下入洋葱或粉丝等辅料，继续小火\n- 大火收汁至汤汁挂线\n- 出锅，礼成\n\n## 体验\n- 羊味十足而不腥膻，大抵是由于羊油去的干净、焯水焯得彻底\n- 番茄的使用十分得当。慢炖40分钟后，番茄已完全化入汤中，汤汁变浓，无需勾芡\n- 可以加入洋葱，必能提味\n- 味酸甜又有咸香。注意番茄和番茄酱的用量\n- 盐可以分几次放，让羊肉充分入味\n- 好吃！\n","source":"_posts/2021-10-01-stewlamb.md","raw":"---\ntitle: 红烩羊肉\nauthor: LiJT\ndate: 2021-10-01\ntags: 美食\nkey: stewlamb20211001\n---\n\n祝祖国母亲生日快乐！祝大家节日安康！\n\n今天在思考番茄酱和番茄沙司的用法，忽然灵光一闪——红烩羊肉，let's do this!\n<!--more-->\n\n## 原料\n- 羊肋排（手动去骨，切二指粗）一小盆\n- 番茄沙司\n- 番茄2枚\n- 红烧酱油/冰糖\n- 大葱、葱、姜、蒜、料酒\n- 盐、胡椒粉\n\n## 做法\n### 焯水\n- 羊肋排去骨切块洗净，冷水下锅，一并放入葱、姜、一勺料酒。大火煮开，转小火滚五分钟。期间打去血沫。捞起，温水洗净羊肉，去葱姜。\n\n### 煎制、熬酱\n- 番茄洗净切块备用，葱姜蒜洗净切片备用\n- 热锅凉油，下葱姜蒜小火慢炸直至蒜微黄，下羊排煎制，至表面金黄色，下番茄全部、番茄酱若干。继续小火翻炒，至番茄大量出水，加入开水，没过食材\n\n### 红烩\n- 加入少许红烧酱油调色，或炒糖色。转大火烧开五分钟给羊肉上色\n- 转小火慢炖10分钟\n- 调味，加入盐、胡椒粉。继续炖20分钟，让羊肉入味\n- 至临出锅前15分钟，下入洋葱或粉丝等辅料，继续小火\n- 大火收汁至汤汁挂线\n- 出锅，礼成\n\n## 体验\n- 羊味十足而不腥膻，大抵是由于羊油去的干净、焯水焯得彻底\n- 番茄的使用十分得当。慢炖40分钟后，番茄已完全化入汤中，汤汁变浓，无需勾芡\n- 可以加入洋葱，必能提味\n- 味酸甜又有咸香。注意番茄和番茄酱的用量\n- 盐可以分几次放，让羊肉充分入味\n- 好吃！\n","slug":"2021-10-01-stewlamb","published":1,"updated":"2022-04-06T09:43:51.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8j0006hsv9dmglh3f1","content":"<p>祝祖国母亲生日快乐！祝大家节日安康！</p>\n<p>今天在思考番茄酱和番茄沙司的用法，忽然灵光一闪——红烩羊肉，let’s do this!</p>\n<span id=\"more\"></span>\n\n<h2 id=\"原料\"><a href=\"#原料\" class=\"headerlink\" title=\"原料\"></a>原料</h2><ul>\n<li>羊肋排（手动去骨，切二指粗）一小盆</li>\n<li>番茄沙司</li>\n<li>番茄2枚</li>\n<li>红烧酱油/冰糖</li>\n<li>大葱、葱、姜、蒜、料酒</li>\n<li>盐、胡椒粉</li>\n</ul>\n<h2 id=\"做法\"><a href=\"#做法\" class=\"headerlink\" title=\"做法\"></a>做法</h2><h3 id=\"焯水\"><a href=\"#焯水\" class=\"headerlink\" title=\"焯水\"></a>焯水</h3><ul>\n<li>羊肋排去骨切块洗净，冷水下锅，一并放入葱、姜、一勺料酒。大火煮开，转小火滚五分钟。期间打去血沫。捞起，温水洗净羊肉，去葱姜。</li>\n</ul>\n<h3 id=\"煎制、熬酱\"><a href=\"#煎制、熬酱\" class=\"headerlink\" title=\"煎制、熬酱\"></a>煎制、熬酱</h3><ul>\n<li>番茄洗净切块备用，葱姜蒜洗净切片备用</li>\n<li>热锅凉油，下葱姜蒜小火慢炸直至蒜微黄，下羊排煎制，至表面金黄色，下番茄全部、番茄酱若干。继续小火翻炒，至番茄大量出水，加入开水，没过食材</li>\n</ul>\n<h3 id=\"红烩\"><a href=\"#红烩\" class=\"headerlink\" title=\"红烩\"></a>红烩</h3><ul>\n<li>加入少许红烧酱油调色，或炒糖色。转大火烧开五分钟给羊肉上色</li>\n<li>转小火慢炖10分钟</li>\n<li>调味，加入盐、胡椒粉。继续炖20分钟，让羊肉入味</li>\n<li>至临出锅前15分钟，下入洋葱或粉丝等辅料，继续小火</li>\n<li>大火收汁至汤汁挂线</li>\n<li>出锅，礼成</li>\n</ul>\n<h2 id=\"体验\"><a href=\"#体验\" class=\"headerlink\" title=\"体验\"></a>体验</h2><ul>\n<li>羊味十足而不腥膻，大抵是由于羊油去的干净、焯水焯得彻底</li>\n<li>番茄的使用十分得当。慢炖40分钟后，番茄已完全化入汤中，汤汁变浓，无需勾芡</li>\n<li>可以加入洋葱，必能提味</li>\n<li>味酸甜又有咸香。注意番茄和番茄酱的用量</li>\n<li>盐可以分几次放，让羊肉充分入味</li>\n<li>好吃！</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>祝祖国母亲生日快乐！祝大家节日安康！</p>\n<p>今天在思考番茄酱和番茄沙司的用法，忽然灵光一闪——红烩羊肉，let’s do this!</p>","more":"<h2 id=\"原料\"><a href=\"#原料\" class=\"headerlink\" title=\"原料\"></a>原料</h2><ul>\n<li>羊肋排（手动去骨，切二指粗）一小盆</li>\n<li>番茄沙司</li>\n<li>番茄2枚</li>\n<li>红烧酱油/冰糖</li>\n<li>大葱、葱、姜、蒜、料酒</li>\n<li>盐、胡椒粉</li>\n</ul>\n<h2 id=\"做法\"><a href=\"#做法\" class=\"headerlink\" title=\"做法\"></a>做法</h2><h3 id=\"焯水\"><a href=\"#焯水\" class=\"headerlink\" title=\"焯水\"></a>焯水</h3><ul>\n<li>羊肋排去骨切块洗净，冷水下锅，一并放入葱、姜、一勺料酒。大火煮开，转小火滚五分钟。期间打去血沫。捞起，温水洗净羊肉，去葱姜。</li>\n</ul>\n<h3 id=\"煎制、熬酱\"><a href=\"#煎制、熬酱\" class=\"headerlink\" title=\"煎制、熬酱\"></a>煎制、熬酱</h3><ul>\n<li>番茄洗净切块备用，葱姜蒜洗净切片备用</li>\n<li>热锅凉油，下葱姜蒜小火慢炸直至蒜微黄，下羊排煎制，至表面金黄色，下番茄全部、番茄酱若干。继续小火翻炒，至番茄大量出水，加入开水，没过食材</li>\n</ul>\n<h3 id=\"红烩\"><a href=\"#红烩\" class=\"headerlink\" title=\"红烩\"></a>红烩</h3><ul>\n<li>加入少许红烧酱油调色，或炒糖色。转大火烧开五分钟给羊肉上色</li>\n<li>转小火慢炖10分钟</li>\n<li>调味，加入盐、胡椒粉。继续炖20分钟，让羊肉入味</li>\n<li>至临出锅前15分钟，下入洋葱或粉丝等辅料，继续小火</li>\n<li>大火收汁至汤汁挂线</li>\n<li>出锅，礼成</li>\n</ul>\n<h2 id=\"体验\"><a href=\"#体验\" class=\"headerlink\" title=\"体验\"></a>体验</h2><ul>\n<li>羊味十足而不腥膻，大抵是由于羊油去的干净、焯水焯得彻底</li>\n<li>番茄的使用十分得当。慢炖40分钟后，番茄已完全化入汤中，汤汁变浓，无需勾芡</li>\n<li>可以加入洋葱，必能提味</li>\n<li>味酸甜又有咸香。注意番茄和番茄酱的用量</li>\n<li>盐可以分几次放，让羊肉充分入味</li>\n<li>好吃！</li>\n</ul>"},{"title":"【连载】鲸的语言？（一）","author":"orange","date":"2021-09-30T16:00:00.000Z","key":"whale0120211001","_content":"\n一块雷雨云逼近了波多黎各的库莱布拉岛（Culebra）南部，威胁着要把小保罗·纳普（Paul Knapp Jr.）和他那艘18英尺充气小艇“小罗盘”号（Little Compass）上的三名乘客淋个透心凉。他船舵上的贴纸上写着： “我会说鲸鱼的语言。”\n\n<!--more-->\n\n鲸的语言？\n\n保罗纳普开始吟唱起不知名的咏叹调，在即将掀起的狂风暴雨中，咏叹调连1米外的乘客都听不见。\n\n狂风将他刚写好的纸张带入海里，很快不见踪影。\n\n他拿起挂在脖子上的喇叭，屹立在充气小艇的前端，继续开始他的人类音频咏叹调。\n\n这是鲸的语言吗？\n\n乘客A用他深蓝色的眼眸死死的盯着保罗纳普，有关海洋生物交流频率的研究在他脑海中不停穿插。\n\n海水一层层一层的荡漾过来，随时可以将气垫船掀翻。\n\n","source":"_posts/2021-10-01-whale01.md","raw":"---\ntitle: 【连载】鲸的语言？（一）\nauthor: orange\ndate: 2021-10-01\ntags: 小说\nkey: whale0120211001\n---\n\n一块雷雨云逼近了波多黎各的库莱布拉岛（Culebra）南部，威胁着要把小保罗·纳普（Paul Knapp Jr.）和他那艘18英尺充气小艇“小罗盘”号（Little Compass）上的三名乘客淋个透心凉。他船舵上的贴纸上写着： “我会说鲸鱼的语言。”\n\n<!--more-->\n\n鲸的语言？\n\n保罗纳普开始吟唱起不知名的咏叹调，在即将掀起的狂风暴雨中，咏叹调连1米外的乘客都听不见。\n\n狂风将他刚写好的纸张带入海里，很快不见踪影。\n\n他拿起挂在脖子上的喇叭，屹立在充气小艇的前端，继续开始他的人类音频咏叹调。\n\n这是鲸的语言吗？\n\n乘客A用他深蓝色的眼眸死死的盯着保罗纳普，有关海洋生物交流频率的研究在他脑海中不停穿插。\n\n海水一层层一层的荡漾过来，随时可以将气垫船掀翻。\n\n","slug":"2021-10-01-whale01","published":1,"updated":"2022-04-06T09:44:01.519Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8k0007hsv9b1n7350m","content":"<p>一块雷雨云逼近了波多黎各的库莱布拉岛（Culebra）南部，威胁着要把小保罗·纳普（Paul Knapp Jr.）和他那艘18英尺充气小艇“小罗盘”号（Little Compass）上的三名乘客淋个透心凉。他船舵上的贴纸上写着： “我会说鲸鱼的语言。”</p>\n<span id=\"more\"></span>\n\n<p>鲸的语言？</p>\n<p>保罗纳普开始吟唱起不知名的咏叹调，在即将掀起的狂风暴雨中，咏叹调连1米外的乘客都听不见。</p>\n<p>狂风将他刚写好的纸张带入海里，很快不见踪影。</p>\n<p>他拿起挂在脖子上的喇叭，屹立在充气小艇的前端，继续开始他的人类音频咏叹调。</p>\n<p>这是鲸的语言吗？</p>\n<p>乘客A用他深蓝色的眼眸死死的盯着保罗纳普，有关海洋生物交流频率的研究在他脑海中不停穿插。</p>\n<p>海水一层层一层的荡漾过来，随时可以将气垫船掀翻。</p>\n","site":{"data":{}},"excerpt":"<p>一块雷雨云逼近了波多黎各的库莱布拉岛（Culebra）南部，威胁着要把小保罗·纳普（Paul Knapp Jr.）和他那艘18英尺充气小艇“小罗盘”号（Little Compass）上的三名乘客淋个透心凉。他船舵上的贴纸上写着： “我会说鲸鱼的语言。”</p>","more":"<p>鲸的语言？</p>\n<p>保罗纳普开始吟唱起不知名的咏叹调，在即将掀起的狂风暴雨中，咏叹调连1米外的乘客都听不见。</p>\n<p>狂风将他刚写好的纸张带入海里，很快不见踪影。</p>\n<p>他拿起挂在脖子上的喇叭，屹立在充气小艇的前端，继续开始他的人类音频咏叹调。</p>\n<p>这是鲸的语言吗？</p>\n<p>乘客A用他深蓝色的眼眸死死的盯着保罗纳普，有关海洋生物交流频率的研究在他脑海中不停穿插。</p>\n<p>海水一层层一层的荡漾过来，随时可以将气垫船掀翻。</p>"},{"title":"PyTorch: CrossEntropyLoss vs. NLLLoss vs. BCELoss","author":"LiJT","date":"2021-10-06T16:00:00.000Z","key":"pytorch20211007","_content":"\nCrossEntropyLoss, NLLLoss 和 BCELoss 本质上都是基于交叉熵(cross entropy)的分类器的损失函数。但是三个函数的输入格式、计算方法和性能（收敛速度）有很大差别。本文记录笔者对此三者的学习笔记和理解。\n{:.info}\n\n<!--more-->\n\n## 交叉熵(Cross Entropy)\n\n交叉熵(Cross Entropy)是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。或曰，概率分布 $p$ 和概率分布 $q$ 的相似程度。如果 $p$ 和 $q$ 越相似，那么越能用 $p$ 近似表示 $q$ 或用 $q$ 近似表示 $p$ 。定义交叉熵为：\n\n$$\nH(p,q) = \\sum_x p(x)\\log \\left(\\frac{1}{q(x)}\\right)\n$$\n\n注意交叉熵不满足对称性。\n\n## nn.CrossEntropyLoss\n\n```python\ntorch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n```\n\n### 计算方法\n\n根据[pytorch官方文档](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)，CrossEntropyLoss的输入值为\"unnormalized scores for each class\"，即未限制在(0,1)上的各个类别的得分。其表达式为\n\n$$\nloss(x,class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)\n$$\n\n其中 $x$ 为一个样本，$class$ 为一个类别, $x[j]\\in(-\\infty,\\infty)$ 为分类器给样本 $x$ 在类别 $j$ 上赋予的得分，或当weight不为空时，\n\n$$\nloss(x,class) = -weight[class]\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)\n$$\n\n其中 $weight[class]$ 为类别 $class$ 的权重。其值越大，总损失中 $class$ 类所占有的损失项的比重越大。\n\n最终，总损失为每个样本$x$上的损失的加权平均，即\n\n$$\n\\mathcal{L}(X,class) = \\frac{\\sum_{x\\in X}loss(x,class[x])}{\\sum_{x\\in X}weight[class[x]]}\n$$\n\n### 总结\n- 是否支持多类别分类：支持\n- 输入得分值域：$(-\\infty,\\infty)$\n- 神经网络输出层是否需要激活/归一化: 不用\n\n## nn.NLLLoss\n\n```python\ntorch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n```\n\n### 计算方法\n\n`NLLLoss`的用法，实际在`CrossEntropyLoss`的文档中给出：\n\nThis criterion combines **LogSoftmax** and **NLLLoss** in one single class.\n{:.success}\n\n也就是说，`CrossEntropyLoss`是`NLLLoss`和`LogSoftmax`的结合体。为看清这一点，我们回到式(2)。其中 $\\log\\frac{\\exp(\\cdot)}{\\sum_j \\exp(\\cdot)}$ 就是LogSoftmax.\n\n因此，如果`CrossEntropyLoss`的输入值是 $(x,class)$， 那么 `NLLLoss` 的输入值就是 $LogSoftmax(x), class$。其中 $LogSoftmax(\\cdot)$ 需要对 $x$ 的每个分量计算一次，最终 $dim(LogSoftmax(x)) = dim(x)$。除此之外，`NLLLoss` 在其他部分的计算过程与 `CrossEntropyLoss` 完全一致。\n\n### 总结\n- 是否支持多类别分类：支持\n- 输入得分值域：$(-\\infty,\\infty)$\n- 神经网络输出层是否需要激活/归一化: 需要，最后一层使用LogSoftmax.也可在神经网络中使用softmax或sigmoid，在计算损失函数时显式加入torch.log计算对数\n\n## nn.BCELoss\n\n```python\ntorch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n```\n\n### 计算方法\n`BCELoss`是专门针对二分类问题的交叉熵损失函数。其计算形式更加接近式(1): \n\n$$\n\\mathcal{L}(x_n,y_n) = -w_n\\left[y_n\\cdot\\log x_n + (1-y_n)\\cdot\\log(1-x_n)\\right] \n$$\n\n### 总结\n- 是否支持多类别分类：不支持。只支持二分类\n- 输入得分值域：$(0,1)$。常搭配$sigmoid$一起使用\n- 神经网络输出层是否需要激活/归一化: sigmoid进行归一化处理。\n\nTips: 在实际使用时，出现过使用BCELoss时算法不收敛、AUC奇低，但换成NLLLoss后一切都很好用的情况。\n\n## 对比表格\n\n|项目\\方法|CrossEntropyLoss|NLLLoss|BCELoss|\n|:---|:---|:---|:---|\n|支持多分类|是|是|否|\n|`y_pred`值域|$(-\\infty,\\infty)$|$(-\\infty,\\infty)$|$(0,1)$|\n|`type(y_target)`|`torch.LongTensor`|`torch.LongTensor`|`torch.DoubleTensor`|\n|输出层是否需要归一化|否|`LogSoftmax`|`sigmoid`|\n\n","source":"_posts/2021-10-07-pytorch.md","raw":"---\ntitle: 'PyTorch: CrossEntropyLoss vs. NLLLoss vs. BCELoss'\nauthor: LiJT\ndate: 2021-10-07\ntags: \n  - pytorch \n  - 深度学习 \n  - coding\nkey: pytorch20211007\n---\n\nCrossEntropyLoss, NLLLoss 和 BCELoss 本质上都是基于交叉熵(cross entropy)的分类器的损失函数。但是三个函数的输入格式、计算方法和性能（收敛速度）有很大差别。本文记录笔者对此三者的学习笔记和理解。\n{:.info}\n\n<!--more-->\n\n## 交叉熵(Cross Entropy)\n\n交叉熵(Cross Entropy)是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。或曰，概率分布 $p$ 和概率分布 $q$ 的相似程度。如果 $p$ 和 $q$ 越相似，那么越能用 $p$ 近似表示 $q$ 或用 $q$ 近似表示 $p$ 。定义交叉熵为：\n\n$$\nH(p,q) = \\sum_x p(x)\\log \\left(\\frac{1}{q(x)}\\right)\n$$\n\n注意交叉熵不满足对称性。\n\n## nn.CrossEntropyLoss\n\n```python\ntorch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n```\n\n### 计算方法\n\n根据[pytorch官方文档](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)，CrossEntropyLoss的输入值为\"unnormalized scores for each class\"，即未限制在(0,1)上的各个类别的得分。其表达式为\n\n$$\nloss(x,class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)\n$$\n\n其中 $x$ 为一个样本，$class$ 为一个类别, $x[j]\\in(-\\infty,\\infty)$ 为分类器给样本 $x$ 在类别 $j$ 上赋予的得分，或当weight不为空时，\n\n$$\nloss(x,class) = -weight[class]\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)\n$$\n\n其中 $weight[class]$ 为类别 $class$ 的权重。其值越大，总损失中 $class$ 类所占有的损失项的比重越大。\n\n最终，总损失为每个样本$x$上的损失的加权平均，即\n\n$$\n\\mathcal{L}(X,class) = \\frac{\\sum_{x\\in X}loss(x,class[x])}{\\sum_{x\\in X}weight[class[x]]}\n$$\n\n### 总结\n- 是否支持多类别分类：支持\n- 输入得分值域：$(-\\infty,\\infty)$\n- 神经网络输出层是否需要激活/归一化: 不用\n\n## nn.NLLLoss\n\n```python\ntorch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n```\n\n### 计算方法\n\n`NLLLoss`的用法，实际在`CrossEntropyLoss`的文档中给出：\n\nThis criterion combines **LogSoftmax** and **NLLLoss** in one single class.\n{:.success}\n\n也就是说，`CrossEntropyLoss`是`NLLLoss`和`LogSoftmax`的结合体。为看清这一点，我们回到式(2)。其中 $\\log\\frac{\\exp(\\cdot)}{\\sum_j \\exp(\\cdot)}$ 就是LogSoftmax.\n\n因此，如果`CrossEntropyLoss`的输入值是 $(x,class)$， 那么 `NLLLoss` 的输入值就是 $LogSoftmax(x), class$。其中 $LogSoftmax(\\cdot)$ 需要对 $x$ 的每个分量计算一次，最终 $dim(LogSoftmax(x)) = dim(x)$。除此之外，`NLLLoss` 在其他部分的计算过程与 `CrossEntropyLoss` 完全一致。\n\n### 总结\n- 是否支持多类别分类：支持\n- 输入得分值域：$(-\\infty,\\infty)$\n- 神经网络输出层是否需要激活/归一化: 需要，最后一层使用LogSoftmax.也可在神经网络中使用softmax或sigmoid，在计算损失函数时显式加入torch.log计算对数\n\n## nn.BCELoss\n\n```python\ntorch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n```\n\n### 计算方法\n`BCELoss`是专门针对二分类问题的交叉熵损失函数。其计算形式更加接近式(1): \n\n$$\n\\mathcal{L}(x_n,y_n) = -w_n\\left[y_n\\cdot\\log x_n + (1-y_n)\\cdot\\log(1-x_n)\\right] \n$$\n\n### 总结\n- 是否支持多类别分类：不支持。只支持二分类\n- 输入得分值域：$(0,1)$。常搭配$sigmoid$一起使用\n- 神经网络输出层是否需要激活/归一化: sigmoid进行归一化处理。\n\nTips: 在实际使用时，出现过使用BCELoss时算法不收敛、AUC奇低，但换成NLLLoss后一切都很好用的情况。\n\n## 对比表格\n\n|项目\\方法|CrossEntropyLoss|NLLLoss|BCELoss|\n|:---|:---|:---|:---|\n|支持多分类|是|是|否|\n|`y_pred`值域|$(-\\infty,\\infty)$|$(-\\infty,\\infty)$|$(0,1)$|\n|`type(y_target)`|`torch.LongTensor`|`torch.LongTensor`|`torch.DoubleTensor`|\n|输出层是否需要归一化|否|`LogSoftmax`|`sigmoid`|\n\n","slug":"2021-10-07-pytorch","published":1,"updated":"2022-04-06T09:44:15.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8k0008hsv92emcfzs8","content":"<p>CrossEntropyLoss, NLLLoss 和 BCELoss 本质上都是基于交叉熵(cross entropy)的分类器的损失函数。但是三个函数的输入格式、计算方法和性能（收敛速度）有很大差别。本文记录笔者对此三者的学习笔记和理解。<br>{:.info}</p>\n<span id=\"more\"></span>\n\n<h2 id=\"交叉熵-Cross-Entropy\"><a href=\"#交叉熵-Cross-Entropy\" class=\"headerlink\" title=\"交叉熵(Cross Entropy)\"></a>交叉熵(Cross Entropy)</h2><p>交叉熵(Cross Entropy)是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。或曰，概率分布 $p$ 和概率分布 $q$ 的相似程度。如果 $p$ 和 $q$ 越相似，那么越能用 $p$ 近似表示 $q$ 或用 $q$ 近似表示 $p$ 。定义交叉熵为：</p>\n<p>$$<br>H(p,q) = \\sum_x p(x)\\log \\left(\\frac{1}{q(x)}\\right)<br>$$</p>\n<p>注意交叉熵不满足对称性。</p>\n<h2 id=\"nn-CrossEntropyLoss\"><a href=\"#nn-CrossEntropyLoss\" class=\"headerlink\" title=\"nn.CrossEntropyLoss\"></a>nn.CrossEntropyLoss</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.CrossEntropyLoss(weight=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, ignore_index=-<span class=\"number\">100</span>, reduce=<span class=\"literal\">None</span>, reduction=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算方法\"><a href=\"#计算方法\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><p>根据<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\">pytorch官方文档</a>，CrossEntropyLoss的输入值为”unnormalized scores for each class”，即未限制在(0,1)上的各个类别的得分。其表达式为</p>\n<p>$$<br>loss(x,class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)<br>$$</p>\n<p>其中 $x$ 为一个样本，$class$ 为一个类别, $x[j]\\in(-\\infty,\\infty)$ 为分类器给样本 $x$ 在类别 $j$ 上赋予的得分，或当weight不为空时，</p>\n<p>$$<br>loss(x,class) = -weight[class]\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)<br>$$</p>\n<p>其中 $weight[class]$ 为类别 $class$ 的权重。其值越大，总损失中 $class$ 类所占有的损失项的比重越大。</p>\n<p>最终，总损失为每个样本$x$上的损失的加权平均，即</p>\n<p>$$<br>\\mathcal{L}(X,class) = \\frac{\\sum_{x\\in X}loss(x,class[x])}{\\sum_{x\\in X}weight[class[x]]}<br>$$</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>是否支持多类别分类：支持</li>\n<li>输入得分值域：$(-\\infty,\\infty)$</li>\n<li>神经网络输出层是否需要激活/归一化: 不用</li>\n</ul>\n<h2 id=\"nn-NLLLoss\"><a href=\"#nn-NLLLoss\" class=\"headerlink\" title=\"nn.NLLLoss\"></a>nn.NLLLoss</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.NLLLoss(weight=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, ignore_index=-<span class=\"number\">100</span>, reduce=<span class=\"literal\">None</span>, reduction=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算方法-1\"><a href=\"#计算方法-1\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><p><code>NLLLoss</code>的用法，实际在<code>CrossEntropyLoss</code>的文档中给出：</p>\n<p>This criterion combines <strong>LogSoftmax</strong> and <strong>NLLLoss</strong> in one single class.<br>{:.success}</p>\n<p>也就是说，<code>CrossEntropyLoss</code>是<code>NLLLoss</code>和<code>LogSoftmax</code>的结合体。为看清这一点，我们回到式(2)。其中 $\\log\\frac{\\exp(\\cdot)}{\\sum_j \\exp(\\cdot)}$ 就是LogSoftmax.</p>\n<p>因此，如果<code>CrossEntropyLoss</code>的输入值是 $(x,class)$， 那么 <code>NLLLoss</code> 的输入值就是 $LogSoftmax(x), class$。其中 $LogSoftmax(\\cdot)$ 需要对 $x$ 的每个分量计算一次，最终 $dim(LogSoftmax(x)) = dim(x)$。除此之外，<code>NLLLoss</code> 在其他部分的计算过程与 <code>CrossEntropyLoss</code> 完全一致。</p>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>是否支持多类别分类：支持</li>\n<li>输入得分值域：$(-\\infty,\\infty)$</li>\n<li>神经网络输出层是否需要激活/归一化: 需要，最后一层使用LogSoftmax.也可在神经网络中使用softmax或sigmoid，在计算损失函数时显式加入torch.log计算对数</li>\n</ul>\n<h2 id=\"nn-BCELoss\"><a href=\"#nn-BCELoss\" class=\"headerlink\" title=\"nn.BCELoss\"></a>nn.BCELoss</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.BCELoss(weight=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算方法-2\"><a href=\"#计算方法-2\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><p><code>BCELoss</code>是专门针对二分类问题的交叉熵损失函数。其计算形式更加接近式(1): </p>\n<p>$$<br>\\mathcal{L}(x_n,y_n) = -w_n\\left[y_n\\cdot\\log x_n + (1-y_n)\\cdot\\log(1-x_n)\\right]<br>$$</p>\n<h3 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>是否支持多类别分类：不支持。只支持二分类</li>\n<li>输入得分值域：$(0,1)$。常搭配$sigmoid$一起使用</li>\n<li>神经网络输出层是否需要激活/归一化: sigmoid进行归一化处理。</li>\n</ul>\n<p>Tips: 在实际使用时，出现过使用BCELoss时算法不收敛、AUC奇低，但换成NLLLoss后一切都很好用的情况。</p>\n<h2 id=\"对比表格\"><a href=\"#对比表格\" class=\"headerlink\" title=\"对比表格\"></a>对比表格</h2><table>\n<thead>\n<tr>\n<th align=\"left\">项目\\方法</th>\n<th align=\"left\">CrossEntropyLoss</th>\n<th align=\"left\">NLLLoss</th>\n<th align=\"left\">BCELoss</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">支持多分类</td>\n<td align=\"left\">是</td>\n<td align=\"left\">是</td>\n<td align=\"left\">否</td>\n</tr>\n<tr>\n<td align=\"left\"><code>y_pred</code>值域</td>\n<td align=\"left\">$(-\\infty,\\infty)$</td>\n<td align=\"left\">$(-\\infty,\\infty)$</td>\n<td align=\"left\">$(0,1)$</td>\n</tr>\n<tr>\n<td align=\"left\"><code>type(y_target)</code></td>\n<td align=\"left\"><code>torch.LongTensor</code></td>\n<td align=\"left\"><code>torch.LongTensor</code></td>\n<td align=\"left\"><code>torch.DoubleTensor</code></td>\n</tr>\n<tr>\n<td align=\"left\">输出层是否需要归一化</td>\n<td align=\"left\">否</td>\n<td align=\"left\"><code>LogSoftmax</code></td>\n<td align=\"left\"><code>sigmoid</code></td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"<p>CrossEntropyLoss, NLLLoss 和 BCELoss 本质上都是基于交叉熵(cross entropy)的分类器的损失函数。但是三个函数的输入格式、计算方法和性能（收敛速度）有很大差别。本文记录笔者对此三者的学习笔记和理解。<br>{:.info}</p>","more":"<h2 id=\"交叉熵-Cross-Entropy\"><a href=\"#交叉熵-Cross-Entropy\" class=\"headerlink\" title=\"交叉熵(Cross Entropy)\"></a>交叉熵(Cross Entropy)</h2><p>交叉熵(Cross Entropy)是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。或曰，概率分布 $p$ 和概率分布 $q$ 的相似程度。如果 $p$ 和 $q$ 越相似，那么越能用 $p$ 近似表示 $q$ 或用 $q$ 近似表示 $p$ 。定义交叉熵为：</p>\n<p>$$<br>H(p,q) = \\sum_x p(x)\\log \\left(\\frac{1}{q(x)}\\right)<br>$$</p>\n<p>注意交叉熵不满足对称性。</p>\n<h2 id=\"nn-CrossEntropyLoss\"><a href=\"#nn-CrossEntropyLoss\" class=\"headerlink\" title=\"nn.CrossEntropyLoss\"></a>nn.CrossEntropyLoss</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.CrossEntropyLoss(weight=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, ignore_index=-<span class=\"number\">100</span>, reduce=<span class=\"literal\">None</span>, reduction=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算方法\"><a href=\"#计算方法\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><p>根据<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\">pytorch官方文档</a>，CrossEntropyLoss的输入值为”unnormalized scores for each class”，即未限制在(0,1)上的各个类别的得分。其表达式为</p>\n<p>$$<br>loss(x,class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)<br>$$</p>\n<p>其中 $x$ 为一个样本，$class$ 为一个类别, $x[j]\\in(-\\infty,\\infty)$ 为分类器给样本 $x$ 在类别 $j$ 上赋予的得分，或当weight不为空时，</p>\n<p>$$<br>loss(x,class) = -weight[class]\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])} \\right)<br>$$</p>\n<p>其中 $weight[class]$ 为类别 $class$ 的权重。其值越大，总损失中 $class$ 类所占有的损失项的比重越大。</p>\n<p>最终，总损失为每个样本$x$上的损失的加权平均，即</p>\n<p>$$<br>\\mathcal{L}(X,class) = \\frac{\\sum_{x\\in X}loss(x,class[x])}{\\sum_{x\\in X}weight[class[x]]}<br>$$</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>是否支持多类别分类：支持</li>\n<li>输入得分值域：$(-\\infty,\\infty)$</li>\n<li>神经网络输出层是否需要激活/归一化: 不用</li>\n</ul>\n<h2 id=\"nn-NLLLoss\"><a href=\"#nn-NLLLoss\" class=\"headerlink\" title=\"nn.NLLLoss\"></a>nn.NLLLoss</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.NLLLoss(weight=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, ignore_index=-<span class=\"number\">100</span>, reduce=<span class=\"literal\">None</span>, reduction=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算方法-1\"><a href=\"#计算方法-1\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><p><code>NLLLoss</code>的用法，实际在<code>CrossEntropyLoss</code>的文档中给出：</p>\n<p>This criterion combines <strong>LogSoftmax</strong> and <strong>NLLLoss</strong> in one single class.<br>{:.success}</p>\n<p>也就是说，<code>CrossEntropyLoss</code>是<code>NLLLoss</code>和<code>LogSoftmax</code>的结合体。为看清这一点，我们回到式(2)。其中 $\\log\\frac{\\exp(\\cdot)}{\\sum_j \\exp(\\cdot)}$ 就是LogSoftmax.</p>\n<p>因此，如果<code>CrossEntropyLoss</code>的输入值是 $(x,class)$， 那么 <code>NLLLoss</code> 的输入值就是 $LogSoftmax(x), class$。其中 $LogSoftmax(\\cdot)$ 需要对 $x$ 的每个分量计算一次，最终 $dim(LogSoftmax(x)) = dim(x)$。除此之外，<code>NLLLoss</code> 在其他部分的计算过程与 <code>CrossEntropyLoss</code> 完全一致。</p>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>是否支持多类别分类：支持</li>\n<li>输入得分值域：$(-\\infty,\\infty)$</li>\n<li>神经网络输出层是否需要激活/归一化: 需要，最后一层使用LogSoftmax.也可在神经网络中使用softmax或sigmoid，在计算损失函数时显式加入torch.log计算对数</li>\n</ul>\n<h2 id=\"nn-BCELoss\"><a href=\"#nn-BCELoss\" class=\"headerlink\" title=\"nn.BCELoss\"></a>nn.BCELoss</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.BCELoss(weight=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算方法-2\"><a href=\"#计算方法-2\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><p><code>BCELoss</code>是专门针对二分类问题的交叉熵损失函数。其计算形式更加接近式(1): </p>\n<p>$$<br>\\mathcal{L}(x_n,y_n) = -w_n\\left[y_n\\cdot\\log x_n + (1-y_n)\\cdot\\log(1-x_n)\\right]<br>$$</p>\n<h3 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>是否支持多类别分类：不支持。只支持二分类</li>\n<li>输入得分值域：$(0,1)$。常搭配$sigmoid$一起使用</li>\n<li>神经网络输出层是否需要激活/归一化: sigmoid进行归一化处理。</li>\n</ul>\n<p>Tips: 在实际使用时，出现过使用BCELoss时算法不收敛、AUC奇低，但换成NLLLoss后一切都很好用的情况。</p>\n<h2 id=\"对比表格\"><a href=\"#对比表格\" class=\"headerlink\" title=\"对比表格\"></a>对比表格</h2><table>\n<thead>\n<tr>\n<th align=\"left\">项目\\方法</th>\n<th align=\"left\">CrossEntropyLoss</th>\n<th align=\"left\">NLLLoss</th>\n<th align=\"left\">BCELoss</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">支持多分类</td>\n<td align=\"left\">是</td>\n<td align=\"left\">是</td>\n<td align=\"left\">否</td>\n</tr>\n<tr>\n<td align=\"left\"><code>y_pred</code>值域</td>\n<td align=\"left\">$(-\\infty,\\infty)$</td>\n<td align=\"left\">$(-\\infty,\\infty)$</td>\n<td align=\"left\">$(0,1)$</td>\n</tr>\n<tr>\n<td align=\"left\"><code>type(y_target)</code></td>\n<td align=\"left\"><code>torch.LongTensor</code></td>\n<td align=\"left\"><code>torch.LongTensor</code></td>\n<td align=\"left\"><code>torch.DoubleTensor</code></td>\n</tr>\n<tr>\n<td align=\"left\">输出层是否需要归一化</td>\n<td align=\"left\">否</td>\n<td align=\"left\"><code>LogSoftmax</code></td>\n<td align=\"left\"><code>sigmoid</code></td>\n</tr>\n</tbody></table>"},{"title":"消融实验(ablation study)","author":"LiJT","date":"2021-10-17T16:00:00.000Z","key":"ablation20211018","_content":"\n## 前言\n\n在深度学习领域论文的实验设计中，经常看到作者提出的模型与“弱化版”模型（少了某些模块、少了参数的限制...等等）的对比，用于说明idea或者某模块的有效性，这便是直观意义上的消融实验。\n\n<!--more-->\n\n## 定义与解释\n\nRobert Long对消融研究（或消融实验）定义：通常用于神经网络，尤其是相对复杂的神经网络，如R-CNN。我们的想法是通过删除部分网络并研究网络的性能来了解网络\n{:.success}\n\n### 例子\n参考[知乎](https://www.zhihu.com/question/291655038/answer/2000381383):\n\n论文提了3个贡献点，A,B,C\n\n- 你去掉A，其它保持不变，发现效果降低了，那说明A确实有用。\n\n- 你去掉B，其它保持不变，发现效果降的比A还多，说明B更重要。\n\n- 你去掉C，其它保持不变，发现效果没变，那C就是凑字数的\n\n### 个人想法\n消融实验是一种简单直观但符合逻辑的实验方法。相比于选取经典算法作为baseline实验，消融实验排除了trick、其他结构上的不同导致的性能影响，而只专注于检验idea的有效性，相当于论文工作的“自己和自己比”，一边是加入了idea的自己，一边是没有加入idea的自己。\n\n可以把消融实验用“控制变量法”和“正交回归”类比。\n\n\n","source":"_posts/2021-10-18-ablation.md","raw":"---\ntitle: 消融实验(ablation study)\nauthor: LiJT\ndate: 2021-10-18\ntags: \n  - 深度学习 \n  - 实验\nkey: ablation20211018\n---\n\n## 前言\n\n在深度学习领域论文的实验设计中，经常看到作者提出的模型与“弱化版”模型（少了某些模块、少了参数的限制...等等）的对比，用于说明idea或者某模块的有效性，这便是直观意义上的消融实验。\n\n<!--more-->\n\n## 定义与解释\n\nRobert Long对消融研究（或消融实验）定义：通常用于神经网络，尤其是相对复杂的神经网络，如R-CNN。我们的想法是通过删除部分网络并研究网络的性能来了解网络\n{:.success}\n\n### 例子\n参考[知乎](https://www.zhihu.com/question/291655038/answer/2000381383):\n\n论文提了3个贡献点，A,B,C\n\n- 你去掉A，其它保持不变，发现效果降低了，那说明A确实有用。\n\n- 你去掉B，其它保持不变，发现效果降的比A还多，说明B更重要。\n\n- 你去掉C，其它保持不变，发现效果没变，那C就是凑字数的\n\n### 个人想法\n消融实验是一种简单直观但符合逻辑的实验方法。相比于选取经典算法作为baseline实验，消融实验排除了trick、其他结构上的不同导致的性能影响，而只专注于检验idea的有效性，相当于论文工作的“自己和自己比”，一边是加入了idea的自己，一边是没有加入idea的自己。\n\n可以把消融实验用“控制变量法”和“正交回归”类比。\n\n\n","slug":"2021-10-18-ablation","published":1,"updated":"2022-04-06T09:44:40.657Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8l000ahsv9asp58s8l","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在深度学习领域论文的实验设计中，经常看到作者提出的模型与“弱化版”模型（少了某些模块、少了参数的限制…等等）的对比，用于说明idea或者某模块的有效性，这便是直观意义上的消融实验。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"定义与解释\"><a href=\"#定义与解释\" class=\"headerlink\" title=\"定义与解释\"></a>定义与解释</h2><p>Robert Long对消融研究（或消融实验）定义：通常用于神经网络，尤其是相对复杂的神经网络，如R-CNN。我们的想法是通过删除部分网络并研究网络的性能来了解网络<br>{:.success}</p>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><p>参考<a href=\"https://www.zhihu.com/question/291655038/answer/2000381383\">知乎</a>:</p>\n<p>论文提了3个贡献点，A,B,C</p>\n<ul>\n<li><p>你去掉A，其它保持不变，发现效果降低了，那说明A确实有用。</p>\n</li>\n<li><p>你去掉B，其它保持不变，发现效果降的比A还多，说明B更重要。</p>\n</li>\n<li><p>你去掉C，其它保持不变，发现效果没变，那C就是凑字数的</p>\n</li>\n</ul>\n<h3 id=\"个人想法\"><a href=\"#个人想法\" class=\"headerlink\" title=\"个人想法\"></a>个人想法</h3><p>消融实验是一种简单直观但符合逻辑的实验方法。相比于选取经典算法作为baseline实验，消融实验排除了trick、其他结构上的不同导致的性能影响，而只专注于检验idea的有效性，相当于论文工作的“自己和自己比”，一边是加入了idea的自己，一边是没有加入idea的自己。</p>\n<p>可以把消融实验用“控制变量法”和“正交回归”类比。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在深度学习领域论文的实验设计中，经常看到作者提出的模型与“弱化版”模型（少了某些模块、少了参数的限制…等等）的对比，用于说明idea或者某模块的有效性，这便是直观意义上的消融实验。</p>","more":"<h2 id=\"定义与解释\"><a href=\"#定义与解释\" class=\"headerlink\" title=\"定义与解释\"></a>定义与解释</h2><p>Robert Long对消融研究（或消融实验）定义：通常用于神经网络，尤其是相对复杂的神经网络，如R-CNN。我们的想法是通过删除部分网络并研究网络的性能来了解网络<br>{:.success}</p>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><p>参考<a href=\"https://www.zhihu.com/question/291655038/answer/2000381383\">知乎</a>:</p>\n<p>论文提了3个贡献点，A,B,C</p>\n<ul>\n<li><p>你去掉A，其它保持不变，发现效果降低了，那说明A确实有用。</p>\n</li>\n<li><p>你去掉B，其它保持不变，发现效果降的比A还多，说明B更重要。</p>\n</li>\n<li><p>你去掉C，其它保持不变，发现效果没变，那C就是凑字数的</p>\n</li>\n</ul>\n<h3 id=\"个人想法\"><a href=\"#个人想法\" class=\"headerlink\" title=\"个人想法\"></a>个人想法</h3><p>消融实验是一种简单直观但符合逻辑的实验方法。相比于选取经典算法作为baseline实验，消融实验排除了trick、其他结构上的不同导致的性能影响，而只专注于检验idea的有效性，相当于论文工作的“自己和自己比”，一边是加入了idea的自己，一边是没有加入idea的自己。</p>\n<p>可以把消融实验用“控制变量法”和“正交回归”类比。</p>"},{"title":"Python踩坑记录&小技巧(持续更新)","author":"LiJT","date":"2021-10-24T16:00:00.000Z","key":"python20211025","_content":"\n本篇主要介绍一些使用的python技巧和第三方库，包括某些方法(method)的骚操作\n\n<!--more-->\n\n## Matplotlib-绘图库\n### 保存图片内容溢出的问题\n- 有些图片，如果label太长，可能会出现保存区域小于原图片大小，导致部分内容在保存文件中缺失的问题。在此情况下，使用 `bbox_inches = 'tight'` 选项：\n  \n```py\nimport matplotlib.pyplot as plt\n\n# 原保存方法\nplt.savefig('pic.png', dpi = 1000)\n\n# 修正后保存方法\nplt.savefig('pic.png', dpi = 1000, bbox_inches = 'tight')\n```\n\n\n## Numpy-矩阵运算库\n### np.unique 可以同时获取unique key和频数\n```python\noutcome_s, frequency_s=np.unique(samples,return_counts=True)\n```\n### np.intersect1d 可以获取两个一维数组的交集\n```python\nA=np.array([1,2,3,4,5])\nB=np.array([3,4,6,0,7])\nC=np.intersect1d(A,B) # C=[3,4]\n```\n\n<!--more-->\n\n## PyTorch-深度学习库\n- 重要的事情说三遍：\n  - 不要将维数设为0！\n  - 不要将维数设为0！\n  - 不要将维度设为0！\n  \n在深度学习的消融实验中，常常需要去掉某个模块来验证其有效性。不要简单地将位数设为0！维度最少要为1.这是因为在某些版本的torch中，如果模型参数是 (N,0) 维的，那么使用torch.save()时会保存N个相应的参数值；但在torch.load()阶段，模型期望接收参数数量为0，所以模型load不进去！\n{:.error}\n\n\n- 指定load模型的目标设备\n\n```py\nimport torch\n\ntorch.load(map_location=device)\n```\n\n## tqdm-进度条\n- tqdm 可以枚举迭代操作，同时显示进度条——再也不用每隔多少步输出一次结果了！\n- 以下为ipython演示结果\n\n```python\nIn [22]: import tqdm\n    ...: li = [i for i in range(999999)]\n    ...: mn = 99999999\n    ...: for elem in tqdm.tqdm(li,'progress:'):\n    ...:   mn = min(mn,elem)\n    ...:\nprogress:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 999999/999999 [00:00<00:00, 2086298.02it/s]\n\n```","source":"_posts/2021-10-25-python.md","raw":"---\ntitle: Python踩坑记录&小技巧(持续更新)\nauthor: LiJT\ndate: 2021-10-25\ntags: \n  - Python \n  - coding \n  - 持续更新\nkey: python20211025\n---\n\n本篇主要介绍一些使用的python技巧和第三方库，包括某些方法(method)的骚操作\n\n<!--more-->\n\n## Matplotlib-绘图库\n### 保存图片内容溢出的问题\n- 有些图片，如果label太长，可能会出现保存区域小于原图片大小，导致部分内容在保存文件中缺失的问题。在此情况下，使用 `bbox_inches = 'tight'` 选项：\n  \n```py\nimport matplotlib.pyplot as plt\n\n# 原保存方法\nplt.savefig('pic.png', dpi = 1000)\n\n# 修正后保存方法\nplt.savefig('pic.png', dpi = 1000, bbox_inches = 'tight')\n```\n\n\n## Numpy-矩阵运算库\n### np.unique 可以同时获取unique key和频数\n```python\noutcome_s, frequency_s=np.unique(samples,return_counts=True)\n```\n### np.intersect1d 可以获取两个一维数组的交集\n```python\nA=np.array([1,2,3,4,5])\nB=np.array([3,4,6,0,7])\nC=np.intersect1d(A,B) # C=[3,4]\n```\n\n<!--more-->\n\n## PyTorch-深度学习库\n- 重要的事情说三遍：\n  - 不要将维数设为0！\n  - 不要将维数设为0！\n  - 不要将维度设为0！\n  \n在深度学习的消融实验中，常常需要去掉某个模块来验证其有效性。不要简单地将位数设为0！维度最少要为1.这是因为在某些版本的torch中，如果模型参数是 (N,0) 维的，那么使用torch.save()时会保存N个相应的参数值；但在torch.load()阶段，模型期望接收参数数量为0，所以模型load不进去！\n{:.error}\n\n\n- 指定load模型的目标设备\n\n```py\nimport torch\n\ntorch.load(map_location=device)\n```\n\n## tqdm-进度条\n- tqdm 可以枚举迭代操作，同时显示进度条——再也不用每隔多少步输出一次结果了！\n- 以下为ipython演示结果\n\n```python\nIn [22]: import tqdm\n    ...: li = [i for i in range(999999)]\n    ...: mn = 99999999\n    ...: for elem in tqdm.tqdm(li,'progress:'):\n    ...:   mn = min(mn,elem)\n    ...:\nprogress:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 999999/999999 [00:00<00:00, 2086298.02it/s]\n\n```","slug":"2021-10-25-python","published":1,"updated":"2022-04-06T09:46:06.378Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8m000bhsv9duy61zlu","content":"<p>本篇主要介绍一些使用的python技巧和第三方库，包括某些方法(method)的骚操作</p>\n<span id=\"more\"></span>\n\n<h2 id=\"Matplotlib-绘图库\"><a href=\"#Matplotlib-绘图库\" class=\"headerlink\" title=\"Matplotlib-绘图库\"></a>Matplotlib-绘图库</h2><h3 id=\"保存图片内容溢出的问题\"><a href=\"#保存图片内容溢出的问题\" class=\"headerlink\" title=\"保存图片内容溢出的问题\"></a>保存图片内容溢出的问题</h3><ul>\n<li>有些图片，如果label太长，可能会出现保存区域小于原图片大小，导致部分内容在保存文件中缺失的问题。在此情况下，使用 <code>bbox_inches = &#39;tight&#39;</code> 选项：</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 原保存方法</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">&#x27;pic.png&#x27;</span>, dpi = <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 修正后保存方法</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">&#x27;pic.png&#x27;</span>, dpi = <span class=\"number\">1000</span>, bbox_inches = <span class=\"string\">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"Numpy-矩阵运算库\"><a href=\"#Numpy-矩阵运算库\" class=\"headerlink\" title=\"Numpy-矩阵运算库\"></a>Numpy-矩阵运算库</h2><h3 id=\"np-unique-可以同时获取unique-key和频数\"><a href=\"#np-unique-可以同时获取unique-key和频数\" class=\"headerlink\" title=\"np.unique 可以同时获取unique key和频数\"></a>np.unique 可以同时获取unique key和频数</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">outcome_s, frequency_s=np.unique(samples,return_counts=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"np-intersect1d-可以获取两个一维数组的交集\"><a href=\"#np-intersect1d-可以获取两个一维数组的交集\" class=\"headerlink\" title=\"np.intersect1d 可以获取两个一维数组的交集\"></a>np.intersect1d 可以获取两个一维数组的交集</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>])</span><br><span class=\"line\">B=np.array([<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>,<span class=\"number\">0</span>,<span class=\"number\">7</span>])</span><br><span class=\"line\">C=np.intersect1d(A,B) <span class=\"comment\"># C=[3,4]</span></span><br></pre></td></tr></table></figure>\n\n<!--more-->\n\n<h2 id=\"PyTorch-深度学习库\"><a href=\"#PyTorch-深度学习库\" class=\"headerlink\" title=\"PyTorch-深度学习库\"></a>PyTorch-深度学习库</h2><ul>\n<li>重要的事情说三遍：<ul>\n<li>不要将维数设为0！</li>\n<li>不要将维数设为0！</li>\n<li>不要将维度设为0！</li>\n</ul>\n</li>\n</ul>\n<p>在深度学习的消融实验中，常常需要去掉某个模块来验证其有效性。不要简单地将位数设为0！维度最少要为1.这是因为在某些版本的torch中，如果模型参数是 (N,0) 维的，那么使用torch.save()时会保存N个相应的参数值；但在torch.load()阶段，模型期望接收参数数量为0，所以模型load不进去！<br>{:.error}</p>\n<ul>\n<li>指定load模型的目标设备</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">torch.load(map_location=device)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"tqdm-进度条\"><a href=\"#tqdm-进度条\" class=\"headerlink\" title=\"tqdm-进度条\"></a>tqdm-进度条</h2><ul>\n<li>tqdm 可以枚举迭代操作，同时显示进度条——再也不用每隔多少步输出一次结果了！</li>\n<li>以下为ipython演示结果</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">22</span>]: <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">    ...: li = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">999999</span>)]</span><br><span class=\"line\">    ...: mn = <span class=\"number\">99999999</span></span><br><span class=\"line\">    ...: <span class=\"keyword\">for</span> elem <span class=\"keyword\">in</span> tqdm.tqdm(li,<span class=\"string\">&#x27;progress:&#x27;</span>):</span><br><span class=\"line\">    ...:   mn = <span class=\"built_in\">min</span>(mn,elem)</span><br><span class=\"line\">    ...:</span><br><span class=\"line\">progress:: <span class=\"number\">100</span>%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| <span class=\"number\">999999</span>/<span class=\"number\">999999</span> [<span class=\"number\">00</span>:<span class=\"number\">00</span>&lt;<span class=\"number\">00</span>:<span class=\"number\">00</span>, <span class=\"number\">2086298.02</span>it/s]</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>本篇主要介绍一些使用的python技巧和第三方库，包括某些方法(method)的骚操作</p>","more":"<h2 id=\"Matplotlib-绘图库\"><a href=\"#Matplotlib-绘图库\" class=\"headerlink\" title=\"Matplotlib-绘图库\"></a>Matplotlib-绘图库</h2><h3 id=\"保存图片内容溢出的问题\"><a href=\"#保存图片内容溢出的问题\" class=\"headerlink\" title=\"保存图片内容溢出的问题\"></a>保存图片内容溢出的问题</h3><ul>\n<li>有些图片，如果label太长，可能会出现保存区域小于原图片大小，导致部分内容在保存文件中缺失的问题。在此情况下，使用 <code>bbox_inches = &#39;tight&#39;</code> 选项：</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 原保存方法</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">&#x27;pic.png&#x27;</span>, dpi = <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 修正后保存方法</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">&#x27;pic.png&#x27;</span>, dpi = <span class=\"number\">1000</span>, bbox_inches = <span class=\"string\">&#x27;tight&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"Numpy-矩阵运算库\"><a href=\"#Numpy-矩阵运算库\" class=\"headerlink\" title=\"Numpy-矩阵运算库\"></a>Numpy-矩阵运算库</h2><h3 id=\"np-unique-可以同时获取unique-key和频数\"><a href=\"#np-unique-可以同时获取unique-key和频数\" class=\"headerlink\" title=\"np.unique 可以同时获取unique key和频数\"></a>np.unique 可以同时获取unique key和频数</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">outcome_s, frequency_s=np.unique(samples,return_counts=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"np-intersect1d-可以获取两个一维数组的交集\"><a href=\"#np-intersect1d-可以获取两个一维数组的交集\" class=\"headerlink\" title=\"np.intersect1d 可以获取两个一维数组的交集\"></a>np.intersect1d 可以获取两个一维数组的交集</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>])</span><br><span class=\"line\">B=np.array([<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>,<span class=\"number\">0</span>,<span class=\"number\">7</span>])</span><br><span class=\"line\">C=np.intersect1d(A,B) <span class=\"comment\"># C=[3,4]</span></span><br></pre></td></tr></table></figure>\n\n<!--more-->\n\n<h2 id=\"PyTorch-深度学习库\"><a href=\"#PyTorch-深度学习库\" class=\"headerlink\" title=\"PyTorch-深度学习库\"></a>PyTorch-深度学习库</h2><ul>\n<li>重要的事情说三遍：<ul>\n<li>不要将维数设为0！</li>\n<li>不要将维数设为0！</li>\n<li>不要将维度设为0！</li>\n</ul>\n</li>\n</ul>\n<p>在深度学习的消融实验中，常常需要去掉某个模块来验证其有效性。不要简单地将位数设为0！维度最少要为1.这是因为在某些版本的torch中，如果模型参数是 (N,0) 维的，那么使用torch.save()时会保存N个相应的参数值；但在torch.load()阶段，模型期望接收参数数量为0，所以模型load不进去！<br>{:.error}</p>\n<ul>\n<li>指定load模型的目标设备</li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">torch.load(map_location=device)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"tqdm-进度条\"><a href=\"#tqdm-进度条\" class=\"headerlink\" title=\"tqdm-进度条\"></a>tqdm-进度条</h2><ul>\n<li>tqdm 可以枚举迭代操作，同时显示进度条——再也不用每隔多少步输出一次结果了！</li>\n<li>以下为ipython演示结果</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">22</span>]: <span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">    ...: li = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">999999</span>)]</span><br><span class=\"line\">    ...: mn = <span class=\"number\">99999999</span></span><br><span class=\"line\">    ...: <span class=\"keyword\">for</span> elem <span class=\"keyword\">in</span> tqdm.tqdm(li,<span class=\"string\">&#x27;progress:&#x27;</span>):</span><br><span class=\"line\">    ...:   mn = <span class=\"built_in\">min</span>(mn,elem)</span><br><span class=\"line\">    ...:</span><br><span class=\"line\">progress:: <span class=\"number\">100</span>%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| <span class=\"number\">999999</span>/<span class=\"number\">999999</span> [<span class=\"number\">00</span>:<span class=\"number\">00</span>&lt;<span class=\"number\">00</span>:<span class=\"number\">00</span>, <span class=\"number\">2086298.02</span>it/s]</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"正则表达式学习笔记(持续更新)","author":"LiJT","date":"2021-10-25T16:00:00.000Z","key":"regex20211026","_content":"\n## 基础部分\n- 工具：egrep. `egrep '[regular expression]' filename`\n\n### 行首行尾\n```python\n^ : 标记一行的开始位置\n$ : 标记一行的结束位置\n\n# 例子\n^cat : 匹配以cat为行首的行，例如 catter\ncat$ : 匹配以cat为结尾的行，例如 scat\n```\n\n<!--more-->\n\n### 字符类\n#### 匹配任意字符\n\n```python\n[...] : 匹配中括号中的任意一个字符，中括号称为字符类\n\n# 例子\ngr[ea]y : 匹配 grey 或 gray, r 和 y 之间可以是e或者a\nsep[ea]r[ea]te : 匹配 seperate 或 separete 或 separate 或 seperete\n<H[123456]> : 匹配 <H1> 到 <H6>， 在html匹配中常见\n```\n\n```python\n- : 划定字符范围\n\n# 例子\n[1-6]=[123456]\n[0-9a-fA-F]=[0123456789abcdefABCDEF]\n```\n\n#### 否定字符类\n```python\n[^...] : 匹配任意不在中括号中的字符，与 [...] 相反\n\n# 例子：\n[^1-6] : 匹配不在 1-6 中的字符\nq[^u] : 匹配包含 q~， 其中 ~ 为不是字母u的其他字符的所有行\n```\n- 当 ^ 在中括号外面时表示行首标识符；当 ^ 在中括号里面时表示否定运算符\n\n### 使用 '.' 匹配 *任意* 字符\n```python\n. : 匹配任意字符\n[.] : 无转义，匹配dot\n\n# 例子：\n03.19.76 : 匹配 03~19~76，其中~可以是任意字符\n03[-./]19[-./]76 : 以分隔符 . - 或 / 匹配 031976\n```\n\n### 多个正则表达式\n- 考虑如何将多个正则表达式结合到一起\n  \n```python\n| : 或运算， a | b 表示匹配正则表达式或正则表达式b。为了限定或运算范围，必要时用小括号括起来，例如 (a|b)\n\n# 例子\ngr(a|e)y = gr[ae]y\n^(From|Subject|Date): 匹配以From:或Subject:或Date:开头的行\n```\n\n### 使用'?'匹配可选字符\n- 考虑匹配 colour 或 color，这里的 u 可选出现或不出现\n\n```python\n? : 可选运算，u? 表示匹配出现u或不出现u，作用对象为?的前一个字符\n\n# 例子\ncolou?r = (color|colour)\n```\n\n### 匹配重复字符\n- 考虑一个字符重复多次： goooooooooooooooooood!，但是次数不定\n\n```python\n+ : 匹配一个字符1次或多次（至少1次）\n* : 匹配一个字符0次或多次（至少0次）\n\n# 例子：\ngoo+d: 匹配good,goood,goo...od\ngoo*d: 匹配god, good, ...\n<HR +SIZE *= *[0-9]+ *>: 空格可以出现任意多次\n\n```\n\n|运算符|字符最小出现次数|字符最大出现次数|\n|:---|:---|:---|\n|?|0|1|\n|+|1|无限|\n|*|0|无限|\n\n#### 自定义字符重复次数\n```python\nu{min, max} : 匹配字符u最小重复min次，最大重复max次。尽可能多地统计\n\n# 例子：\n[a-zA-Z]{3,8}: 匹配3至8个连续出现的英文字母（尽可能多）\n```\n\n## Python re 模块要点\n### 转义字符\n- 上述正则表达式规则基于Linux的egrep。针对Python的re模块，另有一些重要的转义字符可以用\n\n|字符|功能\n|:---|:---\n|\\d\t|匹配数字，即[0-9]\t可以写在字符集[...]中\n|\\D\t|匹配⾮数字，即不是数字\t可以写在字符集[...]中\n|\\s\t|匹配空⽩，即空格，tab键\t可以写在字符集[...]中\n|\\S\t|匹配⾮空⽩字符\t可以写在字符集[...]中\n|\\w\t|匹配单词字符，即[a-zA-Z0-9_]\t可以写在字符集[...]中\n|\\W\t|匹配⾮单词字符\t可以写在字符集[...]中\n\n### re 模块常用函数及注意事项\n\n待补充\n{:.warning}\n\n## 练习：常用正则表达式(Python re格式)\n- 电子邮箱 `\\w{1,10}\\.?\\w{1,10}@(163|gmail|qq).com`\n- 日期 `\\d{4}[.-/]\\d{2}[.-/]\\d{2}`\n- HTTP/HTML URL `\\<http://[^ ]+\\.html?\\>`\n\n## 参考资料\n- Jeffrey E.F.Friedl, Mastering Regular Expressions\n- [python——正则表达式(re模块)详解. 版权声明：本文为CSDN博主「nee~」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。](https://blog.csdn.net/guo_qingxia/article/details/113979135)\n\n\n","source":"_posts/2021-10-26-regex.md","raw":"---\ntitle: 正则表达式学习笔记(持续更新)\nauthor: LiJT\ndate: 2021-10-26\ntags: \n  - coding \n  - 持续更新\nkey: regex20211026\n---\n\n## 基础部分\n- 工具：egrep. `egrep '[regular expression]' filename`\n\n### 行首行尾\n```python\n^ : 标记一行的开始位置\n$ : 标记一行的结束位置\n\n# 例子\n^cat : 匹配以cat为行首的行，例如 catter\ncat$ : 匹配以cat为结尾的行，例如 scat\n```\n\n<!--more-->\n\n### 字符类\n#### 匹配任意字符\n\n```python\n[...] : 匹配中括号中的任意一个字符，中括号称为字符类\n\n# 例子\ngr[ea]y : 匹配 grey 或 gray, r 和 y 之间可以是e或者a\nsep[ea]r[ea]te : 匹配 seperate 或 separete 或 separate 或 seperete\n<H[123456]> : 匹配 <H1> 到 <H6>， 在html匹配中常见\n```\n\n```python\n- : 划定字符范围\n\n# 例子\n[1-6]=[123456]\n[0-9a-fA-F]=[0123456789abcdefABCDEF]\n```\n\n#### 否定字符类\n```python\n[^...] : 匹配任意不在中括号中的字符，与 [...] 相反\n\n# 例子：\n[^1-6] : 匹配不在 1-6 中的字符\nq[^u] : 匹配包含 q~， 其中 ~ 为不是字母u的其他字符的所有行\n```\n- 当 ^ 在中括号外面时表示行首标识符；当 ^ 在中括号里面时表示否定运算符\n\n### 使用 '.' 匹配 *任意* 字符\n```python\n. : 匹配任意字符\n[.] : 无转义，匹配dot\n\n# 例子：\n03.19.76 : 匹配 03~19~76，其中~可以是任意字符\n03[-./]19[-./]76 : 以分隔符 . - 或 / 匹配 031976\n```\n\n### 多个正则表达式\n- 考虑如何将多个正则表达式结合到一起\n  \n```python\n| : 或运算， a | b 表示匹配正则表达式或正则表达式b。为了限定或运算范围，必要时用小括号括起来，例如 (a|b)\n\n# 例子\ngr(a|e)y = gr[ae]y\n^(From|Subject|Date): 匹配以From:或Subject:或Date:开头的行\n```\n\n### 使用'?'匹配可选字符\n- 考虑匹配 colour 或 color，这里的 u 可选出现或不出现\n\n```python\n? : 可选运算，u? 表示匹配出现u或不出现u，作用对象为?的前一个字符\n\n# 例子\ncolou?r = (color|colour)\n```\n\n### 匹配重复字符\n- 考虑一个字符重复多次： goooooooooooooooooood!，但是次数不定\n\n```python\n+ : 匹配一个字符1次或多次（至少1次）\n* : 匹配一个字符0次或多次（至少0次）\n\n# 例子：\ngoo+d: 匹配good,goood,goo...od\ngoo*d: 匹配god, good, ...\n<HR +SIZE *= *[0-9]+ *>: 空格可以出现任意多次\n\n```\n\n|运算符|字符最小出现次数|字符最大出现次数|\n|:---|:---|:---|\n|?|0|1|\n|+|1|无限|\n|*|0|无限|\n\n#### 自定义字符重复次数\n```python\nu{min, max} : 匹配字符u最小重复min次，最大重复max次。尽可能多地统计\n\n# 例子：\n[a-zA-Z]{3,8}: 匹配3至8个连续出现的英文字母（尽可能多）\n```\n\n## Python re 模块要点\n### 转义字符\n- 上述正则表达式规则基于Linux的egrep。针对Python的re模块，另有一些重要的转义字符可以用\n\n|字符|功能\n|:---|:---\n|\\d\t|匹配数字，即[0-9]\t可以写在字符集[...]中\n|\\D\t|匹配⾮数字，即不是数字\t可以写在字符集[...]中\n|\\s\t|匹配空⽩，即空格，tab键\t可以写在字符集[...]中\n|\\S\t|匹配⾮空⽩字符\t可以写在字符集[...]中\n|\\w\t|匹配单词字符，即[a-zA-Z0-9_]\t可以写在字符集[...]中\n|\\W\t|匹配⾮单词字符\t可以写在字符集[...]中\n\n### re 模块常用函数及注意事项\n\n待补充\n{:.warning}\n\n## 练习：常用正则表达式(Python re格式)\n- 电子邮箱 `\\w{1,10}\\.?\\w{1,10}@(163|gmail|qq).com`\n- 日期 `\\d{4}[.-/]\\d{2}[.-/]\\d{2}`\n- HTTP/HTML URL `\\<http://[^ ]+\\.html?\\>`\n\n## 参考资料\n- Jeffrey E.F.Friedl, Mastering Regular Expressions\n- [python——正则表达式(re模块)详解. 版权声明：本文为CSDN博主「nee~」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。](https://blog.csdn.net/guo_qingxia/article/details/113979135)\n\n\n","slug":"2021-10-26-regex","published":1,"updated":"2022-04-06T09:46:41.582Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8n000dhsv99kjk2dem","content":"<h2 id=\"基础部分\"><a href=\"#基础部分\" class=\"headerlink\" title=\"基础部分\"></a>基础部分</h2><ul>\n<li>工具：egrep. <code>egrep &#39;[regular expression]&#39; filename</code></li>\n</ul>\n<h3 id=\"行首行尾\"><a href=\"#行首行尾\" class=\"headerlink\" title=\"行首行尾\"></a>行首行尾</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">^ : 标记一行的开始位置</span><br><span class=\"line\">$ : 标记一行的结束位置</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">^cat : 匹配以cat为行首的行，例如 catter</span><br><span class=\"line\">cat$ : 匹配以cat为结尾的行，例如 scat</span><br></pre></td></tr></table></figure>\n\n<span id=\"more\"></span>\n\n<h3 id=\"字符类\"><a href=\"#字符类\" class=\"headerlink\" title=\"字符类\"></a>字符类</h3><h4 id=\"匹配任意字符\"><a href=\"#匹配任意字符\" class=\"headerlink\" title=\"匹配任意字符\"></a>匹配任意字符</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[...] : 匹配中括号中的任意一个字符，中括号称为字符类</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">gr[ea]y : 匹配 grey 或 gray, r 和 y 之间可以是e或者a</span><br><span class=\"line\">sep[ea]r[ea]te : 匹配 seperate 或 separete 或 separate 或 seperete</span><br><span class=\"line\">&lt;H[<span class=\"number\">123456</span>]&gt; : 匹配 &lt;H1&gt; 到 &lt;H6&gt;， 在html匹配中常见</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- : 划定字符范围</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">[<span class=\"number\">1</span>-<span class=\"number\">6</span>]=[<span class=\"number\">123456</span>]</span><br><span class=\"line\">[<span class=\"number\">0</span>-9a-fA-F]=[0123456789abcdefABCDEF]</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"否定字符类\"><a href=\"#否定字符类\" class=\"headerlink\" title=\"否定字符类\"></a>否定字符类</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[^...] : 匹配任意不在中括号中的字符，与 [...] 相反</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\">[^<span class=\"number\">1</span>-<span class=\"number\">6</span>] : 匹配不在 <span class=\"number\">1</span>-<span class=\"number\">6</span> 中的字符</span><br><span class=\"line\">q[^u] : 匹配包含 q~， 其中 ~ 为不是字母u的其他字符的所有行</span><br></pre></td></tr></table></figure>\n<ul>\n<li>当 ^ 在中括号外面时表示行首标识符；当 ^ 在中括号里面时表示否定运算符</li>\n</ul>\n<h3 id=\"使用-‘-’-匹配-任意-字符\"><a href=\"#使用-‘-’-匹配-任意-字符\" class=\"headerlink\" title=\"使用 ‘.’ 匹配 任意 字符\"></a>使用 ‘.’ 匹配 <em>任意</em> 字符</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">. : 匹配任意字符</span><br><span class=\"line\">[.] : 无转义，匹配dot</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\"><span class=\"number\">03.19</span><span class=\"number\">.76</span> : 匹配 03~<span class=\"number\">19</span>~<span class=\"number\">76</span>，其中~可以是任意字符</span><br><span class=\"line\">03[-./]<span class=\"number\">19</span>[-./]<span class=\"number\">76</span> : 以分隔符 . - 或 / 匹配 031976</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"多个正则表达式\"><a href=\"#多个正则表达式\" class=\"headerlink\" title=\"多个正则表达式\"></a>多个正则表达式</h3><ul>\n<li>考虑如何将多个正则表达式结合到一起</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">| : 或运算， a | b 表示匹配正则表达式或正则表达式b。为了限定或运算范围，必要时用小括号括起来，例如 (a|b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">gr(a|e)y = gr[ae]y</span><br><span class=\"line\">^(From|Subject|Date): 匹配以From:或Subject:或Date:开头的行</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用’-’匹配可选字符\"><a href=\"#使用’-’匹配可选字符\" class=\"headerlink\" title=\"使用’?’匹配可选字符\"></a>使用’?’匹配可选字符</h3><ul>\n<li>考虑匹配 colour 或 color，这里的 u 可选出现或不出现</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">? : 可选运算，u? 表示匹配出现u或不出现u，作用对象为?的前一个字符</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">colou?r = (color|colour)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"匹配重复字符\"><a href=\"#匹配重复字符\" class=\"headerlink\" title=\"匹配重复字符\"></a>匹配重复字符</h3><ul>\n<li>考虑一个字符重复多次： goooooooooooooooooood!，但是次数不定</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ : 匹配一个字符<span class=\"number\">1</span>次或多次（至少<span class=\"number\">1</span>次）</span><br><span class=\"line\">* : 匹配一个字符<span class=\"number\">0</span>次或多次（至少<span class=\"number\">0</span>次）</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\">goo+d: 匹配good,goood,goo...od</span><br><span class=\"line\">goo*d: 匹配god, good, ...</span><br><span class=\"line\">&lt;HR +SIZE *= *[<span class=\"number\">0</span>-<span class=\"number\">9</span>]+ *&gt;: 空格可以出现任意多次</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">运算符</th>\n<th align=\"left\">字符最小出现次数</th>\n<th align=\"left\">字符最大出现次数</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">?</td>\n<td align=\"left\">0</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">+</td>\n<td align=\"left\">1</td>\n<td align=\"left\">无限</td>\n</tr>\n<tr>\n<td align=\"left\">*</td>\n<td align=\"left\">0</td>\n<td align=\"left\">无限</td>\n</tr>\n</tbody></table>\n<h4 id=\"自定义字符重复次数\"><a href=\"#自定义字符重复次数\" class=\"headerlink\" title=\"自定义字符重复次数\"></a>自定义字符重复次数</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">u&#123;<span class=\"built_in\">min</span>, <span class=\"built_in\">max</span>&#125; : 匹配字符u最小重复<span class=\"built_in\">min</span>次，最大重复<span class=\"built_in\">max</span>次。尽可能多地统计</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\">[a-zA-Z]&#123;<span class=\"number\">3</span>,<span class=\"number\">8</span>&#125;: 匹配<span class=\"number\">3</span>至<span class=\"number\">8</span>个连续出现的英文字母（尽可能多）</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Python-re-模块要点\"><a href=\"#Python-re-模块要点\" class=\"headerlink\" title=\"Python re 模块要点\"></a>Python re 模块要点</h2><h3 id=\"转义字符\"><a href=\"#转义字符\" class=\"headerlink\" title=\"转义字符\"></a>转义字符</h3><ul>\n<li>上述正则表达式规则基于Linux的egrep。针对Python的re模块，另有一些重要的转义字符可以用</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"left\">字符</th>\n<th align=\"left\">功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">\\d</td>\n<td align=\"left\">匹配数字，即[0-9]    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\D</td>\n<td align=\"left\">匹配⾮数字，即不是数字    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\s</td>\n<td align=\"left\">匹配空⽩，即空格，tab键    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\S</td>\n<td align=\"left\">匹配⾮空⽩字符    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\w</td>\n<td align=\"left\">匹配单词字符，即[a-zA-Z0-9_]    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\W</td>\n<td align=\"left\">匹配⾮单词字符    可以写在字符集[…]中</td>\n</tr>\n</tbody></table>\n<h3 id=\"re-模块常用函数及注意事项\"><a href=\"#re-模块常用函数及注意事项\" class=\"headerlink\" title=\"re 模块常用函数及注意事项\"></a>re 模块常用函数及注意事项</h3><p>待补充<br>{:.warning}</p>\n<h2 id=\"练习：常用正则表达式-Python-re格式\"><a href=\"#练习：常用正则表达式-Python-re格式\" class=\"headerlink\" title=\"练习：常用正则表达式(Python re格式)\"></a>练习：常用正则表达式(Python re格式)</h2><ul>\n<li>电子邮箱 <code>\\w&#123;1,10&#125;\\.?\\w&#123;1,10&#125;@(163|gmail|qq).com</code></li>\n<li>日期 <code>\\d&#123;4&#125;[.-/]\\d&#123;2&#125;[.-/]\\d&#123;2&#125;</code></li>\n<li>HTTP/HTML URL <code>\\&lt;http://[^ ]+\\.html?\\&gt;</code></li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>Jeffrey E.F.Friedl, Mastering Regular Expressions</li>\n<li><a href=\"https://blog.csdn.net/guo_qingxia/article/details/113979135\">python——正则表达式(re模块)详解. 版权声明：本文为CSDN博主「nee~」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"基础部分\"><a href=\"#基础部分\" class=\"headerlink\" title=\"基础部分\"></a>基础部分</h2><ul>\n<li>工具：egrep. <code>egrep &#39;[regular expression]&#39; filename</code></li>\n</ul>\n<h3 id=\"行首行尾\"><a href=\"#行首行尾\" class=\"headerlink\" title=\"行首行尾\"></a>行首行尾</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">^ : 标记一行的开始位置</span><br><span class=\"line\">$ : 标记一行的结束位置</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">^cat : 匹配以cat为行首的行，例如 catter</span><br><span class=\"line\">cat$ : 匹配以cat为结尾的行，例如 scat</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"字符类\"><a href=\"#字符类\" class=\"headerlink\" title=\"字符类\"></a>字符类</h3><h4 id=\"匹配任意字符\"><a href=\"#匹配任意字符\" class=\"headerlink\" title=\"匹配任意字符\"></a>匹配任意字符</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[...] : 匹配中括号中的任意一个字符，中括号称为字符类</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">gr[ea]y : 匹配 grey 或 gray, r 和 y 之间可以是e或者a</span><br><span class=\"line\">sep[ea]r[ea]te : 匹配 seperate 或 separete 或 separate 或 seperete</span><br><span class=\"line\">&lt;H[<span class=\"number\">123456</span>]&gt; : 匹配 &lt;H1&gt; 到 &lt;H6&gt;， 在html匹配中常见</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- : 划定字符范围</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">[<span class=\"number\">1</span>-<span class=\"number\">6</span>]=[<span class=\"number\">123456</span>]</span><br><span class=\"line\">[<span class=\"number\">0</span>-9a-fA-F]=[0123456789abcdefABCDEF]</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"否定字符类\"><a href=\"#否定字符类\" class=\"headerlink\" title=\"否定字符类\"></a>否定字符类</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[^...] : 匹配任意不在中括号中的字符，与 [...] 相反</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\">[^<span class=\"number\">1</span>-<span class=\"number\">6</span>] : 匹配不在 <span class=\"number\">1</span>-<span class=\"number\">6</span> 中的字符</span><br><span class=\"line\">q[^u] : 匹配包含 q~， 其中 ~ 为不是字母u的其他字符的所有行</span><br></pre></td></tr></table></figure>\n<ul>\n<li>当 ^ 在中括号外面时表示行首标识符；当 ^ 在中括号里面时表示否定运算符</li>\n</ul>\n<h3 id=\"使用-‘-’-匹配-任意-字符\"><a href=\"#使用-‘-’-匹配-任意-字符\" class=\"headerlink\" title=\"使用 ‘.’ 匹配 任意 字符\"></a>使用 ‘.’ 匹配 <em>任意</em> 字符</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">. : 匹配任意字符</span><br><span class=\"line\">[.] : 无转义，匹配dot</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\"><span class=\"number\">03.19</span><span class=\"number\">.76</span> : 匹配 03~<span class=\"number\">19</span>~<span class=\"number\">76</span>，其中~可以是任意字符</span><br><span class=\"line\">03[-./]<span class=\"number\">19</span>[-./]<span class=\"number\">76</span> : 以分隔符 . - 或 / 匹配 031976</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"多个正则表达式\"><a href=\"#多个正则表达式\" class=\"headerlink\" title=\"多个正则表达式\"></a>多个正则表达式</h3><ul>\n<li>考虑如何将多个正则表达式结合到一起</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">| : 或运算， a | b 表示匹配正则表达式或正则表达式b。为了限定或运算范围，必要时用小括号括起来，例如 (a|b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">gr(a|e)y = gr[ae]y</span><br><span class=\"line\">^(From|Subject|Date): 匹配以From:或Subject:或Date:开头的行</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用’-’匹配可选字符\"><a href=\"#使用’-’匹配可选字符\" class=\"headerlink\" title=\"使用’?’匹配可选字符\"></a>使用’?’匹配可选字符</h3><ul>\n<li>考虑匹配 colour 或 color，这里的 u 可选出现或不出现</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">? : 可选运算，u? 表示匹配出现u或不出现u，作用对象为?的前一个字符</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子</span></span><br><span class=\"line\">colou?r = (color|colour)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"匹配重复字符\"><a href=\"#匹配重复字符\" class=\"headerlink\" title=\"匹配重复字符\"></a>匹配重复字符</h3><ul>\n<li>考虑一个字符重复多次： goooooooooooooooooood!，但是次数不定</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ : 匹配一个字符<span class=\"number\">1</span>次或多次（至少<span class=\"number\">1</span>次）</span><br><span class=\"line\">* : 匹配一个字符<span class=\"number\">0</span>次或多次（至少<span class=\"number\">0</span>次）</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\">goo+d: 匹配good,goood,goo...od</span><br><span class=\"line\">goo*d: 匹配god, good, ...</span><br><span class=\"line\">&lt;HR +SIZE *= *[<span class=\"number\">0</span>-<span class=\"number\">9</span>]+ *&gt;: 空格可以出现任意多次</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">运算符</th>\n<th align=\"left\">字符最小出现次数</th>\n<th align=\"left\">字符最大出现次数</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">?</td>\n<td align=\"left\">0</td>\n<td align=\"left\">1</td>\n</tr>\n<tr>\n<td align=\"left\">+</td>\n<td align=\"left\">1</td>\n<td align=\"left\">无限</td>\n</tr>\n<tr>\n<td align=\"left\">*</td>\n<td align=\"left\">0</td>\n<td align=\"left\">无限</td>\n</tr>\n</tbody></table>\n<h4 id=\"自定义字符重复次数\"><a href=\"#自定义字符重复次数\" class=\"headerlink\" title=\"自定义字符重复次数\"></a>自定义字符重复次数</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">u&#123;<span class=\"built_in\">min</span>, <span class=\"built_in\">max</span>&#125; : 匹配字符u最小重复<span class=\"built_in\">min</span>次，最大重复<span class=\"built_in\">max</span>次。尽可能多地统计</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例子：</span></span><br><span class=\"line\">[a-zA-Z]&#123;<span class=\"number\">3</span>,<span class=\"number\">8</span>&#125;: 匹配<span class=\"number\">3</span>至<span class=\"number\">8</span>个连续出现的英文字母（尽可能多）</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Python-re-模块要点\"><a href=\"#Python-re-模块要点\" class=\"headerlink\" title=\"Python re 模块要点\"></a>Python re 模块要点</h2><h3 id=\"转义字符\"><a href=\"#转义字符\" class=\"headerlink\" title=\"转义字符\"></a>转义字符</h3><ul>\n<li>上述正则表达式规则基于Linux的egrep。针对Python的re模块，另有一些重要的转义字符可以用</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"left\">字符</th>\n<th align=\"left\">功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">\\d</td>\n<td align=\"left\">匹配数字，即[0-9]    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\D</td>\n<td align=\"left\">匹配⾮数字，即不是数字    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\s</td>\n<td align=\"left\">匹配空⽩，即空格，tab键    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\S</td>\n<td align=\"left\">匹配⾮空⽩字符    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\w</td>\n<td align=\"left\">匹配单词字符，即[a-zA-Z0-9_]    可以写在字符集[…]中</td>\n</tr>\n<tr>\n<td align=\"left\">\\W</td>\n<td align=\"left\">匹配⾮单词字符    可以写在字符集[…]中</td>\n</tr>\n</tbody></table>\n<h3 id=\"re-模块常用函数及注意事项\"><a href=\"#re-模块常用函数及注意事项\" class=\"headerlink\" title=\"re 模块常用函数及注意事项\"></a>re 模块常用函数及注意事项</h3><p>待补充<br>{:.warning}</p>\n<h2 id=\"练习：常用正则表达式-Python-re格式\"><a href=\"#练习：常用正则表达式-Python-re格式\" class=\"headerlink\" title=\"练习：常用正则表达式(Python re格式)\"></a>练习：常用正则表达式(Python re格式)</h2><ul>\n<li>电子邮箱 <code>\\w&#123;1,10&#125;\\.?\\w&#123;1,10&#125;@(163|gmail|qq).com</code></li>\n<li>日期 <code>\\d&#123;4&#125;[.-/]\\d&#123;2&#125;[.-/]\\d&#123;2&#125;</code></li>\n<li>HTTP/HTML URL <code>\\&lt;http://[^ ]+\\.html?\\&gt;</code></li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>Jeffrey E.F.Friedl, Mastering Regular Expressions</li>\n<li><a href=\"https://blog.csdn.net/guo_qingxia/article/details/113979135\">python——正则表达式(re模块)详解. 版权声明：本文为CSDN博主「nee~」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</a></li>\n</ul>"},{"title":"一些杂谈.1","author":"LiJT","date":"2021-11-22T16:00:00.000Z","key":"delicacy20211123","_content":"\n```\n不被时间和社会所束缚\n幸福地填饱肚子的时候\n那一瞬间 他已变得唯我独尊\n自由自在\n无需介怀地大快朵颐 这种孤高的行为\n正可谓是现代人被平等赋予的\n最高治愈\n——孤独的美食家\n```\n<!--more-->\n\n最近在看《孤独的美食家》，计划从第一季一口气追到第九季。每天总是夜深人静的时间点亮屏幕，看着酥脆的可乐饼、麻辣鲜香的担担面、热气腾腾的关东煮在眼前呈现。虽然折磨，但实在是欲罢不能。\n\n真正的美食，不一定要登大雅之堂，不一定要呈现在五星级酒店，不一定非要松茸加身，鱼子酱包裹。美食可以是路边小馆的羊汤，可以是家庭餐厅的石锅拌饭。美食之美，只有自己的舌、胃、心能够体会。\n\n\n\n","source":"_posts/2021-11-23-delicacy.md","raw":"---\ntitle: 一些杂谈.1\nauthor: LiJT\ndate: 2021-11-23\ntags: \n  - 美食 \n  - 杂谈\nkey: delicacy20211123\n---\n\n```\n不被时间和社会所束缚\n幸福地填饱肚子的时候\n那一瞬间 他已变得唯我独尊\n自由自在\n无需介怀地大快朵颐 这种孤高的行为\n正可谓是现代人被平等赋予的\n最高治愈\n——孤独的美食家\n```\n<!--more-->\n\n最近在看《孤独的美食家》，计划从第一季一口气追到第九季。每天总是夜深人静的时间点亮屏幕，看着酥脆的可乐饼、麻辣鲜香的担担面、热气腾腾的关东煮在眼前呈现。虽然折磨，但实在是欲罢不能。\n\n真正的美食，不一定要登大雅之堂，不一定要呈现在五星级酒店，不一定非要松茸加身，鱼子酱包裹。美食可以是路边小馆的羊汤，可以是家庭餐厅的石锅拌饭。美食之美，只有自己的舌、胃、心能够体会。\n\n\n\n","slug":"2021-11-23-delicacy","published":1,"updated":"2022-04-06T09:47:11.857Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8o000ehsv95b6h4c3m","content":"<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">不被时间和社会所束缚</span><br><span class=\"line\">幸福地填饱肚子的时候</span><br><span class=\"line\">那一瞬间 他已变得唯我独尊</span><br><span class=\"line\">自由自在</span><br><span class=\"line\">无需介怀地大快朵颐 这种孤高的行为</span><br><span class=\"line\">正可谓是现代人被平等赋予的</span><br><span class=\"line\">最高治愈</span><br><span class=\"line\">——孤独的美食家</span><br></pre></td></tr></table></figure>\n<span id=\"more\"></span>\n\n<p>最近在看《孤独的美食家》，计划从第一季一口气追到第九季。每天总是夜深人静的时间点亮屏幕，看着酥脆的可乐饼、麻辣鲜香的担担面、热气腾腾的关东煮在眼前呈现。虽然折磨，但实在是欲罢不能。</p>\n<p>真正的美食，不一定要登大雅之堂，不一定要呈现在五星级酒店，不一定非要松茸加身，鱼子酱包裹。美食可以是路边小馆的羊汤，可以是家庭餐厅的石锅拌饭。美食之美，只有自己的舌、胃、心能够体会。</p>\n","site":{"data":{}},"excerpt":"<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">不被时间和社会所束缚</span><br><span class=\"line\">幸福地填饱肚子的时候</span><br><span class=\"line\">那一瞬间 他已变得唯我独尊</span><br><span class=\"line\">自由自在</span><br><span class=\"line\">无需介怀地大快朵颐 这种孤高的行为</span><br><span class=\"line\">正可谓是现代人被平等赋予的</span><br><span class=\"line\">最高治愈</span><br><span class=\"line\">——孤独的美食家</span><br></pre></td></tr></table></figure>","more":"<p>最近在看《孤独的美食家》，计划从第一季一口气追到第九季。每天总是夜深人静的时间点亮屏幕，看着酥脆的可乐饼、麻辣鲜香的担担面、热气腾腾的关东煮在眼前呈现。虽然折磨，但实在是欲罢不能。</p>\n<p>真正的美食，不一定要登大雅之堂，不一定要呈现在五星级酒店，不一定非要松茸加身，鱼子酱包裹。美食可以是路边小馆的羊汤，可以是家庭餐厅的石锅拌饭。美食之美，只有自己的舌、胃、心能够体会。</p>"},{"title":"记一次vscode remote-ssh登录失败的解决方案","author":"LiJT","date":"2021-11-25T16:00:00.000Z","key":"vscode20211126","_content":"\n我的vscode remote-ssh设置了[免密登录](https://www.jianshu.com/p/32aa2fa936bb)，本来昨天上午还能正常登录，但昨晚开始登录失败，怀疑是vscode版本更新后动了某些配置。参考一些资料后，总结了如下的解决方案.\n<!--more-->\n\n- 环境：本地 win11，服务器 linux\n\n## 步骤1.更改Remote-SSH设置\n- 一种可能导致登录失败的理由是，更新后的remote-ssh缺失了`\"remote.SSH.useLocalServer: true\"`的配置。为此，我们进入remote-ssh的settings.json中查看配置情况：\n1. 点击vscode左边栏“扩展”或按`Ctrl+Shift+X`，找到remote-ssh插件，点击右下角的小齿轮，进入设置页面 \n   \n   ![1](/LiJT-Daily/images/2021112601.png)\n2. 在设置页面，找到\"在settings.json编辑\"按钮，点击进入\n   \n   ![2](/LiJT-Daily/images/2021112602.png)\n3. 在settings.json中，检查是否有`\"remote.SSH.useLocalServer\"`选项。如果没有，则在最外层大括号内添加`\"remote.SSH.useLocalServer\": true`；如果有且值为`false`，则将值修改为`true`。修改后结果如下所示\n   \n   ![3](/LiJT-Daily/images/2021112603.png)\n4. 保存settings.json，重新启动vscode，尝试远程登录。\n\n## 步骤2.清空远程~/.vscode-server文件夹\n- 如果步骤1不能解决问题，则可以尝试步骤2.步骤2相比于步骤1，是强制初始化远程vscode环境。\n\n1. __关闭vscode server__。在本地vscode中按`Ctrl+Shift+P`进入命令面板，输入`Kill VS Code Server on Host`，选中Remote-SSH中的对应命令，强制关闭对应的vscode server。这一步一定不能省略，否则下一步将无法删除 ~/.vscode-server 文件\n   \n   ![4](/LiJT-Daily/images/2021112604.png)\n2. 强制删除~/.vscode-server。vscode 服务器环境统一存储在~/.vscode-server中，其中~表示自己服务器账号的根目录。使用如下命令删除该文件夹：\n```\nrm -rf ~/.vscode-server\n```\n3. 重新启动vscode，尝试远程登录。此时服务器会自动下载新的~/.vscode-server文件，待下载完成、配置完成后，即可使用。\n\n## 更新 (2021.11.27)\n- 当vscode remote-ssh 未关闭而电脑休眠后再唤醒时，会出现相同的登陆失败的问题。直接采用步骤2，问题解决\n\n## 参考资料\n- [非root用户配置VS Code Remote-SSH - - windows系统](https://www.jianshu.com/p/32aa2fa936bb)\n- [Resolver error: Error: The VS Code Server failed to start 的一种解决方案](https://www.cnblogs.com/springwind2006/p/14311454.html)\n- [vs code远程开发 SSH连接失败](https://blog.csdn.net/weilin731/article/details/119778478)\n- [vscode ssh连接失败](https://blog.csdn.net/myWorld001/article/details/119443079?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link)\n","source":"_posts/2021-11-26-vscode.md","raw":"---\ntitle: 记一次vscode remote-ssh登录失败的解决方案\nauthor: LiJT\ndate: 2021-11-26\ntags: \n   - coding \n   - vscode \n   - ssh\nkey: vscode20211126\n---\n\n我的vscode remote-ssh设置了[免密登录](https://www.jianshu.com/p/32aa2fa936bb)，本来昨天上午还能正常登录，但昨晚开始登录失败，怀疑是vscode版本更新后动了某些配置。参考一些资料后，总结了如下的解决方案.\n<!--more-->\n\n- 环境：本地 win11，服务器 linux\n\n## 步骤1.更改Remote-SSH设置\n- 一种可能导致登录失败的理由是，更新后的remote-ssh缺失了`\"remote.SSH.useLocalServer: true\"`的配置。为此，我们进入remote-ssh的settings.json中查看配置情况：\n1. 点击vscode左边栏“扩展”或按`Ctrl+Shift+X`，找到remote-ssh插件，点击右下角的小齿轮，进入设置页面 \n   \n   ![1](/LiJT-Daily/images/2021112601.png)\n2. 在设置页面，找到\"在settings.json编辑\"按钮，点击进入\n   \n   ![2](/LiJT-Daily/images/2021112602.png)\n3. 在settings.json中，检查是否有`\"remote.SSH.useLocalServer\"`选项。如果没有，则在最外层大括号内添加`\"remote.SSH.useLocalServer\": true`；如果有且值为`false`，则将值修改为`true`。修改后结果如下所示\n   \n   ![3](/LiJT-Daily/images/2021112603.png)\n4. 保存settings.json，重新启动vscode，尝试远程登录。\n\n## 步骤2.清空远程~/.vscode-server文件夹\n- 如果步骤1不能解决问题，则可以尝试步骤2.步骤2相比于步骤1，是强制初始化远程vscode环境。\n\n1. __关闭vscode server__。在本地vscode中按`Ctrl+Shift+P`进入命令面板，输入`Kill VS Code Server on Host`，选中Remote-SSH中的对应命令，强制关闭对应的vscode server。这一步一定不能省略，否则下一步将无法删除 ~/.vscode-server 文件\n   \n   ![4](/LiJT-Daily/images/2021112604.png)\n2. 强制删除~/.vscode-server。vscode 服务器环境统一存储在~/.vscode-server中，其中~表示自己服务器账号的根目录。使用如下命令删除该文件夹：\n```\nrm -rf ~/.vscode-server\n```\n3. 重新启动vscode，尝试远程登录。此时服务器会自动下载新的~/.vscode-server文件，待下载完成、配置完成后，即可使用。\n\n## 更新 (2021.11.27)\n- 当vscode remote-ssh 未关闭而电脑休眠后再唤醒时，会出现相同的登陆失败的问题。直接采用步骤2，问题解决\n\n## 参考资料\n- [非root用户配置VS Code Remote-SSH - - windows系统](https://www.jianshu.com/p/32aa2fa936bb)\n- [Resolver error: Error: The VS Code Server failed to start 的一种解决方案](https://www.cnblogs.com/springwind2006/p/14311454.html)\n- [vs code远程开发 SSH连接失败](https://blog.csdn.net/weilin731/article/details/119778478)\n- [vscode ssh连接失败](https://blog.csdn.net/myWorld001/article/details/119443079?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link)\n","slug":"2021-11-26-vscode","published":1,"updated":"2022-04-06T09:47:50.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8p000ghsv924nf2gyu","content":"<p>我的vscode remote-ssh设置了<a href=\"https://www.jianshu.com/p/32aa2fa936bb\">免密登录</a>，本来昨天上午还能正常登录，但昨晚开始登录失败，怀疑是vscode版本更新后动了某些配置。参考一些资料后，总结了如下的解决方案.</p>\n<span id=\"more\"></span>\n\n<ul>\n<li>环境：本地 win11，服务器 linux</li>\n</ul>\n<h2 id=\"步骤1-更改Remote-SSH设置\"><a href=\"#步骤1-更改Remote-SSH设置\" class=\"headerlink\" title=\"步骤1.更改Remote-SSH设置\"></a>步骤1.更改Remote-SSH设置</h2><ul>\n<li>一种可能导致登录失败的理由是，更新后的remote-ssh缺失了<code>&quot;remote.SSH.useLocalServer: true&quot;</code>的配置。为此，我们进入remote-ssh的settings.json中查看配置情况：</li>\n</ul>\n<ol>\n<li>点击vscode左边栏“扩展”或按<code>Ctrl+Shift+X</code>，找到remote-ssh插件，点击右下角的小齿轮，进入设置页面 <img src=\"/LiJT-Daily/images/2021112601.png\" alt=\"1\"></li>\n<li>在设置页面，找到”在settings.json编辑”按钮，点击进入<img src=\"/LiJT-Daily/images/2021112602.png\" alt=\"2\"></li>\n<li>在settings.json中，检查是否有<code>&quot;remote.SSH.useLocalServer&quot;</code>选项。如果没有，则在最外层大括号内添加<code>&quot;remote.SSH.useLocalServer&quot;: true</code>；如果有且值为<code>false</code>，则将值修改为<code>true</code>。修改后结果如下所示<img src=\"/LiJT-Daily/images/2021112603.png\" alt=\"3\"></li>\n<li>保存settings.json，重新启动vscode，尝试远程登录。</li>\n</ol>\n<h2 id=\"步骤2-清空远程-vscode-server文件夹\"><a href=\"#步骤2-清空远程-vscode-server文件夹\" class=\"headerlink\" title=\"步骤2.清空远程~/.vscode-server文件夹\"></a>步骤2.清空远程~/.vscode-server文件夹</h2><ul>\n<li>如果步骤1不能解决问题，则可以尝试步骤2.步骤2相比于步骤1，是强制初始化远程vscode环境。</li>\n</ul>\n<ol>\n<li>__关闭vscode server__。在本地vscode中按<code>Ctrl+Shift+P</code>进入命令面板，输入<code>Kill VS Code Server on Host</code>，选中Remote-SSH中的对应命令，强制关闭对应的vscode server。这一步一定不能省略，否则下一步将无法删除 ~/.vscode-server 文件<img src=\"/LiJT-Daily/images/2021112604.png\" alt=\"4\"></li>\n<li>强制删除<del>/.vscode-server。vscode 服务器环境统一存储在</del>/.vscode-server中，其中~表示自己服务器账号的根目录。使用如下命令删除该文件夹：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rm -rf ~/.vscode-server</span><br></pre></td></tr></table></figure></li>\n<li>重新启动vscode，尝试远程登录。此时服务器会自动下载新的~/.vscode-server文件，待下载完成、配置完成后，即可使用。</li>\n</ol>\n<h2 id=\"更新-2021-11-27\"><a href=\"#更新-2021-11-27\" class=\"headerlink\" title=\"更新 (2021.11.27)\"></a>更新 (2021.11.27)</h2><ul>\n<li>当vscode remote-ssh 未关闭而电脑休眠后再唤醒时，会出现相同的登陆失败的问题。直接采用步骤2，问题解决</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://www.jianshu.com/p/32aa2fa936bb\">非root用户配置VS Code Remote-SSH - - windows系统</a></li>\n<li><a href=\"https://www.cnblogs.com/springwind2006/p/14311454.html\">Resolver error: Error: The VS Code Server failed to start 的一种解决方案</a></li>\n<li><a href=\"https://blog.csdn.net/weilin731/article/details/119778478\">vs code远程开发 SSH连接失败</a></li>\n<li><a href=\"https://blog.csdn.net/myWorld001/article/details/119443079?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link\">vscode ssh连接失败</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>我的vscode remote-ssh设置了<a href=\"https://www.jianshu.com/p/32aa2fa936bb\">免密登录</a>，本来昨天上午还能正常登录，但昨晚开始登录失败，怀疑是vscode版本更新后动了某些配置。参考一些资料后，总结了如下的解决方案.</p>","more":"<ul>\n<li>环境：本地 win11，服务器 linux</li>\n</ul>\n<h2 id=\"步骤1-更改Remote-SSH设置\"><a href=\"#步骤1-更改Remote-SSH设置\" class=\"headerlink\" title=\"步骤1.更改Remote-SSH设置\"></a>步骤1.更改Remote-SSH设置</h2><ul>\n<li>一种可能导致登录失败的理由是，更新后的remote-ssh缺失了<code>&quot;remote.SSH.useLocalServer: true&quot;</code>的配置。为此，我们进入remote-ssh的settings.json中查看配置情况：</li>\n</ul>\n<ol>\n<li>点击vscode左边栏“扩展”或按<code>Ctrl+Shift+X</code>，找到remote-ssh插件，点击右下角的小齿轮，进入设置页面 <img src=\"/LiJT-Daily/images/2021112601.png\" alt=\"1\"></li>\n<li>在设置页面，找到”在settings.json编辑”按钮，点击进入<img src=\"/LiJT-Daily/images/2021112602.png\" alt=\"2\"></li>\n<li>在settings.json中，检查是否有<code>&quot;remote.SSH.useLocalServer&quot;</code>选项。如果没有，则在最外层大括号内添加<code>&quot;remote.SSH.useLocalServer&quot;: true</code>；如果有且值为<code>false</code>，则将值修改为<code>true</code>。修改后结果如下所示<img src=\"/LiJT-Daily/images/2021112603.png\" alt=\"3\"></li>\n<li>保存settings.json，重新启动vscode，尝试远程登录。</li>\n</ol>\n<h2 id=\"步骤2-清空远程-vscode-server文件夹\"><a href=\"#步骤2-清空远程-vscode-server文件夹\" class=\"headerlink\" title=\"步骤2.清空远程~/.vscode-server文件夹\"></a>步骤2.清空远程~/.vscode-server文件夹</h2><ul>\n<li>如果步骤1不能解决问题，则可以尝试步骤2.步骤2相比于步骤1，是强制初始化远程vscode环境。</li>\n</ul>\n<ol>\n<li>__关闭vscode server__。在本地vscode中按<code>Ctrl+Shift+P</code>进入命令面板，输入<code>Kill VS Code Server on Host</code>，选中Remote-SSH中的对应命令，强制关闭对应的vscode server。这一步一定不能省略，否则下一步将无法删除 ~/.vscode-server 文件<img src=\"/LiJT-Daily/images/2021112604.png\" alt=\"4\"></li>\n<li>强制删除<del>/.vscode-server。vscode 服务器环境统一存储在</del>/.vscode-server中，其中~表示自己服务器账号的根目录。使用如下命令删除该文件夹：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rm -rf ~/.vscode-server</span><br></pre></td></tr></table></figure></li>\n<li>重新启动vscode，尝试远程登录。此时服务器会自动下载新的~/.vscode-server文件，待下载完成、配置完成后，即可使用。</li>\n</ol>\n<h2 id=\"更新-2021-11-27\"><a href=\"#更新-2021-11-27\" class=\"headerlink\" title=\"更新 (2021.11.27)\"></a>更新 (2021.11.27)</h2><ul>\n<li>当vscode remote-ssh 未关闭而电脑休眠后再唤醒时，会出现相同的登陆失败的问题。直接采用步骤2，问题解决</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://www.jianshu.com/p/32aa2fa936bb\">非root用户配置VS Code Remote-SSH - - windows系统</a></li>\n<li><a href=\"https://www.cnblogs.com/springwind2006/p/14311454.html\">Resolver error: Error: The VS Code Server failed to start 的一种解决方案</a></li>\n<li><a href=\"https://blog.csdn.net/weilin731/article/details/119778478\">vs code远程开发 SSH连接失败</a></li>\n<li><a href=\"https://blog.csdn.net/myWorld001/article/details/119443079?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link\">vscode ssh连接失败</a></li>\n</ul>"},{"title":"Hadoop 实战练习记录","author":"LiJT","date":"2021-12-12T16:00:00.000Z","key":"hadoop20211213","_content":"\n## 写在前面\n本篇记录Hadoop实战学习中的笔记以及问题分析。\n\n<!--more-->\n\n## Mapreduce 实战\n### Mapreduce 程序模型\n#### 什么是Mapreduce\nMapReduce是一种可用于数据处理的编程模型，我们现在设想一个场景，你接到一个任务，任务是：挖掘分析我国气象中心近年来的数据日志，该数据日志大小有3T,让你分析计算出每一年的最高气温，如果你现在只有一台计算机，如何处理呢？我想你应该会读取这些数据，并且将读取到的数据与目前的最大气温值进行比较。比较完所有的数据之后就可以得出最高气温了。不过以我们的经验都知道要处理这么多数据肯定是非常耗时的。\n\n如果我现在给你三台机器，你会如何处理呢？你应该想到了：最好的处理方式是将这些数据切分成三块，然后分别计算处理这些数据（Map），处理完毕之后发送到一台机器上进行合并（merge），再计算合并之后的数据，归纳（reduce）并输出。\n\n这就是一个比较完整的MapReduce的过程了。\n\n![Mapreduce原理](/LiJT-Daily/images/2021121301.png)\n\n#### Mapreduce程序结构(以Word Count为例)\n```java\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n \nimport java.io.IOException;\nimport java.util.StringTokenizer;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.*;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n//Mapper类\n/*LongWritable表示每一行起始偏移量\n第一个Text是用来接受文件中的内容，\n第二个Text是用来输出给Reduce类的key,\nIntWritable是用来输出给Reduce类的value*/\n public static class TokenizerMapper \n       extends Mapper<LongWritable, Text, Text, IntWritable>{\n    private final static IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n    public void map(LongWritable key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n      StringTokenizer itr = new StringTokenizer(value.toString());\n      while (itr.hasMoreTokens()) {\n        word.set(itr.nextToken());\n        context.write(word, one);\n      }\n    }\n  }\n  public static class IntSumReducer \n       extends Reducer<Text,IntWritable,Text,IntWritable> {\n    private IntWritable result = new IntWritable();\n    public void reduce(Text key, Iterable<IntWritable> values, \n                       Context context\n                       ) throws IOException, InterruptedException {\n      int sum = 0;\n      for (IntWritable val : values) {\n        sum += val.get();\n      }\n      result.set(sum);\n      context.write(key, result);\n    }\n  }\n  public static void main(String[] args) throws Exception {\n    //创建配置对象\n    Configuration conf = new Configuration();\n    //创建job对象\n    Job job = new Job(conf, \"word count\");\n    //设置运行job的类\n    job.setJarByClass(WordCount.class);\n    //设置Mapper的类\n    job.setMapperClass(TokenizerMapper.class);\n    //设置Reduce的类\n    job.setReducerClass(IntSumReducer.class);\n    //设置输出的key value格式\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(IntWritable.class);\n    //设置输入路径\n    String inputfile = \"/usr/input\";\n    //设置输出路径\n    String outputFile = \"/usr/output\";\n    //执行输入\n    FileInputFormat.addInputPath(job, new Path(inputfile));\n    //执行输出\n    FileOutputFormat.setOutputPath(job, new Path(outputFile));\n    //是否运行成功，true输出0，false输出1\n    System.exit(job.waitForCompletion(true) ? 0 : 1);\n  }\n}\n```\n## Hbase 实战\n这里主要记录Hbase shell里的一些常用指令\n\n#### 创建表\n新建一个名为`test`的表，使其中包含一个名为`data`的列，表和列族属性都为默认值：\n```sql\ncreate 'test','data'\n```\n\n创建完成后，我们可以输入`list`来查看表是否创建成功\n\n#### 添加数据\n我们来给上一关创建的`test`表的列`data`添加一些数据.使用`put`命令可以用来添加数据，使用`get`命令可以获取数据。\n```sql\nput 'test','row1','data:1','value1'\nput 'test','row2','data:2','value2'\nget 'test','row1'\n```\n\n输入`scan`命令就可以查看所有的数据了\n\n#### 删除数据和表\n删除整行数据：`deleteall [表名]，[行名称]`\n```sql\ndeleteall 'test','row1'\n```\n\n删除表需要先禁用、再删除。分为两步：\n```\ndisable 表名\ndrop 表名\n```","source":"_posts/2021-12-13-hadoop.md","raw":"---\ntitle: Hadoop 实战练习记录\nauthor: LiJT\ndate: 2021-12-13\ntags: \n  - 大数据 \n  - Java \n  - Hadoop \n  - Mapreduce\nkey: hadoop20211213\n---\n\n## 写在前面\n本篇记录Hadoop实战学习中的笔记以及问题分析。\n\n<!--more-->\n\n## Mapreduce 实战\n### Mapreduce 程序模型\n#### 什么是Mapreduce\nMapReduce是一种可用于数据处理的编程模型，我们现在设想一个场景，你接到一个任务，任务是：挖掘分析我国气象中心近年来的数据日志，该数据日志大小有3T,让你分析计算出每一年的最高气温，如果你现在只有一台计算机，如何处理呢？我想你应该会读取这些数据，并且将读取到的数据与目前的最大气温值进行比较。比较完所有的数据之后就可以得出最高气温了。不过以我们的经验都知道要处理这么多数据肯定是非常耗时的。\n\n如果我现在给你三台机器，你会如何处理呢？你应该想到了：最好的处理方式是将这些数据切分成三块，然后分别计算处理这些数据（Map），处理完毕之后发送到一台机器上进行合并（merge），再计算合并之后的数据，归纳（reduce）并输出。\n\n这就是一个比较完整的MapReduce的过程了。\n\n![Mapreduce原理](/LiJT-Daily/images/2021121301.png)\n\n#### Mapreduce程序结构(以Word Count为例)\n```java\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n \nimport java.io.IOException;\nimport java.util.StringTokenizer;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.*;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n//Mapper类\n/*LongWritable表示每一行起始偏移量\n第一个Text是用来接受文件中的内容，\n第二个Text是用来输出给Reduce类的key,\nIntWritable是用来输出给Reduce类的value*/\n public static class TokenizerMapper \n       extends Mapper<LongWritable, Text, Text, IntWritable>{\n    private final static IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n    public void map(LongWritable key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n      StringTokenizer itr = new StringTokenizer(value.toString());\n      while (itr.hasMoreTokens()) {\n        word.set(itr.nextToken());\n        context.write(word, one);\n      }\n    }\n  }\n  public static class IntSumReducer \n       extends Reducer<Text,IntWritable,Text,IntWritable> {\n    private IntWritable result = new IntWritable();\n    public void reduce(Text key, Iterable<IntWritable> values, \n                       Context context\n                       ) throws IOException, InterruptedException {\n      int sum = 0;\n      for (IntWritable val : values) {\n        sum += val.get();\n      }\n      result.set(sum);\n      context.write(key, result);\n    }\n  }\n  public static void main(String[] args) throws Exception {\n    //创建配置对象\n    Configuration conf = new Configuration();\n    //创建job对象\n    Job job = new Job(conf, \"word count\");\n    //设置运行job的类\n    job.setJarByClass(WordCount.class);\n    //设置Mapper的类\n    job.setMapperClass(TokenizerMapper.class);\n    //设置Reduce的类\n    job.setReducerClass(IntSumReducer.class);\n    //设置输出的key value格式\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(IntWritable.class);\n    //设置输入路径\n    String inputfile = \"/usr/input\";\n    //设置输出路径\n    String outputFile = \"/usr/output\";\n    //执行输入\n    FileInputFormat.addInputPath(job, new Path(inputfile));\n    //执行输出\n    FileOutputFormat.setOutputPath(job, new Path(outputFile));\n    //是否运行成功，true输出0，false输出1\n    System.exit(job.waitForCompletion(true) ? 0 : 1);\n  }\n}\n```\n## Hbase 实战\n这里主要记录Hbase shell里的一些常用指令\n\n#### 创建表\n新建一个名为`test`的表，使其中包含一个名为`data`的列，表和列族属性都为默认值：\n```sql\ncreate 'test','data'\n```\n\n创建完成后，我们可以输入`list`来查看表是否创建成功\n\n#### 添加数据\n我们来给上一关创建的`test`表的列`data`添加一些数据.使用`put`命令可以用来添加数据，使用`get`命令可以获取数据。\n```sql\nput 'test','row1','data:1','value1'\nput 'test','row2','data:2','value2'\nget 'test','row1'\n```\n\n输入`scan`命令就可以查看所有的数据了\n\n#### 删除数据和表\n删除整行数据：`deleteall [表名]，[行名称]`\n```sql\ndeleteall 'test','row1'\n```\n\n删除表需要先禁用、再删除。分为两步：\n```\ndisable 表名\ndrop 表名\n```","slug":"2021-12-13-hadoop","published":1,"updated":"2022-04-06T09:49:51.656Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8q000hhsv94r1o5liy","content":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>本篇记录Hadoop实战学习中的笔记以及问题分析。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"Mapreduce-实战\"><a href=\"#Mapreduce-实战\" class=\"headerlink\" title=\"Mapreduce 实战\"></a>Mapreduce 实战</h2><h3 id=\"Mapreduce-程序模型\"><a href=\"#Mapreduce-程序模型\" class=\"headerlink\" title=\"Mapreduce 程序模型\"></a>Mapreduce 程序模型</h3><h4 id=\"什么是Mapreduce\"><a href=\"#什么是Mapreduce\" class=\"headerlink\" title=\"什么是Mapreduce\"></a>什么是Mapreduce</h4><p>MapReduce是一种可用于数据处理的编程模型，我们现在设想一个场景，你接到一个任务，任务是：挖掘分析我国气象中心近年来的数据日志，该数据日志大小有3T,让你分析计算出每一年的最高气温，如果你现在只有一台计算机，如何处理呢？我想你应该会读取这些数据，并且将读取到的数据与目前的最大气温值进行比较。比较完所有的数据之后就可以得出最高气温了。不过以我们的经验都知道要处理这么多数据肯定是非常耗时的。</p>\n<p>如果我现在给你三台机器，你会如何处理呢？你应该想到了：最好的处理方式是将这些数据切分成三块，然后分别计算处理这些数据（Map），处理完毕之后发送到一台机器上进行合并（merge），再计算合并之后的数据，归纳（reduce）并输出。</p>\n<p>这就是一个比较完整的MapReduce的过程了。</p>\n<p><img src=\"/LiJT-Daily/images/2021121301.png\" alt=\"Mapreduce原理\"></p>\n<h4 id=\"Mapreduce程序结构-以Word-Count为例\"><a href=\"#Mapreduce程序结构-以Word-Count为例\" class=\"headerlink\" title=\"Mapreduce程序结构(以Word Count为例)\"></a>Mapreduce程序结构(以Word Count为例)</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.StringTokenizer;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.StringTokenizer;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.*;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">WordCount</span> &#123;</span><br><span class=\"line\"><span class=\"comment\">//Mapper类</span></span><br><span class=\"line\"><span class=\"comment\">/*LongWritable表示每一行起始偏移量</span></span><br><span class=\"line\"><span class=\"comment\">第一个Text是用来接受文件中的内容，</span></span><br><span class=\"line\"><span class=\"comment\">第二个Text是用来输出给Reduce类的key,</span></span><br><span class=\"line\"><span class=\"comment\">IntWritable是用来输出给Reduce类的value*/</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">class</span> <span class=\"title class_\">TokenizerMapper</span> </span><br><span class=\"line\">       <span class=\"keyword\">extends</span> <span class=\"title class_\">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt;&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"type\">IntWritable</span> <span class=\"variable\">one</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">IntWritable</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"type\">Text</span> <span class=\"variable\">word</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Text</span>();</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">map</span><span class=\"params\">(LongWritable key, Text value, Context context</span></span><br><span class=\"line\"><span class=\"params\">                    )</span> <span class=\"keyword\">throws</span> IOException, InterruptedException &#123;</span><br><span class=\"line\">      <span class=\"type\">StringTokenizer</span> <span class=\"variable\">itr</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">StringTokenizer</span>(value.toString());</span><br><span class=\"line\">      <span class=\"keyword\">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class=\"line\">        word.set(itr.nextToken());</span><br><span class=\"line\">        context.write(word, one);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">class</span> <span class=\"title class_\">IntSumReducer</span> </span><br><span class=\"line\">       <span class=\"keyword\">extends</span> <span class=\"title class_\">Reducer</span>&lt;Text,IntWritable,Text,IntWritable&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"type\">IntWritable</span> <span class=\"variable\">result</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">IntWritable</span>();</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">reduce</span><span class=\"params\">(Text key, Iterable&lt;IntWritable&gt; values, </span></span><br><span class=\"line\"><span class=\"params\">                       Context context</span></span><br><span class=\"line\"><span class=\"params\">                       )</span> <span class=\"keyword\">throws</span> IOException, InterruptedException &#123;</span><br><span class=\"line\">      <span class=\"type\">int</span> <span class=\"variable\">sum</span> <span class=\"operator\">=</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">      <span class=\"keyword\">for</span> (IntWritable val : values) &#123;</span><br><span class=\"line\">        sum += val.get();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      result.set(sum);</span><br><span class=\"line\">      context.write(key, result);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception &#123;</span><br><span class=\"line\">    <span class=\"comment\">//创建配置对象</span></span><br><span class=\"line\">    <span class=\"type\">Configuration</span> <span class=\"variable\">conf</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Configuration</span>();</span><br><span class=\"line\">    <span class=\"comment\">//创建job对象</span></span><br><span class=\"line\">    <span class=\"type\">Job</span> <span class=\"variable\">job</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Job</span>(conf, <span class=\"string\">&quot;word count&quot;</span>);</span><br><span class=\"line\">    <span class=\"comment\">//设置运行job的类</span></span><br><span class=\"line\">    job.setJarByClass(WordCount.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置Mapper的类</span></span><br><span class=\"line\">    job.setMapperClass(TokenizerMapper.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置Reduce的类</span></span><br><span class=\"line\">    job.setReducerClass(IntSumReducer.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置输出的key value格式</span></span><br><span class=\"line\">    job.setOutputKeyClass(Text.class);</span><br><span class=\"line\">    job.setOutputValueClass(IntWritable.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置输入路径</span></span><br><span class=\"line\">    <span class=\"type\">String</span> <span class=\"variable\">inputfile</span> <span class=\"operator\">=</span> <span class=\"string\">&quot;/usr/input&quot;</span>;</span><br><span class=\"line\">    <span class=\"comment\">//设置输出路径</span></span><br><span class=\"line\">    <span class=\"type\">String</span> <span class=\"variable\">outputFile</span> <span class=\"operator\">=</span> <span class=\"string\">&quot;/usr/output&quot;</span>;</span><br><span class=\"line\">    <span class=\"comment\">//执行输入</span></span><br><span class=\"line\">    FileInputFormat.addInputPath(job, <span class=\"keyword\">new</span> <span class=\"title class_\">Path</span>(inputfile));</span><br><span class=\"line\">    <span class=\"comment\">//执行输出</span></span><br><span class=\"line\">    FileOutputFormat.setOutputPath(job, <span class=\"keyword\">new</span> <span class=\"title class_\">Path</span>(outputFile));</span><br><span class=\"line\">    <span class=\"comment\">//是否运行成功，true输出0，false输出1</span></span><br><span class=\"line\">    System.exit(job.waitForCompletion(<span class=\"literal\">true</span>) ? <span class=\"number\">0</span> : <span class=\"number\">1</span>);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Hbase-实战\"><a href=\"#Hbase-实战\" class=\"headerlink\" title=\"Hbase 实战\"></a>Hbase 实战</h2><p>这里主要记录Hbase shell里的一些常用指令</p>\n<h4 id=\"创建表\"><a href=\"#创建表\" class=\"headerlink\" title=\"创建表\"></a>创建表</h4><p>新建一个名为<code>test</code>的表，使其中包含一个名为<code>data</code>的列，表和列族属性都为默认值：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>创建完成后，我们可以输入<code>list</code>来查看表是否创建成功</p>\n<h4 id=\"添加数据\"><a href=\"#添加数据\" class=\"headerlink\" title=\"添加数据\"></a>添加数据</h4><p>我们来给上一关创建的<code>test</code>表的列<code>data</code>添加一些数据.使用<code>put</code>命令可以用来添加数据，使用<code>get</code>命令可以获取数据。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">put <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row1&#x27;</span>,<span class=\"string\">&#x27;data:1&#x27;</span>,<span class=\"string\">&#x27;value1&#x27;</span></span><br><span class=\"line\">put <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row2&#x27;</span>,<span class=\"string\">&#x27;data:2&#x27;</span>,<span class=\"string\">&#x27;value2&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">get</span> <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row1&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>输入<code>scan</code>命令就可以查看所有的数据了</p>\n<h4 id=\"删除数据和表\"><a href=\"#删除数据和表\" class=\"headerlink\" title=\"删除数据和表\"></a>删除数据和表</h4><p>删除整行数据：<code>deleteall [表名]，[行名称]</code></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deleteall <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row1&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>删除表需要先禁用、再删除。分为两步：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">disable 表名</span><br><span class=\"line\">drop 表名</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>本篇记录Hadoop实战学习中的笔记以及问题分析。</p>","more":"<h2 id=\"Mapreduce-实战\"><a href=\"#Mapreduce-实战\" class=\"headerlink\" title=\"Mapreduce 实战\"></a>Mapreduce 实战</h2><h3 id=\"Mapreduce-程序模型\"><a href=\"#Mapreduce-程序模型\" class=\"headerlink\" title=\"Mapreduce 程序模型\"></a>Mapreduce 程序模型</h3><h4 id=\"什么是Mapreduce\"><a href=\"#什么是Mapreduce\" class=\"headerlink\" title=\"什么是Mapreduce\"></a>什么是Mapreduce</h4><p>MapReduce是一种可用于数据处理的编程模型，我们现在设想一个场景，你接到一个任务，任务是：挖掘分析我国气象中心近年来的数据日志，该数据日志大小有3T,让你分析计算出每一年的最高气温，如果你现在只有一台计算机，如何处理呢？我想你应该会读取这些数据，并且将读取到的数据与目前的最大气温值进行比较。比较完所有的数据之后就可以得出最高气温了。不过以我们的经验都知道要处理这么多数据肯定是非常耗时的。</p>\n<p>如果我现在给你三台机器，你会如何处理呢？你应该想到了：最好的处理方式是将这些数据切分成三块，然后分别计算处理这些数据（Map），处理完毕之后发送到一台机器上进行合并（merge），再计算合并之后的数据，归纳（reduce）并输出。</p>\n<p>这就是一个比较完整的MapReduce的过程了。</p>\n<p><img src=\"/LiJT-Daily/images/2021121301.png\" alt=\"Mapreduce原理\"></p>\n<h4 id=\"Mapreduce程序结构-以Word-Count为例\"><a href=\"#Mapreduce程序结构-以Word-Count为例\" class=\"headerlink\" title=\"Mapreduce程序结构(以Word Count为例)\"></a>Mapreduce程序结构(以Word Count为例)</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.StringTokenizer;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.StringTokenizer;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.*;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">WordCount</span> &#123;</span><br><span class=\"line\"><span class=\"comment\">//Mapper类</span></span><br><span class=\"line\"><span class=\"comment\">/*LongWritable表示每一行起始偏移量</span></span><br><span class=\"line\"><span class=\"comment\">第一个Text是用来接受文件中的内容，</span></span><br><span class=\"line\"><span class=\"comment\">第二个Text是用来输出给Reduce类的key,</span></span><br><span class=\"line\"><span class=\"comment\">IntWritable是用来输出给Reduce类的value*/</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">class</span> <span class=\"title class_\">TokenizerMapper</span> </span><br><span class=\"line\">       <span class=\"keyword\">extends</span> <span class=\"title class_\">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt;&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"type\">IntWritable</span> <span class=\"variable\">one</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">IntWritable</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"type\">Text</span> <span class=\"variable\">word</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Text</span>();</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">map</span><span class=\"params\">(LongWritable key, Text value, Context context</span></span><br><span class=\"line\"><span class=\"params\">                    )</span> <span class=\"keyword\">throws</span> IOException, InterruptedException &#123;</span><br><span class=\"line\">      <span class=\"type\">StringTokenizer</span> <span class=\"variable\">itr</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">StringTokenizer</span>(value.toString());</span><br><span class=\"line\">      <span class=\"keyword\">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class=\"line\">        word.set(itr.nextToken());</span><br><span class=\"line\">        context.write(word, one);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">class</span> <span class=\"title class_\">IntSumReducer</span> </span><br><span class=\"line\">       <span class=\"keyword\">extends</span> <span class=\"title class_\">Reducer</span>&lt;Text,IntWritable,Text,IntWritable&gt; &#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"type\">IntWritable</span> <span class=\"variable\">result</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">IntWritable</span>();</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">reduce</span><span class=\"params\">(Text key, Iterable&lt;IntWritable&gt; values, </span></span><br><span class=\"line\"><span class=\"params\">                       Context context</span></span><br><span class=\"line\"><span class=\"params\">                       )</span> <span class=\"keyword\">throws</span> IOException, InterruptedException &#123;</span><br><span class=\"line\">      <span class=\"type\">int</span> <span class=\"variable\">sum</span> <span class=\"operator\">=</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">      <span class=\"keyword\">for</span> (IntWritable val : values) &#123;</span><br><span class=\"line\">        sum += val.get();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      result.set(sum);</span><br><span class=\"line\">      context.write(key, result);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception &#123;</span><br><span class=\"line\">    <span class=\"comment\">//创建配置对象</span></span><br><span class=\"line\">    <span class=\"type\">Configuration</span> <span class=\"variable\">conf</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Configuration</span>();</span><br><span class=\"line\">    <span class=\"comment\">//创建job对象</span></span><br><span class=\"line\">    <span class=\"type\">Job</span> <span class=\"variable\">job</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Job</span>(conf, <span class=\"string\">&quot;word count&quot;</span>);</span><br><span class=\"line\">    <span class=\"comment\">//设置运行job的类</span></span><br><span class=\"line\">    job.setJarByClass(WordCount.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置Mapper的类</span></span><br><span class=\"line\">    job.setMapperClass(TokenizerMapper.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置Reduce的类</span></span><br><span class=\"line\">    job.setReducerClass(IntSumReducer.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置输出的key value格式</span></span><br><span class=\"line\">    job.setOutputKeyClass(Text.class);</span><br><span class=\"line\">    job.setOutputValueClass(IntWritable.class);</span><br><span class=\"line\">    <span class=\"comment\">//设置输入路径</span></span><br><span class=\"line\">    <span class=\"type\">String</span> <span class=\"variable\">inputfile</span> <span class=\"operator\">=</span> <span class=\"string\">&quot;/usr/input&quot;</span>;</span><br><span class=\"line\">    <span class=\"comment\">//设置输出路径</span></span><br><span class=\"line\">    <span class=\"type\">String</span> <span class=\"variable\">outputFile</span> <span class=\"operator\">=</span> <span class=\"string\">&quot;/usr/output&quot;</span>;</span><br><span class=\"line\">    <span class=\"comment\">//执行输入</span></span><br><span class=\"line\">    FileInputFormat.addInputPath(job, <span class=\"keyword\">new</span> <span class=\"title class_\">Path</span>(inputfile));</span><br><span class=\"line\">    <span class=\"comment\">//执行输出</span></span><br><span class=\"line\">    FileOutputFormat.setOutputPath(job, <span class=\"keyword\">new</span> <span class=\"title class_\">Path</span>(outputFile));</span><br><span class=\"line\">    <span class=\"comment\">//是否运行成功，true输出0，false输出1</span></span><br><span class=\"line\">    System.exit(job.waitForCompletion(<span class=\"literal\">true</span>) ? <span class=\"number\">0</span> : <span class=\"number\">1</span>);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Hbase-实战\"><a href=\"#Hbase-实战\" class=\"headerlink\" title=\"Hbase 实战\"></a>Hbase 实战</h2><p>这里主要记录Hbase shell里的一些常用指令</p>\n<h4 id=\"创建表\"><a href=\"#创建表\" class=\"headerlink\" title=\"创建表\"></a>创建表</h4><p>新建一个名为<code>test</code>的表，使其中包含一个名为<code>data</code>的列，表和列族属性都为默认值：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;data&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>创建完成后，我们可以输入<code>list</code>来查看表是否创建成功</p>\n<h4 id=\"添加数据\"><a href=\"#添加数据\" class=\"headerlink\" title=\"添加数据\"></a>添加数据</h4><p>我们来给上一关创建的<code>test</code>表的列<code>data</code>添加一些数据.使用<code>put</code>命令可以用来添加数据，使用<code>get</code>命令可以获取数据。</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">put <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row1&#x27;</span>,<span class=\"string\">&#x27;data:1&#x27;</span>,<span class=\"string\">&#x27;value1&#x27;</span></span><br><span class=\"line\">put <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row2&#x27;</span>,<span class=\"string\">&#x27;data:2&#x27;</span>,<span class=\"string\">&#x27;value2&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">get</span> <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row1&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>输入<code>scan</code>命令就可以查看所有的数据了</p>\n<h4 id=\"删除数据和表\"><a href=\"#删除数据和表\" class=\"headerlink\" title=\"删除数据和表\"></a>删除数据和表</h4><p>删除整行数据：<code>deleteall [表名]，[行名称]</code></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deleteall <span class=\"string\">&#x27;test&#x27;</span>,<span class=\"string\">&#x27;row1&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>删除表需要先禁用、再删除。分为两步：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">disable 表名</span><br><span class=\"line\">drop 表名</span><br></pre></td></tr></table></figure>"},{"title":"Java 常用轮子","author":"LiJT","date":"2021-12-12T16:00:00.000Z","key":"java20211213","_content":"\n## 写在前面\nWelcome back! （也对我自己）\n\n这一篇记录一些常用的Java工具包，与[Python技巧](/LiJT-Daily/2021/10/25/python.html)相对应。后者也好长时间没更新了，以后会慢慢补上。\n\n```\n偷偷地我走了，\n正如我偷偷地来。\n偷偷地我挥一挥手，\n不留下一篇SCI。\n```\n<!--more-->\n\n## java.util\n### StringTokenizer 类\n- 用途：分割字符串，类似于python的 `re.split()`.\n\n#### 构造方法\n1. `StringTokenizer(String str)` ：构造一个用来解析 str 的 StringTokenizer 对象。java 默认的分隔符是空格(\"\")、制表符(\\t)、换行符(\\n)、回车符(\\r)。\n2. `StringTokenizer(String str, String delim)` ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符。\n3. `StringTokenizer(String str, String delim, boolean returnDelims)` ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符，同时，指定是否返回分隔符。\n\n#### 常用方法\n1. `int countTokens()`：返回nextToken方法被调用的次数。\n2. `boolean hasMoreTokens()`：返回是否还有分隔符。\n3. `boolean hasMoreElements()`：判断枚举 （Enumeration） 对象中是否还有数据。\n4. `String nextToken()`：返回从当前位置到下一个分隔符的字符串。\n5. `Object nextElement()`：返回枚举 （Enumeration） 对象的下一个元素。\n6. `String nextToken(String delim)`：与 4 类似，以指定的分隔符返回结果。\n\n#### 示例\n```java\n// Hadoop WordCount中，mapper的map方法。默认用空格分隔字符串\npublic void map(LongWritable key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n    StringTokenizer itr = new StringTokenizer(value.toString());\n    word.set(itr.nextToken());\n    context.write(word, one);\n}\n```","source":"_posts/2021-12-13-java.md","raw":"---\ntitle: Java 常用轮子\nauthor: LiJT\ndate: 2021-12-13\ntags: 大数据 Java Hadoop \nkey: java20211213\n---\n\n## 写在前面\nWelcome back! （也对我自己）\n\n这一篇记录一些常用的Java工具包，与[Python技巧](/LiJT-Daily/2021/10/25/python.html)相对应。后者也好长时间没更新了，以后会慢慢补上。\n\n```\n偷偷地我走了，\n正如我偷偷地来。\n偷偷地我挥一挥手，\n不留下一篇SCI。\n```\n<!--more-->\n\n## java.util\n### StringTokenizer 类\n- 用途：分割字符串，类似于python的 `re.split()`.\n\n#### 构造方法\n1. `StringTokenizer(String str)` ：构造一个用来解析 str 的 StringTokenizer 对象。java 默认的分隔符是空格(\"\")、制表符(\\t)、换行符(\\n)、回车符(\\r)。\n2. `StringTokenizer(String str, String delim)` ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符。\n3. `StringTokenizer(String str, String delim, boolean returnDelims)` ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符，同时，指定是否返回分隔符。\n\n#### 常用方法\n1. `int countTokens()`：返回nextToken方法被调用的次数。\n2. `boolean hasMoreTokens()`：返回是否还有分隔符。\n3. `boolean hasMoreElements()`：判断枚举 （Enumeration） 对象中是否还有数据。\n4. `String nextToken()`：返回从当前位置到下一个分隔符的字符串。\n5. `Object nextElement()`：返回枚举 （Enumeration） 对象的下一个元素。\n6. `String nextToken(String delim)`：与 4 类似，以指定的分隔符返回结果。\n\n#### 示例\n```java\n// Hadoop WordCount中，mapper的map方法。默认用空格分隔字符串\npublic void map(LongWritable key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n    StringTokenizer itr = new StringTokenizer(value.toString());\n    word.set(itr.nextToken());\n    context.write(word, one);\n}\n```","slug":"2021-12-13-java","published":1,"updated":"2022-04-06T09:50:32.027Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8q000jhsv97n4scyd2","content":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>Welcome back! （也对我自己）</p>\n<p>这一篇记录一些常用的Java工具包，与<a href=\"/LiJT-Daily/2021/10/25/python.html\">Python技巧</a>相对应。后者也好长时间没更新了，以后会慢慢补上。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">偷偷地我走了，</span><br><span class=\"line\">正如我偷偷地来。</span><br><span class=\"line\">偷偷地我挥一挥手，</span><br><span class=\"line\">不留下一篇SCI。</span><br></pre></td></tr></table></figure>\n<span id=\"more\"></span>\n\n<h2 id=\"java-util\"><a href=\"#java-util\" class=\"headerlink\" title=\"java.util\"></a>java.util</h2><h3 id=\"StringTokenizer-类\"><a href=\"#StringTokenizer-类\" class=\"headerlink\" title=\"StringTokenizer 类\"></a>StringTokenizer 类</h3><ul>\n<li>用途：分割字符串，类似于python的 <code>re.split()</code>.</li>\n</ul>\n<h4 id=\"构造方法\"><a href=\"#构造方法\" class=\"headerlink\" title=\"构造方法\"></a>构造方法</h4><ol>\n<li><code>StringTokenizer(String str)</code> ：构造一个用来解析 str 的 StringTokenizer 对象。java 默认的分隔符是空格(“”)、制表符(\\t)、换行符(\\n)、回车符(\\r)。</li>\n<li><code>StringTokenizer(String str, String delim)</code> ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符。</li>\n<li><code>StringTokenizer(String str, String delim, boolean returnDelims)</code> ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符，同时，指定是否返回分隔符。</li>\n</ol>\n<h4 id=\"常用方法\"><a href=\"#常用方法\" class=\"headerlink\" title=\"常用方法\"></a>常用方法</h4><ol>\n<li><code>int countTokens()</code>：返回nextToken方法被调用的次数。</li>\n<li><code>boolean hasMoreTokens()</code>：返回是否还有分隔符。</li>\n<li><code>boolean hasMoreElements()</code>：判断枚举 （Enumeration） 对象中是否还有数据。</li>\n<li><code>String nextToken()</code>：返回从当前位置到下一个分隔符的字符串。</li>\n<li><code>Object nextElement()</code>：返回枚举 （Enumeration） 对象的下一个元素。</li>\n<li><code>String nextToken(String delim)</code>：与 4 类似，以指定的分隔符返回结果。</li>\n</ol>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Hadoop WordCount中，mapper的map方法。默认用空格分隔字符串</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">map</span><span class=\"params\">(LongWritable key, Text value, Context context</span></span><br><span class=\"line\"><span class=\"params\">                    )</span> <span class=\"keyword\">throws</span> IOException, InterruptedException &#123;</span><br><span class=\"line\">    <span class=\"type\">StringTokenizer</span> <span class=\"variable\">itr</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">StringTokenizer</span>(value.toString());</span><br><span class=\"line\">    word.set(itr.nextToken());</span><br><span class=\"line\">    context.write(word, one);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>Welcome back! （也对我自己）</p>\n<p>这一篇记录一些常用的Java工具包，与<a href=\"/LiJT-Daily/2021/10/25/python.html\">Python技巧</a>相对应。后者也好长时间没更新了，以后会慢慢补上。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">偷偷地我走了，</span><br><span class=\"line\">正如我偷偷地来。</span><br><span class=\"line\">偷偷地我挥一挥手，</span><br><span class=\"line\">不留下一篇SCI。</span><br></pre></td></tr></table></figure>","more":"<h2 id=\"java-util\"><a href=\"#java-util\" class=\"headerlink\" title=\"java.util\"></a>java.util</h2><h3 id=\"StringTokenizer-类\"><a href=\"#StringTokenizer-类\" class=\"headerlink\" title=\"StringTokenizer 类\"></a>StringTokenizer 类</h3><ul>\n<li>用途：分割字符串，类似于python的 <code>re.split()</code>.</li>\n</ul>\n<h4 id=\"构造方法\"><a href=\"#构造方法\" class=\"headerlink\" title=\"构造方法\"></a>构造方法</h4><ol>\n<li><code>StringTokenizer(String str)</code> ：构造一个用来解析 str 的 StringTokenizer 对象。java 默认的分隔符是空格(“”)、制表符(\\t)、换行符(\\n)、回车符(\\r)。</li>\n<li><code>StringTokenizer(String str, String delim)</code> ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符。</li>\n<li><code>StringTokenizer(String str, String delim, boolean returnDelims)</code> ：构造一个用来解析 str 的 StringTokenizer 对象，并提供一个指定的分隔符，同时，指定是否返回分隔符。</li>\n</ol>\n<h4 id=\"常用方法\"><a href=\"#常用方法\" class=\"headerlink\" title=\"常用方法\"></a>常用方法</h4><ol>\n<li><code>int countTokens()</code>：返回nextToken方法被调用的次数。</li>\n<li><code>boolean hasMoreTokens()</code>：返回是否还有分隔符。</li>\n<li><code>boolean hasMoreElements()</code>：判断枚举 （Enumeration） 对象中是否还有数据。</li>\n<li><code>String nextToken()</code>：返回从当前位置到下一个分隔符的字符串。</li>\n<li><code>Object nextElement()</code>：返回枚举 （Enumeration） 对象的下一个元素。</li>\n<li><code>String nextToken(String delim)</code>：与 4 类似，以指定的分隔符返回结果。</li>\n</ol>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Hadoop WordCount中，mapper的map方法。默认用空格分隔字符串</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">map</span><span class=\"params\">(LongWritable key, Text value, Context context</span></span><br><span class=\"line\"><span class=\"params\">                    )</span> <span class=\"keyword\">throws</span> IOException, InterruptedException &#123;</span><br><span class=\"line\">    <span class=\"type\">StringTokenizer</span> <span class=\"variable\">itr</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">StringTokenizer</span>(value.toString());</span><br><span class=\"line\">    word.set(itr.nextToken());</span><br><span class=\"line\">    context.write(word, one);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"模糊理论及其应用简介（笔记）","author":"LiJT","date":"2021-12-28T16:00:00.000Z","key":"fuzzy20211229","_content":"\n模糊理论（Fuzzy Theory）是指用到了**模糊集合**的基本概念或**连续隶属度函数**的理论。它可分类为模糊数学，模糊系统，不确定性和信息，模糊决策，模糊逻辑与人工智能这五个分支，它们并不是完全独立的，它们之间有紧密的联系。例如，模糊控制就会用到模糊数学和模糊逻辑中的概念。从实际应用的观点来看，模糊理论的应用大部分集中在**模糊系统**上，尤其集中在模糊控制上。也有一些模糊专家系统应用于医疗诊断和决策支持。由于模糊理论从理论和实践的角度看仍然是新生事物，所以我们期望，随着模糊领域的成熟，将会出现更多可靠的实际应用。 （摘自百度百科）\n\n<!--more-->\n## 什么是模糊理论\n\n### 模糊\n\n介绍模糊理论之前，我们首先直观地理解**模糊**这一概念。例如小明**十分喜欢吃牛肉和鸡蛋**，**特别讨厌番茄和甜食**。那么可以明确地说，小明喜欢吃牛肉滑蛋饭但很讨厌吃糖拌西红柿。但如果给小明做一份**番茄炖牛肉**，我们就不能确定小明是喜欢还是不喜欢。在这一场景下，小明对番茄炖牛肉的态度就是“模糊”的。\n\n### 模糊逻辑\n\n更一般地，我们引入**模糊逻辑**的概念。在经典二值逻辑中，我们用1表示真（喜欢），0表示假（不喜欢），那么命题1（小明喜欢牛肉滑蛋饭）的值为1，命题2（小明喜欢糖拌西红柿）的值为假。对于命题3（小明喜欢番茄炖牛肉），我们使用介于0和1之间的**隶属度**表示这两个值之间的过渡状态，例如命题3的值=0.7，表示小明有点喜欢番茄炖牛肉。使用隶属度值**消除二值之间非此即彼的对立，这就是模糊逻辑**。\n\n### 模糊集合\n\n接下来，我们更进一步地引入**模糊集合**的概念。在古典集合中，对于任意全域$U$内的一个元素$x$和一个集合$A$，如果使用$f_A(\\cdot)$表示元素相对于集合的关系，则只包含以下两种情况：\n\n$$\nf_A(x)=\\left\\{\n\\begin{aligned}\n0, x\\notin A\\\\\n1, x\\in A\n\\end{aligned}\\right.\n$$\n\n那么 $f_A:U\\to\\{ 0,1\\}$就是一个二值函数。在**模糊集合**中，则使用连续值表示*元素属于集合的程度*，这样的函数$f_A：U\\to[0,1]$就被称为连续的**隶属度函数**。所谓“隶属度”，就是“元素隶属于集合的程度”。例如 $f_A(x)=0.6$，表示元素$x$属于集合$A$的程度是0.6.","source":"_posts/2021-12-29-fuzzy.md","raw":"---\ntitle: 模糊理论及其应用简介（笔记）\nauthor: LiJT\ndate: 2021-12-29\ntags: 数学\nkey: fuzzy20211229\n---\n\n模糊理论（Fuzzy Theory）是指用到了**模糊集合**的基本概念或**连续隶属度函数**的理论。它可分类为模糊数学，模糊系统，不确定性和信息，模糊决策，模糊逻辑与人工智能这五个分支，它们并不是完全独立的，它们之间有紧密的联系。例如，模糊控制就会用到模糊数学和模糊逻辑中的概念。从实际应用的观点来看，模糊理论的应用大部分集中在**模糊系统**上，尤其集中在模糊控制上。也有一些模糊专家系统应用于医疗诊断和决策支持。由于模糊理论从理论和实践的角度看仍然是新生事物，所以我们期望，随着模糊领域的成熟，将会出现更多可靠的实际应用。 （摘自百度百科）\n\n<!--more-->\n## 什么是模糊理论\n\n### 模糊\n\n介绍模糊理论之前，我们首先直观地理解**模糊**这一概念。例如小明**十分喜欢吃牛肉和鸡蛋**，**特别讨厌番茄和甜食**。那么可以明确地说，小明喜欢吃牛肉滑蛋饭但很讨厌吃糖拌西红柿。但如果给小明做一份**番茄炖牛肉**，我们就不能确定小明是喜欢还是不喜欢。在这一场景下，小明对番茄炖牛肉的态度就是“模糊”的。\n\n### 模糊逻辑\n\n更一般地，我们引入**模糊逻辑**的概念。在经典二值逻辑中，我们用1表示真（喜欢），0表示假（不喜欢），那么命题1（小明喜欢牛肉滑蛋饭）的值为1，命题2（小明喜欢糖拌西红柿）的值为假。对于命题3（小明喜欢番茄炖牛肉），我们使用介于0和1之间的**隶属度**表示这两个值之间的过渡状态，例如命题3的值=0.7，表示小明有点喜欢番茄炖牛肉。使用隶属度值**消除二值之间非此即彼的对立，这就是模糊逻辑**。\n\n### 模糊集合\n\n接下来，我们更进一步地引入**模糊集合**的概念。在古典集合中，对于任意全域$U$内的一个元素$x$和一个集合$A$，如果使用$f_A(\\cdot)$表示元素相对于集合的关系，则只包含以下两种情况：\n\n$$\nf_A(x)=\\left\\{\n\\begin{aligned}\n0, x\\notin A\\\\\n1, x\\in A\n\\end{aligned}\\right.\n$$\n\n那么 $f_A:U\\to\\{ 0,1\\}$就是一个二值函数。在**模糊集合**中，则使用连续值表示*元素属于集合的程度*，这样的函数$f_A：U\\to[0,1]$就被称为连续的**隶属度函数**。所谓“隶属度”，就是“元素隶属于集合的程度”。例如 $f_A(x)=0.6$，表示元素$x$属于集合$A$的程度是0.6.","slug":"2021-12-29-fuzzy","published":1,"updated":"2022-04-06T09:50:45.714Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1ngri8r000lhsv9a0qw5eqx","content":"<p>模糊理论（Fuzzy Theory）是指用到了<strong>模糊集合</strong>的基本概念或<strong>连续隶属度函数</strong>的理论。它可分类为模糊数学，模糊系统，不确定性和信息，模糊决策，模糊逻辑与人工智能这五个分支，它们并不是完全独立的，它们之间有紧密的联系。例如，模糊控制就会用到模糊数学和模糊逻辑中的概念。从实际应用的观点来看，模糊理论的应用大部分集中在<strong>模糊系统</strong>上，尤其集中在模糊控制上。也有一些模糊专家系统应用于医疗诊断和决策支持。由于模糊理论从理论和实践的角度看仍然是新生事物，所以我们期望，随着模糊领域的成熟，将会出现更多可靠的实际应用。 （摘自百度百科）</p>\n<span id=\"more\"></span>\n<h2 id=\"什么是模糊理论\"><a href=\"#什么是模糊理论\" class=\"headerlink\" title=\"什么是模糊理论\"></a>什么是模糊理论</h2><h3 id=\"模糊\"><a href=\"#模糊\" class=\"headerlink\" title=\"模糊\"></a>模糊</h3><p>介绍模糊理论之前，我们首先直观地理解<strong>模糊</strong>这一概念。例如小明<strong>十分喜欢吃牛肉和鸡蛋</strong>，<strong>特别讨厌番茄和甜食</strong>。那么可以明确地说，小明喜欢吃牛肉滑蛋饭但很讨厌吃糖拌西红柿。但如果给小明做一份<strong>番茄炖牛肉</strong>，我们就不能确定小明是喜欢还是不喜欢。在这一场景下，小明对番茄炖牛肉的态度就是“模糊”的。</p>\n<h3 id=\"模糊逻辑\"><a href=\"#模糊逻辑\" class=\"headerlink\" title=\"模糊逻辑\"></a>模糊逻辑</h3><p>更一般地，我们引入<strong>模糊逻辑</strong>的概念。在经典二值逻辑中，我们用1表示真（喜欢），0表示假（不喜欢），那么命题1（小明喜欢牛肉滑蛋饭）的值为1，命题2（小明喜欢糖拌西红柿）的值为假。对于命题3（小明喜欢番茄炖牛肉），我们使用介于0和1之间的<strong>隶属度</strong>表示这两个值之间的过渡状态，例如命题3的值=0.7，表示小明有点喜欢番茄炖牛肉。使用隶属度值<strong>消除二值之间非此即彼的对立，这就是模糊逻辑</strong>。</p>\n<h3 id=\"模糊集合\"><a href=\"#模糊集合\" class=\"headerlink\" title=\"模糊集合\"></a>模糊集合</h3><p>接下来，我们更进一步地引入<strong>模糊集合</strong>的概念。在古典集合中，对于任意全域$U$内的一个元素$x$和一个集合$A$，如果使用$f_A(\\cdot)$表示元素相对于集合的关系，则只包含以下两种情况：</p>\n<p>$$<br>f_A(x)=\\left{<br>\\begin{aligned}<br>0, x\\notin A\\<br>1, x\\in A<br>\\end{aligned}\\right.<br>$$</p>\n<p>那么 $f_A:U\\to{ 0,1}$就是一个二值函数。在<strong>模糊集合</strong>中，则使用连续值表示<em>元素属于集合的程度</em>，这样的函数$f_A：U\\to[0,1]$就被称为连续的<strong>隶属度函数</strong>。所谓“隶属度”，就是“元素隶属于集合的程度”。例如 $f_A(x)=0.6$，表示元素$x$属于集合$A$的程度是0.6.</p>\n","site":{"data":{}},"excerpt":"<p>模糊理论（Fuzzy Theory）是指用到了<strong>模糊集合</strong>的基本概念或<strong>连续隶属度函数</strong>的理论。它可分类为模糊数学，模糊系统，不确定性和信息，模糊决策，模糊逻辑与人工智能这五个分支，它们并不是完全独立的，它们之间有紧密的联系。例如，模糊控制就会用到模糊数学和模糊逻辑中的概念。从实际应用的观点来看，模糊理论的应用大部分集中在<strong>模糊系统</strong>上，尤其集中在模糊控制上。也有一些模糊专家系统应用于医疗诊断和决策支持。由于模糊理论从理论和实践的角度看仍然是新生事物，所以我们期望，随着模糊领域的成熟，将会出现更多可靠的实际应用。 （摘自百度百科）</p>","more":"<h2 id=\"什么是模糊理论\"><a href=\"#什么是模糊理论\" class=\"headerlink\" title=\"什么是模糊理论\"></a>什么是模糊理论</h2><h3 id=\"模糊\"><a href=\"#模糊\" class=\"headerlink\" title=\"模糊\"></a>模糊</h3><p>介绍模糊理论之前，我们首先直观地理解<strong>模糊</strong>这一概念。例如小明<strong>十分喜欢吃牛肉和鸡蛋</strong>，<strong>特别讨厌番茄和甜食</strong>。那么可以明确地说，小明喜欢吃牛肉滑蛋饭但很讨厌吃糖拌西红柿。但如果给小明做一份<strong>番茄炖牛肉</strong>，我们就不能确定小明是喜欢还是不喜欢。在这一场景下，小明对番茄炖牛肉的态度就是“模糊”的。</p>\n<h3 id=\"模糊逻辑\"><a href=\"#模糊逻辑\" class=\"headerlink\" title=\"模糊逻辑\"></a>模糊逻辑</h3><p>更一般地，我们引入<strong>模糊逻辑</strong>的概念。在经典二值逻辑中，我们用1表示真（喜欢），0表示假（不喜欢），那么命题1（小明喜欢牛肉滑蛋饭）的值为1，命题2（小明喜欢糖拌西红柿）的值为假。对于命题3（小明喜欢番茄炖牛肉），我们使用介于0和1之间的<strong>隶属度</strong>表示这两个值之间的过渡状态，例如命题3的值=0.7，表示小明有点喜欢番茄炖牛肉。使用隶属度值<strong>消除二值之间非此即彼的对立，这就是模糊逻辑</strong>。</p>\n<h3 id=\"模糊集合\"><a href=\"#模糊集合\" class=\"headerlink\" title=\"模糊集合\"></a>模糊集合</h3><p>接下来，我们更进一步地引入<strong>模糊集合</strong>的概念。在古典集合中，对于任意全域$U$内的一个元素$x$和一个集合$A$，如果使用$f_A(\\cdot)$表示元素相对于集合的关系，则只包含以下两种情况：</p>\n<p>$$<br>f_A(x)=\\left{<br>\\begin{aligned}<br>0, x\\notin A\\<br>1, x\\in A<br>\\end{aligned}\\right.<br>$$</p>\n<p>那么 $f_A:U\\to{ 0,1}$就是一个二值函数。在<strong>模糊集合</strong>中，则使用连续值表示<em>元素属于集合的程度</em>，这样的函数$f_A：U\\to[0,1]$就被称为连续的<strong>隶属度函数</strong>。所谓“隶属度”，就是“元素隶属于集合的程度”。例如 $f_A(x)=0.6$，表示元素$x$属于集合$A$的程度是0.6.</p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cl1nc5d0d0000fwv95tabbjmx","tag_id":"cl1nc5d0h0001fwv9f5ief6c3","_id":"cl1nc5d0j0002fwv916etf1ux"},{"post_id":"cl1ngri8c0001hsv99z4d9myf","tag_id":"cl1ngri8g0004hsv96d41c1de","_id":"cl1ngri8r000khsv90ekb5mqu"},{"post_id":"cl1ngri8c0001hsv99z4d9myf","tag_id":"cl1ngri8l0009hsv9dqi306gs","_id":"cl1ngri8r000mhsv92w2fe4ac"},{"post_id":"cl1ngri8c0001hsv99z4d9myf","tag_id":"cl1ngri8n000chsv98k9wgx7w","_id":"cl1ngri8v000ohsv9czs9c6jz"},{"post_id":"cl1ngri8c0001hsv99z4d9myf","tag_id":"cl1ngri8p000fhsv9b00fed3k","_id":"cl1ngri8w000phsv9a0rsb2aj"},{"post_id":"cl1ngri8f0003hsv9hohn9i0d","tag_id":"cl1ngri8q000ihsv92qc19qi2","_id":"cl1ngri8w000rhsv98fticlz7"},{"post_id":"cl1ngri8j0006hsv9dmglh3f1","tag_id":"cl1ngri8q000ihsv92qc19qi2","_id":"cl1ngri8w000shsv91yxhbdq5"},{"post_id":"cl1ngri8k0007hsv9b1n7350m","tag_id":"cl1ngri8w000qhsv9cvut4lvb","_id":"cl1ngri8x000uhsv9en98fa5i"},{"post_id":"cl1ngri8k0008hsv92emcfzs8","tag_id":"cl1ngri8g0004hsv96d41c1de","_id":"cl1ngri8x000xhsv91c4t0a57"},{"post_id":"cl1ngri8k0008hsv92emcfzs8","tag_id":"cl1ngri8l0009hsv9dqi306gs","_id":"cl1ngri8x000yhsv9dn9o1qck"},{"post_id":"cl1ngri8k0008hsv92emcfzs8","tag_id":"cl1ngri8n000chsv98k9wgx7w","_id":"cl1ngri8y0010hsv9gbu91qb3"},{"post_id":"cl1ngri8l000ahsv9asp58s8l","tag_id":"cl1ngri8l0009hsv9dqi306gs","_id":"cl1ngri8y0011hsv9dcgn9osg"},{"post_id":"cl1ngri8l000ahsv9asp58s8l","tag_id":"cl1ngri8x000whsv9fe0520pl","_id":"cl1ngri8y0013hsv99qd9cgw9"},{"post_id":"cl1ngri8m000bhsv9duy61zlu","tag_id":"cl1ngri8x000zhsv97aqp713j","_id":"cl1ngri8z0016hsv9ad3x2vht"},{"post_id":"cl1ngri8m000bhsv9duy61zlu","tag_id":"cl1ngri8n000chsv98k9wgx7w","_id":"cl1ngri8z0017hsv950o5hwn0"},{"post_id":"cl1ngri8m000bhsv9duy61zlu","tag_id":"cl1ngri8p000fhsv9b00fed3k","_id":"cl1ngri8z0019hsv924f3g2kx"},{"post_id":"cl1ngri8n000dhsv99kjk2dem","tag_id":"cl1ngri8n000chsv98k9wgx7w","_id":"cl1ngri8z001ahsv9ddy48u83"},{"post_id":"cl1ngri8n000dhsv99kjk2dem","tag_id":"cl1ngri8p000fhsv9b00fed3k","_id":"cl1ngri8z001chsv99wq9bzyj"},{"post_id":"cl1ngri8o000ehsv95b6h4c3m","tag_id":"cl1ngri8q000ihsv92qc19qi2","_id":"cl1ngri90001ehsv9a0xo0czw"},{"post_id":"cl1ngri8o000ehsv95b6h4c3m","tag_id":"cl1ngri8z001bhsv9diiiev3w","_id":"cl1ngri90001fhsv9dfpz7twq"},{"post_id":"cl1ngri8p000ghsv924nf2gyu","tag_id":"cl1ngri8n000chsv98k9wgx7w","_id":"cl1ngri90001ihsv94abu4uw1"},{"post_id":"cl1ngri8p000ghsv924nf2gyu","tag_id":"cl1ngri8z001dhsv94h3l9xgn","_id":"cl1ngri90001jhsv94z4s6wgm"},{"post_id":"cl1ngri8p000ghsv924nf2gyu","tag_id":"cl1ngri90001ghsv94oc921na","_id":"cl1ngri90001lhsv9aa1j0igz"},{"post_id":"cl1ngri8q000hhsv94r1o5liy","tag_id":"cl1ngri90001hhsv99nml1cvq","_id":"cl1ngri91001phsv92zkx6v7t"},{"post_id":"cl1ngri8q000hhsv94r1o5liy","tag_id":"cl1ngri90001khsv925n3egrb","_id":"cl1ngri91001qhsv946mabzym"},{"post_id":"cl1ngri8q000hhsv94r1o5liy","tag_id":"cl1ngri90001mhsv95gpqaoo8","_id":"cl1ngri92001shsv9f5nm4dva"},{"post_id":"cl1ngri8q000hhsv94r1o5liy","tag_id":"cl1ngri91001nhsv9dcqsghcq","_id":"cl1ngri92001thsv9h06dfv6j"},{"post_id":"cl1ngri8q000jhsv97n4scyd2","tag_id":"cl1ngri91001ohsv9g05th412","_id":"cl1ngri93001vhsv9czqh9gah"},{"post_id":"cl1ngri8r000lhsv9a0qw5eqx","tag_id":"cl1ngri91001rhsv9dbcabw4l","_id":"cl1ngri93001whsv9hxpggkh0"},{"post_id":"cl1nc5d0p0006fwv95vgjdnt5","tag_id":"cl1nc5d0h0001fwv9f5ief6c3","_id":"cl1ngri93001xhsv94yfyfmif"},{"post_id":"cl1nc5d0p0006fwv95vgjdnt5","tag_id":"cl1ngri92001uhsv9drdpckb7","_id":"cl1ngri93001yhsv9dej4dv4e"},{"post_id":"cl1nc5d0l0003fwv9a7dvaox0","tag_id":"cl1ngri91001rhsv9dbcabw4l","_id":"cl1ngri96001zhsv9dqg5g3if"},{"post_id":"cl1nc5d0l0003fwv9a7dvaox0","tag_id":"cl1ngri8z001bhsv9diiiev3w","_id":"cl1ngri960020hsv954sc7l1x"}],"Tag":[{"name":"科研","_id":"cl1nc5d0h0001fwv9f5ief6c3"},{"name":"数学 杂谈","_id":"cl1nc5d0n0004fwv99xuh9lb7"},{"name":"科研 学习","_id":"cl1nc5d0q0007fwv98eyi2gwv"},{"name":"pytorch","_id":"cl1ngri8g0004hsv96d41c1de"},{"name":"深度学习","_id":"cl1ngri8l0009hsv9dqi306gs"},{"name":"coding","_id":"cl1ngri8n000chsv98k9wgx7w"},{"name":"持续更新","_id":"cl1ngri8p000fhsv9b00fed3k"},{"name":"美食","_id":"cl1ngri8q000ihsv92qc19qi2"},{"name":"小说","_id":"cl1ngri8w000qhsv9cvut4lvb"},{"name":"实验","_id":"cl1ngri8x000whsv9fe0520pl"},{"name":"Python","_id":"cl1ngri8x000zhsv97aqp713j"},{"name":"杂谈","_id":"cl1ngri8z001bhsv9diiiev3w"},{"name":"vscode","_id":"cl1ngri8z001dhsv94h3l9xgn"},{"name":"ssh","_id":"cl1ngri90001ghsv94oc921na"},{"name":"大数据","_id":"cl1ngri90001hhsv99nml1cvq"},{"name":"Java","_id":"cl1ngri90001khsv925n3egrb"},{"name":"Hadoop","_id":"cl1ngri90001mhsv95gpqaoo8"},{"name":"Mapreduce","_id":"cl1ngri91001nhsv9dcqsghcq"},{"name":"大数据 Java Hadoop","_id":"cl1ngri91001ohsv9g05th412"},{"name":"数学","_id":"cl1ngri91001rhsv9dbcabw4l"},{"name":"学习","_id":"cl1ngri92001uhsv9drdpckb7"}]}}